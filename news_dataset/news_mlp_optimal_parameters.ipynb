{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting optimal MLP's hiperparameters for news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.set_option('display.max_columns', 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank( timedelta)</th>\n",
       "      <th>rank( n_tokens_title)</th>\n",
       "      <th>rank( n_tokens_content)</th>\n",
       "      <th>rank( n_unique_tokens)</th>\n",
       "      <th>rank( n_non_stop_words)</th>\n",
       "      <th>rank( n_non_stop_unique_tokens)</th>\n",
       "      <th>rank( num_hrefs)</th>\n",
       "      <th>rank( num_self_hrefs)</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>rank( average_token_length)</th>\n",
       "      <th>rank( num_keywords)</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>rank( kw_max_min)</th>\n",
       "      <th>rank( kw_avg_min)</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>rank( kw_avg_max)</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>rank( kw_max_avg)</th>\n",
       "      <th>rank( kw_avg_avg)</th>\n",
       "      <th>rank( self_reference_min_shares)</th>\n",
       "      <th>rank( self_reference_max_shares)</th>\n",
       "      <th>rank( self_reference_avg_sharess)</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>rank( LDA_00)</th>\n",
       "      <th>rank( LDA_01)</th>\n",
       "      <th>rank( LDA_02)</th>\n",
       "      <th>rank( LDA_03)</th>\n",
       "      <th>rank( LDA_04)</th>\n",
       "      <th>rank( global_subjectivity)</th>\n",
       "      <th>rank( global_sentiment_polarity)</th>\n",
       "      <th>rank( global_rate_positive_words)</th>\n",
       "      <th>rank( global_rate_negative_words)</th>\n",
       "      <th>rank( rate_positive_words)</th>\n",
       "      <th>rank( rate_negative_words)</th>\n",
       "      <th>rank( avg_positive_polarity)</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>rank( avg_negative_polarity)</th>\n",
       "      <th>rank( min_negative_polarity)</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.091313</td>\n",
       "      <td>0.746312</td>\n",
       "      <td>-0.830751</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>-0.859076</td>\n",
       "      <td>1.250329</td>\n",
       "      <td>-0.773700</td>\n",
       "      <td>-0.247319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060832</td>\n",
       "      <td>-1.077791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.314162</td>\n",
       "      <td>-2.013451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-0.809729</td>\n",
       "      <td>-0.897243</td>\n",
       "      <td>-0.895353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.011874</td>\n",
       "      <td>1.107189</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.133906</td>\n",
       "      <td>-0.019697</td>\n",
       "      <td>0.834551</td>\n",
       "      <td>-0.299737</td>\n",
       "      <td>0.407371</td>\n",
       "      <td>-0.186943</td>\n",
       "      <td>0.425334</td>\n",
       "      <td>-0.344559</td>\n",
       "      <td>0.257404</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.840613</td>\n",
       "      <td>-0.309042</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.091313</td>\n",
       "      <td>-0.627749</td>\n",
       "      <td>-0.629945</td>\n",
       "      <td>0.636396</td>\n",
       "      <td>-0.682170</td>\n",
       "      <td>1.037852</td>\n",
       "      <td>-1.082209</td>\n",
       "      <td>-0.770293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874264</td>\n",
       "      <td>-1.654145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.314162</td>\n",
       "      <td>-2.013451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-1.337803</td>\n",
       "      <td>-1.337726</td>\n",
       "      <td>-1.337803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.506066</td>\n",
       "      <td>0.481113</td>\n",
       "      <td>0.164789</td>\n",
       "      <td>0.215657</td>\n",
       "      <td>0.071541</td>\n",
       "      <td>-1.206170</td>\n",
       "      <td>0.345029</td>\n",
       "      <td>0.255150</td>\n",
       "      <td>0.038674</td>\n",
       "      <td>0.167738</td>\n",
       "      <td>-0.092096</td>\n",
       "      <td>-0.900984</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.303623</td>\n",
       "      <td>1.355812</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.091313</td>\n",
       "      <td>-0.627749</td>\n",
       "      <td>-0.877419</td>\n",
       "      <td>0.346405</td>\n",
       "      <td>-0.977397</td>\n",
       "      <td>-0.284000</td>\n",
       "      <td>-1.082209</td>\n",
       "      <td>-0.770293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.983430</td>\n",
       "      <td>-0.561454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.314162</td>\n",
       "      <td>-2.013451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-0.314418</td>\n",
       "      <td>-0.753138</td>\n",
       "      <td>-0.722589</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628018</td>\n",
       "      <td>-0.102896</td>\n",
       "      <td>-0.194219</td>\n",
       "      <td>-0.319837</td>\n",
       "      <td>1.102533</td>\n",
       "      <td>2.439542</td>\n",
       "      <td>2.017790</td>\n",
       "      <td>1.034661</td>\n",
       "      <td>-0.690612</td>\n",
       "      <td>1.106431</td>\n",
       "      <td>-0.977397</td>\n",
       "      <td>1.564511</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.637609</td>\n",
       "      <td>-0.868165</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.091313</td>\n",
       "      <td>-0.627749</td>\n",
       "      <td>0.309539</td>\n",
       "      <td>-0.344123</td>\n",
       "      <td>0.321434</td>\n",
       "      <td>-0.264207</td>\n",
       "      <td>0.207090</td>\n",
       "      <td>-1.494860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.947209</td>\n",
       "      <td>-0.086922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.314162</td>\n",
       "      <td>-2.013451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-1.337803</td>\n",
       "      <td>-1.337726</td>\n",
       "      <td>-1.337803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.437130</td>\n",
       "      <td>1.172315</td>\n",
       "      <td>0.875191</td>\n",
       "      <td>-0.392816</td>\n",
       "      <td>-0.811837</td>\n",
       "      <td>-0.291810</td>\n",
       "      <td>-0.208737</td>\n",
       "      <td>0.150161</td>\n",
       "      <td>0.574307</td>\n",
       "      <td>-0.284132</td>\n",
       "      <td>0.363172</td>\n",
       "      <td>0.351546</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.984764</td>\n",
       "      <td>-0.309042</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.091313</td>\n",
       "      <td>1.191898</td>\n",
       "      <td>1.253929</td>\n",
       "      <td>-1.200952</td>\n",
       "      <td>1.406604</td>\n",
       "      <td>-1.358432</td>\n",
       "      <td>1.046996</td>\n",
       "      <td>2.268357</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069322</td>\n",
       "      <td>-0.086922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.314162</td>\n",
       "      <td>-2.013451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-0.768720</td>\n",
       "      <td>1.144183</td>\n",
       "      <td>0.294747</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.314651</td>\n",
       "      <td>-0.220448</td>\n",
       "      <td>-0.531720</td>\n",
       "      <td>-0.626094</td>\n",
       "      <td>1.680026</td>\n",
       "      <td>0.738234</td>\n",
       "      <td>1.686806</td>\n",
       "      <td>1.934743</td>\n",
       "      <td>-0.367261</td>\n",
       "      <td>1.143818</td>\n",
       "      <td>-1.009924</td>\n",
       "      <td>0.671991</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.327633</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>-3.716757</td>\n",
       "      <td>0.299307</td>\n",
       "      <td>-0.208059</td>\n",
       "      <td>-0.100354</td>\n",
       "      <td>-0.394045</td>\n",
       "      <td>-0.060357</td>\n",
       "      <td>0.207090</td>\n",
       "      <td>1.378593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.507837</td>\n",
       "      <td>0.343989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.024409</td>\n",
       "      <td>-0.424676</td>\n",
       "      <td>26900.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>0.911184</td>\n",
       "      <td>2514.742857</td>\n",
       "      <td>-0.200666</td>\n",
       "      <td>0.179677</td>\n",
       "      <td>1.547643</td>\n",
       "      <td>1.792045</td>\n",
       "      <td>1.960439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.686325</td>\n",
       "      <td>-0.822431</td>\n",
       "      <td>0.344962</td>\n",
       "      <td>-0.966295</td>\n",
       "      <td>1.300303</td>\n",
       "      <td>0.369968</td>\n",
       "      <td>0.265549</td>\n",
       "      <td>-0.088382</td>\n",
       "      <td>-0.099273</td>\n",
       "      <td>0.086256</td>\n",
       "      <td>-0.011160</td>\n",
       "      <td>-0.331371</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.056493</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39640</th>\n",
       "      <td>-3.716757</td>\n",
       "      <td>0.746312</td>\n",
       "      <td>-0.278442</td>\n",
       "      <td>1.442174</td>\n",
       "      <td>-0.472542</td>\n",
       "      <td>1.915979</td>\n",
       "      <td>0.207090</td>\n",
       "      <td>1.378593</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-0.944538</td>\n",
       "      <td>-0.086922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.111863</td>\n",
       "      <td>-0.343553</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>-0.463864</td>\n",
       "      <td>1664.267857</td>\n",
       "      <td>0.457255</td>\n",
       "      <td>0.522204</td>\n",
       "      <td>0.512085</td>\n",
       "      <td>-0.200537</td>\n",
       "      <td>-0.045952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.229267</td>\n",
       "      <td>-0.398422</td>\n",
       "      <td>0.508340</td>\n",
       "      <td>1.064995</td>\n",
       "      <td>-0.650512</td>\n",
       "      <td>1.306810</td>\n",
       "      <td>0.854330</td>\n",
       "      <td>0.039433</td>\n",
       "      <td>-0.730368</td>\n",
       "      <td>0.757048</td>\n",
       "      <td>-0.660623</td>\n",
       "      <td>0.203796</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.416663</td>\n",
       "      <td>0.394831</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39641</th>\n",
       "      <td>-3.716757</td>\n",
       "      <td>-0.158415</td>\n",
       "      <td>0.091302</td>\n",
       "      <td>-0.222587</td>\n",
       "      <td>0.147508</td>\n",
       "      <td>-0.491646</td>\n",
       "      <td>1.335872</td>\n",
       "      <td>-0.770293</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.415071</td>\n",
       "      <td>0.343989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.072048</td>\n",
       "      <td>-0.460873</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>0.404934</td>\n",
       "      <td>1753.882353</td>\n",
       "      <td>0.855287</td>\n",
       "      <td>1.068122</td>\n",
       "      <td>0.159376</td>\n",
       "      <td>-0.483671</td>\n",
       "      <td>-0.385722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505177</td>\n",
       "      <td>-0.640777</td>\n",
       "      <td>-0.697652</td>\n",
       "      <td>1.015044</td>\n",
       "      <td>0.250808</td>\n",
       "      <td>0.697813</td>\n",
       "      <td>-0.997733</td>\n",
       "      <td>-0.324699</td>\n",
       "      <td>0.953765</td>\n",
       "      <td>-0.792776</td>\n",
       "      <td>0.900083</td>\n",
       "      <td>-0.660859</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.892713</td>\n",
       "      <td>-0.868165</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39642</th>\n",
       "      <td>-3.716757</td>\n",
       "      <td>-2.153192</td>\n",
       "      <td>0.617082</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.705942</td>\n",
       "      <td>0.023808</td>\n",
       "      <td>0.329067</td>\n",
       "      <td>-0.770293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.082436</td>\n",
       "      <td>-1.077791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.314162</td>\n",
       "      <td>-2.375909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>0.081465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.198484</td>\n",
       "      <td>-1.659634</td>\n",
       "      <td>-0.842009</td>\n",
       "      <td>-0.902979</td>\n",
       "      <td>-0.902124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193188</td>\n",
       "      <td>0.241684</td>\n",
       "      <td>1.515967</td>\n",
       "      <td>0.021404</td>\n",
       "      <td>-0.064950</td>\n",
       "      <td>-1.048091</td>\n",
       "      <td>-1.469914</td>\n",
       "      <td>-1.181859</td>\n",
       "      <td>0.827942</td>\n",
       "      <td>-1.331563</td>\n",
       "      <td>1.541598</td>\n",
       "      <td>-1.397816</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.475867</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39643</th>\n",
       "      <td>-3.716757</td>\n",
       "      <td>-0.158415</td>\n",
       "      <td>-1.245233</td>\n",
       "      <td>1.489854</td>\n",
       "      <td>-1.299567</td>\n",
       "      <td>1.540148</td>\n",
       "      <td>-1.696325</td>\n",
       "      <td>-0.770293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.700679</td>\n",
       "      <td>-1.654145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.622922</td>\n",
       "      <td>-1.749738</td>\n",
       "      <td>205600.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>0.859487</td>\n",
       "      <td>3035.080555</td>\n",
       "      <td>-0.473319</td>\n",
       "      <td>0.424711</td>\n",
       "      <td>0.512085</td>\n",
       "      <td>-0.200537</td>\n",
       "      <td>-0.045952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309937</td>\n",
       "      <td>1.816184</td>\n",
       "      <td>0.115936</td>\n",
       "      <td>0.239210</td>\n",
       "      <td>0.067294</td>\n",
       "      <td>0.792819</td>\n",
       "      <td>-0.159920</td>\n",
       "      <td>1.407029</td>\n",
       "      <td>-0.296564</td>\n",
       "      <td>0.920030</td>\n",
       "      <td>-0.810958</td>\n",
       "      <td>-1.304289</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.532339</td>\n",
       "      <td>0.988570</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39644 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rank( timedelta)  rank( n_tokens_title)  rank( n_tokens_content)  \\\n",
       "0              3.091313               0.746312                -0.830751   \n",
       "1              3.091313              -0.627749                -0.629945   \n",
       "2              3.091313              -0.627749                -0.877419   \n",
       "3              3.091313              -0.627749                 0.309539   \n",
       "4              3.091313               1.191898                 1.253929   \n",
       "...                 ...                    ...                      ...   \n",
       "39639         -3.716757               0.299307                -0.208059   \n",
       "39640         -3.716757               0.746312                -0.278442   \n",
       "39641         -3.716757              -0.158415                 0.091302   \n",
       "39642         -3.716757              -2.153192                 0.617082   \n",
       "39643         -3.716757              -0.158415                -1.245233   \n",
       "\n",
       "       rank( n_unique_tokens)  rank( n_non_stop_words)  \\\n",
       "0                    1.171875                -0.859076   \n",
       "1                    0.636396                -0.682170   \n",
       "2                    0.346405                -0.977397   \n",
       "3                   -0.344123                 0.321434   \n",
       "4                   -1.200952                 1.406604   \n",
       "...                       ...                      ...   \n",
       "39639               -0.100354                -0.394045   \n",
       "39640                1.442174                -0.472542   \n",
       "39641               -0.222587                 0.147508   \n",
       "39642                0.002434                 0.705942   \n",
       "39643                1.489854                -1.299567   \n",
       "\n",
       "       rank( n_non_stop_unique_tokens)  rank( num_hrefs)  \\\n",
       "0                             1.250329         -0.773700   \n",
       "1                             1.037852         -1.082209   \n",
       "2                            -0.284000         -1.082209   \n",
       "3                            -0.264207          0.207090   \n",
       "4                            -1.358432          1.046996   \n",
       "...                                ...               ...   \n",
       "39639                        -0.060357          0.207090   \n",
       "39640                         1.915979          0.207090   \n",
       "39641                        -0.491646          1.335872   \n",
       "39642                         0.023808          0.329067   \n",
       "39643                         1.540148         -1.696325   \n",
       "\n",
       "       rank( num_self_hrefs)   num_imgs   num_videos  \\\n",
       "0                  -0.247319        1.0          0.0   \n",
       "1                  -0.770293        1.0          0.0   \n",
       "2                  -0.770293        1.0          0.0   \n",
       "3                  -1.494860        1.0          0.0   \n",
       "4                   2.268357       20.0          0.0   \n",
       "...                      ...        ...          ...   \n",
       "39639               1.378593        1.0          1.0   \n",
       "39640               1.378593        3.0         48.0   \n",
       "39641              -0.770293       12.0          1.0   \n",
       "39642              -0.770293        1.0          0.0   \n",
       "39643              -0.770293        0.0          2.0   \n",
       "\n",
       "       rank( average_token_length)  rank( num_keywords)  \\\n",
       "0                         0.060832            -1.077791   \n",
       "1                         0.874264            -1.654145   \n",
       "2                        -0.983430            -0.561454   \n",
       "3                        -0.947209            -0.086922   \n",
       "4                         0.069322            -0.086922   \n",
       "...                            ...                  ...   \n",
       "39639                    -0.507837             0.343989   \n",
       "39640                    -0.944538            -0.086922   \n",
       "39641                     1.415071             0.343989   \n",
       "39642                     1.082436            -1.077791   \n",
       "39643                    -0.700679            -1.654145   \n",
       "\n",
       "        data_channel_is_lifestyle   data_channel_is_entertainment  \\\n",
       "0                             0.0                             1.0   \n",
       "1                             0.0                             0.0   \n",
       "2                             0.0                             0.0   \n",
       "3                             0.0                             1.0   \n",
       "4                             0.0                             0.0   \n",
       "...                           ...                             ...   \n",
       "39639                         0.0                             0.0   \n",
       "39640                         0.0                             0.0   \n",
       "39641                         0.0                             0.0   \n",
       "39642                         0.0                             0.0   \n",
       "39643                         0.0                             1.0   \n",
       "\n",
       "        data_channel_is_bus   data_channel_is_socmed   data_channel_is_tech  \\\n",
       "0                       0.0                      0.0                    0.0   \n",
       "1                       1.0                      0.0                    0.0   \n",
       "2                       1.0                      0.0                    0.0   \n",
       "3                       0.0                      0.0                    0.0   \n",
       "4                       0.0                      0.0                    1.0   \n",
       "...                     ...                      ...                    ...   \n",
       "39639                   0.0                      0.0                    1.0   \n",
       "39640                   0.0                      1.0                    0.0   \n",
       "39641                   0.0                      0.0                    0.0   \n",
       "39642                   0.0                      0.0                    0.0   \n",
       "39643                   0.0                      0.0                    0.0   \n",
       "\n",
       "        data_channel_is_world   kw_min_min  rank( kw_max_min)  \\\n",
       "0                         0.0          0.0          -2.314162   \n",
       "1                         0.0          0.0          -2.314162   \n",
       "2                         0.0          0.0          -2.314162   \n",
       "3                         0.0          0.0          -2.314162   \n",
       "4                         0.0          0.0          -2.314162   \n",
       "...                       ...          ...                ...   \n",
       "39639                     0.0         -1.0           0.024409   \n",
       "39640                     0.0         -1.0          -0.111863   \n",
       "39641                     0.0         -1.0           0.072048   \n",
       "39642                     1.0         -1.0          -2.314162   \n",
       "39643                     0.0         -1.0          -1.622922   \n",
       "\n",
       "       rank( kw_avg_min)   kw_min_max   kw_max_max  rank( kw_avg_max)  \\\n",
       "0              -2.013451          0.0          0.0          -3.091313   \n",
       "1              -2.013451          0.0          0.0          -3.091313   \n",
       "2              -2.013451          0.0          0.0          -3.091313   \n",
       "3              -2.013451          0.0          0.0          -3.091313   \n",
       "4              -2.013451          0.0          0.0          -3.091313   \n",
       "...                  ...          ...          ...                ...   \n",
       "39639          -0.424676      26900.0     843300.0           0.911184   \n",
       "39640          -0.343553       6500.0     843300.0          -0.463864   \n",
       "39641          -0.460873       6200.0     843300.0           0.404934   \n",
       "39642          -2.375909          0.0     843300.0           0.081465   \n",
       "39643          -1.749738     205600.0     843300.0           0.859487   \n",
       "\n",
       "        kw_min_avg  rank( kw_max_avg)  rank( kw_avg_avg)  \\\n",
       "0         0.000000          -3.091313          -3.091313   \n",
       "1         0.000000          -3.091313          -3.091313   \n",
       "2         0.000000          -3.091313          -3.091313   \n",
       "3         0.000000          -3.091313          -3.091313   \n",
       "4         0.000000          -3.091313          -3.091313   \n",
       "...            ...                ...                ...   \n",
       "39639  2514.742857          -0.200666           0.179677   \n",
       "39640  1664.267857           0.457255           0.522204   \n",
       "39641  1753.882353           0.855287           1.068122   \n",
       "39642     0.000000          -1.198484          -1.659634   \n",
       "39643  3035.080555          -0.473319           0.424711   \n",
       "\n",
       "       rank( self_reference_min_shares)  rank( self_reference_max_shares)  \\\n",
       "0                             -0.809729                         -0.897243   \n",
       "1                             -1.337803                         -1.337726   \n",
       "2                             -0.314418                         -0.753138   \n",
       "3                             -1.337803                         -1.337726   \n",
       "4                             -0.768720                          1.144183   \n",
       "...                                 ...                               ...   \n",
       "39639                          1.547643                          1.792045   \n",
       "39640                          0.512085                         -0.200537   \n",
       "39641                          0.159376                         -0.483671   \n",
       "39642                         -0.842009                         -0.902979   \n",
       "39643                          0.512085                         -0.200537   \n",
       "\n",
       "       rank( self_reference_avg_sharess)   weekday_is_monday  \\\n",
       "0                              -0.895353                 1.0   \n",
       "1                              -1.337803                 1.0   \n",
       "2                              -0.722589                 1.0   \n",
       "3                              -1.337803                 1.0   \n",
       "4                               0.294747                 1.0   \n",
       "...                                  ...                 ...   \n",
       "39639                           1.960439                 0.0   \n",
       "39640                          -0.045952                 0.0   \n",
       "39641                          -0.385722                 0.0   \n",
       "39642                          -0.902124                 0.0   \n",
       "39643                          -0.045952                 0.0   \n",
       "\n",
       "        weekday_is_tuesday   weekday_is_wednesday   weekday_is_thursday  \\\n",
       "0                      0.0                    0.0                   0.0   \n",
       "1                      0.0                    0.0                   0.0   \n",
       "2                      0.0                    0.0                   0.0   \n",
       "3                      0.0                    0.0                   0.0   \n",
       "4                      0.0                    0.0                   0.0   \n",
       "...                    ...                    ...                   ...   \n",
       "39639                  0.0                    1.0                   0.0   \n",
       "39640                  0.0                    1.0                   0.0   \n",
       "39641                  0.0                    1.0                   0.0   \n",
       "39642                  0.0                    1.0                   0.0   \n",
       "39643                  0.0                    1.0                   0.0   \n",
       "\n",
       "        weekday_is_friday   weekday_is_saturday   weekday_is_sunday  \\\n",
       "0                     0.0                   0.0                 0.0   \n",
       "1                     0.0                   0.0                 0.0   \n",
       "2                     0.0                   0.0                 0.0   \n",
       "3                     0.0                   0.0                 0.0   \n",
       "4                     0.0                   0.0                 0.0   \n",
       "...                   ...                   ...                 ...   \n",
       "39639                 0.0                   0.0                 0.0   \n",
       "39640                 0.0                   0.0                 0.0   \n",
       "39641                 0.0                   0.0                 0.0   \n",
       "39642                 0.0                   0.0                 0.0   \n",
       "39643                 0.0                   0.0                 0.0   \n",
       "\n",
       "        is_weekend  rank( LDA_00)  rank( LDA_01)  rank( LDA_02)  \\\n",
       "0              0.0       1.011874       1.107189       0.003762   \n",
       "1              0.0       1.506066       0.481113       0.164789   \n",
       "2              0.0       0.628018      -0.102896      -0.194219   \n",
       "3              0.0      -0.437130       1.172315       0.875191   \n",
       "4              0.0      -0.314651      -0.220448      -0.531720   \n",
       "...            ...            ...            ...            ...   \n",
       "39639          0.0      -0.686325      -0.822431       0.344962   \n",
       "39640          0.0      -0.229267      -0.398422       0.508340   \n",
       "39641          0.0       0.505177      -0.640777      -0.697652   \n",
       "39642          0.0       0.193188       0.241684       1.515967   \n",
       "39643          0.0       0.309937       1.816184       0.115936   \n",
       "\n",
       "       rank( LDA_03)  rank( LDA_04)  rank( global_subjectivity)  \\\n",
       "0           0.133906      -0.019697                    0.834551   \n",
       "1           0.215657       0.071541                   -1.206170   \n",
       "2          -0.319837       1.102533                    2.439542   \n",
       "3          -0.392816      -0.811837                   -0.291810   \n",
       "4          -0.626094       1.680026                    0.738234   \n",
       "...              ...            ...                         ...   \n",
       "39639      -0.966295       1.300303                    0.369968   \n",
       "39640       1.064995      -0.650512                    1.306810   \n",
       "39641       1.015044       0.250808                    0.697813   \n",
       "39642       0.021404      -0.064950                   -1.048091   \n",
       "39643       0.239210       0.067294                    0.792819   \n",
       "\n",
       "       rank( global_sentiment_polarity)  rank( global_rate_positive_words)  \\\n",
       "0                             -0.299737                           0.407371   \n",
       "1                              0.345029                           0.255150   \n",
       "2                              2.017790                           1.034661   \n",
       "3                             -0.208737                           0.150161   \n",
       "4                              1.686806                           1.934743   \n",
       "...                                 ...                                ...   \n",
       "39639                          0.265549                          -0.088382   \n",
       "39640                          0.854330                           0.039433   \n",
       "39641                         -0.997733                          -0.324699   \n",
       "39642                         -1.469914                          -1.181859   \n",
       "39643                         -0.159920                           1.407029   \n",
       "\n",
       "       rank( global_rate_negative_words)  rank( rate_positive_words)  \\\n",
       "0                              -0.186943                    0.425334   \n",
       "1                               0.038674                    0.167738   \n",
       "2                              -0.690612                    1.106431   \n",
       "3                               0.574307                   -0.284132   \n",
       "4                              -0.367261                    1.143818   \n",
       "...                                  ...                         ...   \n",
       "39639                          -0.099273                    0.086256   \n",
       "39640                          -0.730368                    0.757048   \n",
       "39641                           0.953765                   -0.792776   \n",
       "39642                           0.827942                   -1.331563   \n",
       "39643                          -0.296564                    0.920030   \n",
       "\n",
       "       rank( rate_negative_words)  rank( avg_positive_polarity)  \\\n",
       "0                       -0.344559                      0.257404   \n",
       "1                       -0.092096                     -0.900984   \n",
       "2                       -0.977397                      1.564511   \n",
       "3                        0.363172                      0.351546   \n",
       "4                       -1.009924                      0.671991   \n",
       "...                           ...                           ...   \n",
       "39639                   -0.011160                     -0.331371   \n",
       "39640                   -0.660623                      0.203796   \n",
       "39641                    0.900083                     -0.660859   \n",
       "39642                    1.541598                     -1.397816   \n",
       "39643                   -0.810958                     -1.304289   \n",
       "\n",
       "        min_positive_polarity   max_positive_polarity  \\\n",
       "0                    0.100000                    0.70   \n",
       "1                    0.033333                    0.70   \n",
       "2                    0.100000                    1.00   \n",
       "3                    0.136364                    0.80   \n",
       "4                    0.033333                    1.00   \n",
       "...                       ...                     ...   \n",
       "39639                0.100000                    0.75   \n",
       "39640                0.136364                    0.70   \n",
       "39641                0.136364                    0.50   \n",
       "39642                0.062500                    0.50   \n",
       "39643                0.100000                    0.50   \n",
       "\n",
       "       rank( avg_negative_polarity)  rank( min_negative_polarity)  \\\n",
       "0                         -0.840613                     -0.309042   \n",
       "1                          1.303623                      1.355812   \n",
       "2                         -1.637609                     -0.868165   \n",
       "3                         -0.984764                     -0.309042   \n",
       "4                          0.327633                      0.032505   \n",
       "...                             ...                           ...   \n",
       "39639                     -0.056493                      0.032505   \n",
       "39640                      0.416663                      0.394831   \n",
       "39641                     -0.892713                     -0.868165   \n",
       "39642                      0.475867                      0.032505   \n",
       "39643                      0.532339                      0.988570   \n",
       "\n",
       "        max_negative_polarity   title_subjectivity   title_sentiment_polarity  \\\n",
       "0                   -0.200000             0.500000                  -0.187500   \n",
       "1                   -0.100000             0.000000                   0.000000   \n",
       "2                   -0.133333             0.000000                   0.000000   \n",
       "3                   -0.166667             0.000000                   0.000000   \n",
       "4                   -0.050000             0.454545                   0.136364   \n",
       "...                       ...                  ...                        ...   \n",
       "39639               -0.125000             0.100000                   0.000000   \n",
       "39640               -0.100000             0.300000                   1.000000   \n",
       "39641               -0.166667             0.454545                   0.136364   \n",
       "39642               -0.012500             0.000000                   0.000000   \n",
       "39643               -0.200000             0.333333                   0.250000   \n",
       "\n",
       "        abs_title_subjectivity   abs_title_sentiment_polarity   shares  \n",
       "0                     0.000000                       0.187500      593  \n",
       "1                     0.500000                       0.000000      711  \n",
       "2                     0.500000                       0.000000     1500  \n",
       "3                     0.500000                       0.000000     1200  \n",
       "4                     0.045455                       0.136364      505  \n",
       "...                        ...                            ...      ...  \n",
       "39639                 0.400000                       0.000000     1800  \n",
       "39640                 0.200000                       1.000000     1900  \n",
       "39641                 0.045455                       0.136364     1900  \n",
       "39642                 0.500000                       0.000000     1100  \n",
       "39643                 0.166667                       0.250000     1300  \n",
       "\n",
       "[39644 rows x 60 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read preprocessed news dataset\n",
    "news_df = pd.read_csv('./prep_news_data.csv')\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Neural Network class with flexible settings\n",
    "class FlexibleRegressionNN(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_layers_sizes: list, dropout_rate: float) -> None:\n",
    "        super(FlexibleRegressionNN, self).__init__()\n",
    "        layers = list()\n",
    "\n",
    "        # Define first and n-1 hidden layers\n",
    "        neuron_num = input_size\n",
    "        for size in hidden_layers_sizes:\n",
    "            layers.append(nn.Linear(neuron_num, size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            neuron_num = size\n",
    "\n",
    "        layers.append(nn.Linear(neuron_num, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    # Define forward loop for NN\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.0001615109022571731\n",
      "  Params:\n",
      "    num_hidden_layers: 3\n",
      "    layer_0_size: 223\n",
      "    layer_1_size: 64\n",
      "    layer_2_size: 194\n",
      "    dropout_rate: 0.11419484328966484\n",
      "    learning_rate: 0.00017486754285944678\n",
      "    batch_size: 32\n",
      "    epochs: 29\n"
     ]
    }
   ],
   "source": [
    "# Getting the best hyperparameters\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:41:44,307] A new study created in memory with name: no-name-4506028c-3372-4fdd-9420-670390ee4b69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Train Loss: 0.000843, Test Loss: 0.000179\n",
      "Epoch 2/8, Train Loss: 0.000291, Test Loss: 0.000173\n",
      "Epoch 3/8, Train Loss: 0.000221, Test Loss: 0.000172\n",
      "Epoch 4/8, Train Loss: 0.000200, Test Loss: 0.000171\n",
      "Epoch 5/8, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 6/8, Train Loss: 0.000195, Test Loss: 0.000170\n",
      "Epoch 7/8, Train Loss: 0.000195, Test Loss: 0.000171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:41:53,206] Trial 0 finished with value: 0.0001695358608472933 and parameters: {'num_hidden_layers': 6, 'layer_0_size': 151, 'layer_1_size': 105, 'layer_2_size': 141, 'layer_3_size': 150, 'layer_4_size': 200, 'layer_5_size': 57, 'dropout_rate': 0.39609257146663823, 'learning_rate': 0.0006249147375130159, 'batch_size': 64, 'epochs': 8}. Best is trial 0 with value: 0.0001695358608472933.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/8, Train Loss: 0.000195, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37, Train Loss: 0.010939, Test Loss: 0.004812\n",
      "Epoch 2/37, Train Loss: 0.001849, Test Loss: 0.000285\n",
      "Epoch 3/37, Train Loss: 0.000950, Test Loss: 0.000261\n",
      "Epoch 4/37, Train Loss: 0.000809, Test Loss: 0.000264\n",
      "Epoch 5/37, Train Loss: 0.000719, Test Loss: 0.000265\n",
      "Epoch 6/37, Train Loss: 0.000638, Test Loss: 0.000272\n",
      "Epoch 7/37, Train Loss: 0.000598, Test Loss: 0.000277\n",
      "Epoch 8/37, Train Loss: 0.000554, Test Loss: 0.000284\n",
      "Epoch 9/37, Train Loss: 0.000527, Test Loss: 0.000298\n",
      "Epoch 10/37, Train Loss: 0.000509, Test Loss: 0.000290\n",
      "Epoch 11/37, Train Loss: 0.000488, Test Loss: 0.000289\n",
      "Epoch 12/37, Train Loss: 0.000464, Test Loss: 0.000284\n",
      "Epoch 13/37, Train Loss: 0.000453, Test Loss: 0.000262\n",
      "Epoch 14/37, Train Loss: 0.000438, Test Loss: 0.000274\n",
      "Epoch 15/37, Train Loss: 0.000429, Test Loss: 0.000265\n",
      "Epoch 16/37, Train Loss: 0.000418, Test Loss: 0.000262\n",
      "Epoch 17/37, Train Loss: 0.000408, Test Loss: 0.000272\n",
      "Epoch 18/37, Train Loss: 0.000402, Test Loss: 0.000265\n",
      "Epoch 19/37, Train Loss: 0.000400, Test Loss: 0.000271\n",
      "Epoch 20/37, Train Loss: 0.000388, Test Loss: 0.000259\n",
      "Epoch 21/37, Train Loss: 0.000380, Test Loss: 0.000255\n",
      "Epoch 22/37, Train Loss: 0.000375, Test Loss: 0.000238\n",
      "Epoch 23/37, Train Loss: 0.000369, Test Loss: 0.000248\n",
      "Epoch 24/37, Train Loss: 0.000362, Test Loss: 0.000241\n",
      "Epoch 25/37, Train Loss: 0.000361, Test Loss: 0.000230\n",
      "Epoch 26/37, Train Loss: 0.000357, Test Loss: 0.000220\n",
      "Epoch 27/37, Train Loss: 0.000353, Test Loss: 0.000225\n",
      "Epoch 28/37, Train Loss: 0.000344, Test Loss: 0.000223\n",
      "Epoch 29/37, Train Loss: 0.000341, Test Loss: 0.000222\n",
      "Epoch 30/37, Train Loss: 0.000336, Test Loss: 0.000213\n",
      "Epoch 31/37, Train Loss: 0.000329, Test Loss: 0.000211\n",
      "Epoch 32/37, Train Loss: 0.000328, Test Loss: 0.000212\n",
      "Epoch 33/37, Train Loss: 0.000325, Test Loss: 0.000207\n",
      "Epoch 34/37, Train Loss: 0.000321, Test Loss: 0.000206\n",
      "Epoch 35/37, Train Loss: 0.000317, Test Loss: 0.000202\n",
      "Epoch 36/37, Train Loss: 0.000310, Test Loss: 0.000202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:42:07,245] Trial 1 finished with value: 0.0002022894221872482 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 98, 'layer_1_size': 169, 'layer_2_size': 169, 'layer_3_size': 88, 'layer_4_size': 51, 'dropout_rate': 0.23049688330889093, 'learning_rate': 2.5166582695071884e-05, 'batch_size': 256, 'epochs': 37}. Best is trial 0 with value: 0.0001695358608472933.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/37, Train Loss: 0.000310, Test Loss: 0.000202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.000537, Test Loss: 0.000171\n",
      "Epoch 2/20, Train Loss: 0.000198, Test Loss: 0.000170\n",
      "Epoch 3/20, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 4/20, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 5/20, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 6/20, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 7/20, Train Loss: 0.000196, Test Loss: 0.000172\n",
      "Epoch 8/20, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 9/20, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 10/20, Train Loss: 0.000196, Test Loss: 0.000171\n",
      "Epoch 11/20, Train Loss: 0.000194, Test Loss: 0.000169\n",
      "Epoch 12/20, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 13/20, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 14/20, Train Loss: 0.000195, Test Loss: 0.000171\n",
      "Epoch 15/20, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 16/20, Train Loss: 0.000195, Test Loss: 0.000170\n",
      "Epoch 17/20, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 18/20, Train Loss: 0.000195, Test Loss: 0.000174\n",
      "Epoch 19/20, Train Loss: 0.000196, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:42:11,937] Trial 2 finished with value: 0.0001670846314599687 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 72, 'layer_1_size': 80, 'dropout_rate': 0.4162021331760887, 'learning_rate': 0.005532839067392692, 'batch_size': 128, 'epochs': 20}. Best is trial 2 with value: 0.0001670846314599687.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Train Loss: 0.000196, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29, Train Loss: 0.000269, Test Loss: 0.000173\n",
      "Epoch 2/29, Train Loss: 0.000200, Test Loss: 0.000168\n",
      "Epoch 3/29, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 4/29, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 5/29, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 6/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 8/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 10/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 15/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/29, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 18/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/29, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 20/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/29, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 22/29, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 23/29, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 24/29, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 25/29, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 26/29, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 27/29, Train Loss: 0.000185, Test Loss: 0.000167\n",
      "Epoch 28/29, Train Loss: 0.000184, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:42:25,698] Trial 3 finished with value: 0.0001643245242128673 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 156, 'layer_1_size': 166, 'layer_2_size': 75, 'dropout_rate': 0.19791418479424602, 'learning_rate': 0.00016439484762322107, 'batch_size': 64, 'epochs': 29}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29, Train Loss: 0.000183, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Train Loss: 0.006139, Test Loss: 0.000497\n",
      "Epoch 2/15, Train Loss: 0.001353, Test Loss: 0.000313\n",
      "Epoch 3/15, Train Loss: 0.001127, Test Loss: 0.000275\n",
      "Epoch 4/15, Train Loss: 0.000990, Test Loss: 0.000239\n",
      "Epoch 5/15, Train Loss: 0.000872, Test Loss: 0.000224\n",
      "Epoch 6/15, Train Loss: 0.000779, Test Loss: 0.000216\n",
      "Epoch 7/15, Train Loss: 0.000699, Test Loss: 0.000202\n",
      "Epoch 8/15, Train Loss: 0.000630, Test Loss: 0.000187\n",
      "Epoch 9/15, Train Loss: 0.000569, Test Loss: 0.000183\n",
      "Epoch 10/15, Train Loss: 0.000513, Test Loss: 0.000175\n",
      "Epoch 11/15, Train Loss: 0.000463, Test Loss: 0.000172\n",
      "Epoch 12/15, Train Loss: 0.000427, Test Loss: 0.000170\n",
      "Epoch 13/15, Train Loss: 0.000398, Test Loss: 0.000170\n",
      "Epoch 14/15, Train Loss: 0.000375, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:42:38,677] Trial 4 finished with value: 0.00017029924257375598 and parameters: {'num_hidden_layers': 9, 'layer_0_size': 138, 'layer_1_size': 60, 'layer_2_size': 59, 'layer_3_size': 221, 'layer_4_size': 89, 'layer_5_size': 229, 'layer_6_size': 134, 'layer_7_size': 123, 'layer_8_size': 169, 'dropout_rate': 0.4079187926394938, 'learning_rate': 1.6264650185635673e-05, 'batch_size': 128, 'epochs': 15}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15, Train Loss: 0.000350, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22, Train Loss: 0.000410, Test Loss: 0.000172\n",
      "Epoch 2/22, Train Loss: 0.000213, Test Loss: 0.000180\n",
      "Epoch 3/22, Train Loss: 0.000202, Test Loss: 0.000172\n",
      "Epoch 4/22, Train Loss: 0.000198, Test Loss: 0.000170\n",
      "Epoch 5/22, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 6/22, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 7/22, Train Loss: 0.000195, Test Loss: 0.000170\n",
      "Epoch 8/22, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 9/22, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 10/22, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 11/22, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 12/22, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 13/22, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 14/22, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 15/22, Train Loss: 0.000193, Test Loss: 0.000169\n",
      "Epoch 16/22, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 17/22, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 18/22, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 19/22, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 20/22, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 21/22, Train Loss: 0.000193, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:42:52,209] Trial 5 finished with value: 0.00016803314458464286 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 113, 'layer_1_size': 228, 'layer_2_size': 37, 'layer_3_size': 194, 'layer_4_size': 213, 'dropout_rate': 0.34392812517622406, 'learning_rate': 0.002406062686071093, 'batch_size': 256, 'epochs': 22}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/22, Train Loss: 0.000193, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23, Train Loss: 0.000762, Test Loss: 0.000262\n",
      "Epoch 2/23, Train Loss: 0.000383, Test Loss: 0.000224\n",
      "Epoch 3/23, Train Loss: 0.000307, Test Loss: 0.000215\n",
      "Epoch 4/23, Train Loss: 0.000276, Test Loss: 0.000209\n",
      "Epoch 5/23, Train Loss: 0.000256, Test Loss: 0.000217\n",
      "Epoch 6/23, Train Loss: 0.000246, Test Loss: 0.000212\n",
      "Epoch 7/23, Train Loss: 0.000239, Test Loss: 0.000195\n",
      "Epoch 8/23, Train Loss: 0.000231, Test Loss: 0.000185\n",
      "Epoch 9/23, Train Loss: 0.000227, Test Loss: 0.000185\n",
      "Epoch 10/23, Train Loss: 0.000221, Test Loss: 0.000191\n",
      "Epoch 11/23, Train Loss: 0.000218, Test Loss: 0.000185\n",
      "Epoch 12/23, Train Loss: 0.000214, Test Loss: 0.000184\n",
      "Epoch 13/23, Train Loss: 0.000212, Test Loss: 0.000182\n",
      "Epoch 14/23, Train Loss: 0.000208, Test Loss: 0.000177\n",
      "Epoch 15/23, Train Loss: 0.000206, Test Loss: 0.000178\n",
      "Epoch 16/23, Train Loss: 0.000204, Test Loss: 0.000177\n",
      "Epoch 17/23, Train Loss: 0.000203, Test Loss: 0.000179\n",
      "Epoch 18/23, Train Loss: 0.000203, Test Loss: 0.000176\n",
      "Epoch 19/23, Train Loss: 0.000200, Test Loss: 0.000173\n",
      "Epoch 20/23, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 21/23, Train Loss: 0.000199, Test Loss: 0.000172\n",
      "Epoch 22/23, Train Loss: 0.000197, Test Loss: 0.000171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:43:02,595] Trial 6 finished with value: 0.00017039395259915534 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 232, 'layer_1_size': 167, 'layer_2_size': 201, 'dropout_rate': 0.3259262911673347, 'learning_rate': 7.203871092784932e-05, 'batch_size': 128, 'epochs': 23}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/23, Train Loss: 0.000196, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.002077, Test Loss: 0.001018\n",
      "Epoch 2/5, Train Loss: 0.000835, Test Loss: 0.000335\n",
      "Epoch 3/5, Train Loss: 0.000556, Test Loss: 0.000203\n",
      "Epoch 4/5, Train Loss: 0.000518, Test Loss: 0.000183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:43:08,525] Trial 7 finished with value: 0.0001811019636724884 and parameters: {'num_hidden_layers': 10, 'layer_0_size': 57, 'layer_1_size': 248, 'layer_2_size': 153, 'layer_3_size': 121, 'layer_4_size': 34, 'layer_5_size': 61, 'layer_6_size': 41, 'layer_7_size': 70, 'layer_8_size': 139, 'layer_9_size': 195, 'dropout_rate': 0.24971210537033037, 'learning_rate': 2.078570260601894e-06, 'batch_size': 64, 'epochs': 5}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.000507, Test Loss: 0.000181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.000288, Test Loss: 0.000192\n",
      "Epoch 2/10, Train Loss: 0.000206, Test Loss: 0.000181\n",
      "Epoch 3/10, Train Loss: 0.000200, Test Loss: 0.000173\n",
      "Epoch 4/10, Train Loss: 0.000196, Test Loss: 0.000171\n",
      "Epoch 5/10, Train Loss: 0.000198, Test Loss: 0.000172\n",
      "Epoch 6/10, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 7/10, Train Loss: 0.000196, Test Loss: 0.000172\n",
      "Epoch 8/10, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 9/10, Train Loss: 0.000195, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:43:22,292] Trial 8 finished with value: 0.00016957783343734206 and parameters: {'num_hidden_layers': 6, 'layer_0_size': 208, 'layer_1_size': 245, 'layer_2_size': 137, 'layer_3_size': 127, 'layer_4_size': 181, 'layer_5_size': 163, 'dropout_rate': 0.45882572254986065, 'learning_rate': 0.00041165970931925186, 'batch_size': 256, 'epochs': 10}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.000195, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.000616, Test Loss: 0.000170\n",
      "Epoch 2/30, Train Loss: 0.000283, Test Loss: 0.000171\n",
      "Epoch 3/30, Train Loss: 0.000242, Test Loss: 0.000169\n",
      "Epoch 4/30, Train Loss: 0.000219, Test Loss: 0.000169\n",
      "Epoch 5/30, Train Loss: 0.000208, Test Loss: 0.000169\n",
      "Epoch 6/30, Train Loss: 0.000201, Test Loss: 0.000167\n",
      "Epoch 7/30, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 8/30, Train Loss: 0.000195, Test Loss: 0.000171\n",
      "Epoch 9/30, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 10/30, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 11/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/30, Train Loss: 0.000193, Test Loss: 0.000170\n",
      "Epoch 13/30, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 14/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 15/30, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 16/30, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 17/30, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 18/30, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 19/30, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 20/30, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 21/30, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 22/30, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 23/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 24/30, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 25/30, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 26/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 27/30, Train Loss: 0.000192, Test Loss: 0.000170\n",
      "Epoch 28/30, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 29/30, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:43:59,446] Trial 9 finished with value: 0.00016571329521661204 and parameters: {'num_hidden_layers': 9, 'layer_0_size': 226, 'layer_1_size': 233, 'layer_2_size': 171, 'layer_3_size': 79, 'layer_4_size': 103, 'layer_5_size': 101, 'layer_6_size': 40, 'layer_7_size': 187, 'layer_8_size': 63, 'dropout_rate': 0.17661630187124905, 'learning_rate': 0.0025196494593041283, 'batch_size': 256, 'epochs': 30}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.000193, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36, Train Loss: 0.008192, Test Loss: 0.004326\n",
      "Epoch 2/36, Train Loss: 0.002445, Test Loss: 0.000798\n",
      "Epoch 3/36, Train Loss: 0.000714, Test Loss: 0.000300\n",
      "Epoch 4/36, Train Loss: 0.000571, Test Loss: 0.000275\n",
      "Epoch 5/36, Train Loss: 0.000544, Test Loss: 0.000254\n",
      "Epoch 6/36, Train Loss: 0.000507, Test Loss: 0.000235\n",
      "Epoch 7/36, Train Loss: 0.000473, Test Loss: 0.000222\n",
      "Epoch 8/36, Train Loss: 0.000445, Test Loss: 0.000210\n",
      "Epoch 9/36, Train Loss: 0.000419, Test Loss: 0.000204\n",
      "Epoch 10/36, Train Loss: 0.000398, Test Loss: 0.000197\n",
      "Epoch 11/36, Train Loss: 0.000385, Test Loss: 0.000195\n",
      "Epoch 12/36, Train Loss: 0.000366, Test Loss: 0.000193\n",
      "Epoch 13/36, Train Loss: 0.000355, Test Loss: 0.000188\n",
      "Epoch 14/36, Train Loss: 0.000341, Test Loss: 0.000186\n",
      "Epoch 15/36, Train Loss: 0.000335, Test Loss: 0.000186\n",
      "Epoch 16/36, Train Loss: 0.000327, Test Loss: 0.000184\n",
      "Epoch 17/36, Train Loss: 0.000319, Test Loss: 0.000183\n",
      "Epoch 18/36, Train Loss: 0.000311, Test Loss: 0.000183\n",
      "Epoch 19/36, Train Loss: 0.000309, Test Loss: 0.000181\n",
      "Epoch 20/36, Train Loss: 0.000302, Test Loss: 0.000181\n",
      "Epoch 21/36, Train Loss: 0.000300, Test Loss: 0.000182\n",
      "Epoch 22/36, Train Loss: 0.000295, Test Loss: 0.000181\n",
      "Epoch 23/36, Train Loss: 0.000290, Test Loss: 0.000179\n",
      "Epoch 24/36, Train Loss: 0.000286, Test Loss: 0.000179\n",
      "Epoch 25/36, Train Loss: 0.000282, Test Loss: 0.000179\n",
      "Epoch 26/36, Train Loss: 0.000283, Test Loss: 0.000180\n",
      "Epoch 27/36, Train Loss: 0.000279, Test Loss: 0.000180\n",
      "Epoch 28/36, Train Loss: 0.000276, Test Loss: 0.000181\n",
      "Epoch 29/36, Train Loss: 0.000271, Test Loss: 0.000180\n",
      "Epoch 30/36, Train Loss: 0.000270, Test Loss: 0.000179\n",
      "Epoch 31/36, Train Loss: 0.000268, Test Loss: 0.000181\n",
      "Epoch 32/36, Train Loss: 0.000266, Test Loss: 0.000182\n",
      "Epoch 33/36, Train Loss: 0.000267, Test Loss: 0.000180\n",
      "Epoch 34/36, Train Loss: 0.000262, Test Loss: 0.000180\n",
      "Epoch 35/36, Train Loss: 0.000259, Test Loss: 0.000179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:44:51,596] Trial 10 finished with value: 0.00018030063860637272 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 176, 'layer_1_size': 132, 'layer_2_size': 85, 'dropout_rate': 0.10032723443459772, 'learning_rate': 1.1349606939753764e-06, 'batch_size': 32, 'epochs': 36}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/36, Train Loss: 0.000259, Test Loss: 0.000180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29, Train Loss: 0.000387, Test Loss: 0.000172\n",
      "Epoch 2/29, Train Loss: 0.000213, Test Loss: 0.000170\n",
      "Epoch 3/29, Train Loss: 0.000203, Test Loss: 0.000178\n",
      "Epoch 4/29, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 5/29, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 6/29, Train Loss: 0.000198, Test Loss: 0.000171\n",
      "Epoch 7/29, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 8/29, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 9/29, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 10/29, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 11/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/29, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 13/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 14/29, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 15/29, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 16/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 17/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 18/29, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 19/29, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 20/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 21/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 22/29, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 23/29, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 24/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 25/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 26/29, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 27/29, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 28/29, Train Loss: 0.000193, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:45:31,963] Trial 11 finished with value: 0.00016519005412778972 and parameters: {'num_hidden_layers': 8, 'layer_0_size': 255, 'layer_1_size': 202, 'layer_2_size': 248, 'layer_3_size': 39, 'layer_4_size': 122, 'layer_5_size': 115, 'layer_6_size': 38, 'layer_7_size': 237, 'dropout_rate': 0.14268698327024834, 'learning_rate': 0.0006527700075544653, 'batch_size': 64, 'epochs': 29}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29, Train Loss: 0.000192, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28, Train Loss: 0.000932, Test Loss: 0.000219\n",
      "Epoch 2/28, Train Loss: 0.000270, Test Loss: 0.000185\n",
      "Epoch 3/28, Train Loss: 0.000215, Test Loss: 0.000176\n",
      "Epoch 4/28, Train Loss: 0.000201, Test Loss: 0.000173\n",
      "Epoch 5/28, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 6/28, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 7/28, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 8/28, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 9/28, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 10/28, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 11/28, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 12/28, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 13/28, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 14/28, Train Loss: 0.000190, Test Loss: 0.000168\n",
      "Epoch 15/28, Train Loss: 0.000189, Test Loss: 0.000168\n",
      "Epoch 16/28, Train Loss: 0.000189, Test Loss: 0.000168\n",
      "Epoch 17/28, Train Loss: 0.000188, Test Loss: 0.000167\n",
      "Epoch 18/28, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 19/28, Train Loss: 0.000188, Test Loss: 0.000167\n",
      "Epoch 20/28, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 21/28, Train Loss: 0.000186, Test Loss: 0.000167\n",
      "Epoch 22/28, Train Loss: 0.000185, Test Loss: 0.000170\n",
      "Epoch 23/28, Train Loss: 0.000185, Test Loss: 0.000168\n",
      "Epoch 24/28, Train Loss: 0.000184, Test Loss: 0.000173\n",
      "Epoch 25/28, Train Loss: 0.000184, Test Loss: 0.000167\n",
      "Epoch 26/28, Train Loss: 0.000183, Test Loss: 0.000172\n",
      "Epoch 27/28, Train Loss: 0.000183, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:45:41,805] Trial 12 finished with value: 0.00016811090605892053 and parameters: {'num_hidden_layers': 1, 'layer_0_size': 186, 'dropout_rate': 0.11922905094967731, 'learning_rate': 0.0003120994527682614, 'batch_size': 64, 'epochs': 28}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/28, Train Loss: 0.000181, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.000237, Test Loss: 0.000170\n",
      "Epoch 2/30, Train Loss: 0.000203, Test Loss: 0.000169\n",
      "Epoch 3/30, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 4/30, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 5/30, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 6/30, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 7/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 8/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 10/30, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/30, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/30, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 13/30, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/30, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/30, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 16/30, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 17/30, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 18/30, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/30, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/30, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 21/30, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 22/30, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 23/30, Train Loss: 0.000188, Test Loss: 0.000167\n",
      "Epoch 24/30, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/30, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 26/30, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 27/30, Train Loss: 0.000184, Test Loss: 0.000169\n",
      "Epoch 28/30, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 29/30, Train Loss: 0.000182, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:46:35,137] Trial 13 finished with value: 0.00016570169274135907 and parameters: {'num_hidden_layers': 7, 'layer_0_size': 246, 'layer_1_size': 194, 'layer_2_size': 242, 'layer_3_size': 33, 'layer_4_size': 141, 'layer_5_size': 156, 'layer_6_size': 256, 'dropout_rate': 0.18090754256869374, 'learning_rate': 0.0001306463234559864, 'batch_size': 64, 'epochs': 30}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.000185, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33, Train Loss: 0.000240, Test Loss: 0.000170\n",
      "Epoch 2/33, Train Loss: 0.000203, Test Loss: 0.000170\n",
      "Epoch 3/33, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 4/33, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 5/33, Train Loss: 0.000196, Test Loss: 0.000173\n",
      "Epoch 6/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 7/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 8/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 9/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 10/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 11/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 12/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 13/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 14/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 15/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 16/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 17/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 18/33, Train Loss: 0.000196, Test Loss: 0.000172\n",
      "Epoch 19/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 20/33, Train Loss: 0.000196, Test Loss: 0.000172\n",
      "Epoch 21/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 22/33, Train Loss: 0.000196, Test Loss: 0.000173\n",
      "Epoch 23/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 24/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 25/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 26/33, Train Loss: 0.000196, Test Loss: 0.000172\n",
      "Epoch 27/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 28/33, Train Loss: 0.000196, Test Loss: 0.000175\n",
      "Epoch 29/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 30/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 31/33, Train Loss: 0.000196, Test Loss: 0.000171\n",
      "Epoch 32/33, Train Loss: 0.000196, Test Loss: 0.000171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:47:40,196] Trial 14 finished with value: 0.00016962181495816162 and parameters: {'num_hidden_layers': 8, 'layer_0_size': 191, 'layer_1_size': 196, 'layer_2_size': 253, 'layer_3_size': 32, 'layer_4_size': 255, 'layer_5_size': 219, 'layer_6_size': 121, 'layer_7_size': 239, 'dropout_rate': 0.1670298965612594, 'learning_rate': 0.0011052370638094933, 'batch_size': 64, 'epochs': 33}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/33, Train Loss: 0.000196, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 0.000357, Test Loss: 0.000171\n",
      "Epoch 2/25, Train Loss: 0.000234, Test Loss: 0.000169\n",
      "Epoch 3/25, Train Loss: 0.000215, Test Loss: 0.000169\n",
      "Epoch 4/25, Train Loss: 0.000209, Test Loss: 0.000170\n",
      "Epoch 5/25, Train Loss: 0.000204, Test Loss: 0.000171\n",
      "Epoch 6/25, Train Loss: 0.000202, Test Loss: 0.000175\n",
      "Epoch 7/25, Train Loss: 0.000200, Test Loss: 0.000169\n",
      "Epoch 8/25, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 9/25, Train Loss: 0.000198, Test Loss: 0.000167\n",
      "Epoch 10/25, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 11/25, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 12/25, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 13/25, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 14/25, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 15/25, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 16/25, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 17/25, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 18/25, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 19/25, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 20/25, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 21/25, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 22/25, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 23/25, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 24/25, Train Loss: 0.000192, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:48:13,943] Trial 15 finished with value: 0.0001649270315642899 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 38, 'layer_1_size': 128, 'layer_2_size': 108, 'layer_3_size': 256, 'dropout_rate': 0.24616758163652272, 'learning_rate': 6.349495880896758e-05, 'batch_size': 32, 'epochs': 25}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 0.000436, Test Loss: 0.000171\n",
      "Epoch 2/25, Train Loss: 0.000319, Test Loss: 0.000170\n",
      "Epoch 3/25, Train Loss: 0.000271, Test Loss: 0.000170\n",
      "Epoch 4/25, Train Loss: 0.000241, Test Loss: 0.000170\n",
      "Epoch 5/25, Train Loss: 0.000225, Test Loss: 0.000170\n",
      "Epoch 6/25, Train Loss: 0.000217, Test Loss: 0.000171\n",
      "Epoch 7/25, Train Loss: 0.000211, Test Loss: 0.000171\n",
      "Epoch 8/25, Train Loss: 0.000207, Test Loss: 0.000170\n",
      "Epoch 9/25, Train Loss: 0.000204, Test Loss: 0.000170\n",
      "Epoch 10/25, Train Loss: 0.000203, Test Loss: 0.000169\n",
      "Epoch 11/25, Train Loss: 0.000201, Test Loss: 0.000169\n",
      "Epoch 12/25, Train Loss: 0.000200, Test Loss: 0.000169\n",
      "Epoch 13/25, Train Loss: 0.000199, Test Loss: 0.000169\n",
      "Epoch 14/25, Train Loss: 0.000198, Test Loss: 0.000169\n",
      "Epoch 15/25, Train Loss: 0.000198, Test Loss: 0.000169\n",
      "Epoch 16/25, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 17/25, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 18/25, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 19/25, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 20/25, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 21/25, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 22/25, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 23/25, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 24/25, Train Loss: 0.000195, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:48:47,603] Trial 16 finished with value: 0.00016855361310545488 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 35, 'layer_1_size': 130, 'layer_2_size': 102, 'layer_3_size': 256, 'dropout_rate': 0.25985148851470485, 'learning_rate': 1.718656587456018e-05, 'batch_size': 32, 'epochs': 25}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Train Loss: 0.000195, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17, Train Loss: 0.001841, Test Loss: 0.000312\n",
      "Epoch 2/17, Train Loss: 0.001141, Test Loss: 0.000250\n",
      "Epoch 3/17, Train Loss: 0.000875, Test Loss: 0.000215\n",
      "Epoch 4/17, Train Loss: 0.000733, Test Loss: 0.000194\n",
      "Epoch 5/17, Train Loss: 0.000631, Test Loss: 0.000189\n",
      "Epoch 6/17, Train Loss: 0.000558, Test Loss: 0.000184\n",
      "Epoch 7/17, Train Loss: 0.000491, Test Loss: 0.000184\n",
      "Epoch 8/17, Train Loss: 0.000455, Test Loss: 0.000180\n",
      "Epoch 9/17, Train Loss: 0.000419, Test Loss: 0.000180\n",
      "Epoch 10/17, Train Loss: 0.000383, Test Loss: 0.000176\n",
      "Epoch 11/17, Train Loss: 0.000356, Test Loss: 0.000177\n",
      "Epoch 12/17, Train Loss: 0.000334, Test Loss: 0.000175\n",
      "Epoch 13/17, Train Loss: 0.000321, Test Loss: 0.000177\n",
      "Epoch 14/17, Train Loss: 0.000301, Test Loss: 0.000175\n",
      "Epoch 15/17, Train Loss: 0.000291, Test Loss: 0.000175\n",
      "Epoch 16/17, Train Loss: 0.000276, Test Loss: 0.000173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:49:02,371] Trial 17 finished with value: 0.00017230698282153225 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 150, 'layer_1_size': 33, 'layer_2_size': 105, 'dropout_rate': 0.2920816157783184, 'learning_rate': 6.068419699188056e-06, 'batch_size': 32, 'epochs': 17}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/17, Train Loss: 0.000268, Test Loss: 0.000172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26, Train Loss: 0.001597, Test Loss: 0.000308\n",
      "Epoch 2/26, Train Loss: 0.000419, Test Loss: 0.000220\n",
      "Epoch 3/26, Train Loss: 0.000282, Test Loss: 0.000190\n",
      "Epoch 4/26, Train Loss: 0.000236, Test Loss: 0.000180\n",
      "Epoch 5/26, Train Loss: 0.000213, Test Loss: 0.000172\n",
      "Epoch 6/26, Train Loss: 0.000202, Test Loss: 0.000170\n",
      "Epoch 7/26, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 8/26, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 9/26, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 10/26, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 11/26, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 12/26, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 13/26, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 14/26, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 15/26, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 16/26, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 17/26, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 18/26, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 19/26, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 20/26, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 21/26, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 22/26, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 23/26, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 24/26, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 25/26, Train Loss: 0.000189, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:49:12,975] Trial 18 finished with value: 0.00016532743814885238 and parameters: {'num_hidden_layers': 1, 'layer_0_size': 111, 'dropout_rate': 0.20594154286398622, 'learning_rate': 7.939957334420946e-05, 'batch_size': 32, 'epochs': 26}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/26, Train Loss: 0.000189, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39, Train Loss: 0.000298, Test Loss: 0.000179\n",
      "Epoch 2/39, Train Loss: 0.000207, Test Loss: 0.000178\n",
      "Epoch 3/39, Train Loss: 0.000199, Test Loss: 0.000173\n",
      "Epoch 4/39, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 5/39, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 6/39, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 7/39, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 8/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/39, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 10/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 15/39, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 16/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 18/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 19/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 21/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 22/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 23/39, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 24/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 25/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 26/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 27/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 28/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 29/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 30/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 31/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 32/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 33/39, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 34/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 35/39, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 36/39, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 37/39, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 38/39, Train Loss: 0.000192, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:49:59,169] Trial 19 finished with value: 0.00016568229667948418 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 86, 'layer_1_size': 159, 'layer_2_size': 81, 'layer_3_size': 184, 'dropout_rate': 0.28635439408409236, 'learning_rate': 0.00018110071689293102, 'batch_size': 32, 'epochs': 39}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/39, Train Loss: 0.000191, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18, Train Loss: 0.000622, Test Loss: 0.000193\n",
      "Epoch 2/18, Train Loss: 0.000278, Test Loss: 0.000193\n",
      "Epoch 3/18, Train Loss: 0.000230, Test Loss: 0.000177\n",
      "Epoch 4/18, Train Loss: 0.000212, Test Loss: 0.000174\n",
      "Epoch 5/18, Train Loss: 0.000203, Test Loss: 0.000170\n",
      "Epoch 6/18, Train Loss: 0.000199, Test Loss: 0.000169\n",
      "Epoch 7/18, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 8/18, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 9/18, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 10/18, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 11/18, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 12/18, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 13/18, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 14/18, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 15/18, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/18, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 17/18, Train Loss: 0.000192, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:50:15,170] Trial 20 finished with value: 0.00016484776797241348 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 136, 'layer_1_size': 104, 'dropout_rate': 0.21177971684438185, 'learning_rate': 3.6891687469379244e-05, 'batch_size': 32, 'epochs': 18}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/18, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18, Train Loss: 0.000568, Test Loss: 0.000181\n",
      "Epoch 2/18, Train Loss: 0.000247, Test Loss: 0.000174\n",
      "Epoch 3/18, Train Loss: 0.000214, Test Loss: 0.000171\n",
      "Epoch 4/18, Train Loss: 0.000203, Test Loss: 0.000169\n",
      "Epoch 5/18, Train Loss: 0.000198, Test Loss: 0.000169\n",
      "Epoch 6/18, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 7/18, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 8/18, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 9/18, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 10/18, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 11/18, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 12/18, Train Loss: 0.000209, Test Loss: 0.000166\n",
      "Epoch 13/18, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/18, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/18, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 16/18, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 17/18, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:50:27,518] Trial 21 finished with value: 0.00016556778399123482 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 126, 'layer_1_size': 106, 'dropout_rate': 0.2119464427359402, 'learning_rate': 4.3051617312437873e-05, 'batch_size': 32, 'epochs': 18}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/18, Train Loss: 0.000191, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14, Train Loss: 0.000506, Test Loss: 0.000172\n",
      "Epoch 2/14, Train Loss: 0.000401, Test Loss: 0.000169\n",
      "Epoch 3/14, Train Loss: 0.000347, Test Loss: 0.000169\n",
      "Epoch 4/14, Train Loss: 0.000315, Test Loss: 0.000169\n",
      "Epoch 5/14, Train Loss: 0.000291, Test Loss: 0.000169\n",
      "Epoch 6/14, Train Loss: 0.000273, Test Loss: 0.000169\n",
      "Epoch 7/14, Train Loss: 0.000263, Test Loss: 0.000169\n",
      "Epoch 8/14, Train Loss: 0.000252, Test Loss: 0.000169\n",
      "Epoch 9/14, Train Loss: 0.000245, Test Loss: 0.000169\n",
      "Epoch 10/14, Train Loss: 0.000240, Test Loss: 0.000169\n",
      "Epoch 11/14, Train Loss: 0.000235, Test Loss: 0.000169\n",
      "Epoch 12/14, Train Loss: 0.000231, Test Loss: 0.000169\n",
      "Epoch 13/14, Train Loss: 0.000226, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:50:46,031] Trial 22 finished with value: 0.00016902340115896021 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 166, 'layer_1_size': 100, 'layer_2_size': 114, 'layer_3_size': 237, 'dropout_rate': 0.2527022956811284, 'learning_rate': 6.393284813180709e-06, 'batch_size': 32, 'epochs': 14}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/14, Train Loss: 0.000224, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22, Train Loss: 0.001145, Test Loss: 0.000199\n",
      "Epoch 2/22, Train Loss: 0.000470, Test Loss: 0.000180\n",
      "Epoch 3/22, Train Loss: 0.000331, Test Loss: 0.000176\n",
      "Epoch 4/22, Train Loss: 0.000268, Test Loss: 0.000176\n",
      "Epoch 5/22, Train Loss: 0.000237, Test Loss: 0.000170\n",
      "Epoch 6/22, Train Loss: 0.000220, Test Loss: 0.000169\n",
      "Epoch 7/22, Train Loss: 0.000210, Test Loss: 0.000169\n",
      "Epoch 8/22, Train Loss: 0.000205, Test Loss: 0.000169\n",
      "Epoch 9/22, Train Loss: 0.000201, Test Loss: 0.000169\n",
      "Epoch 10/22, Train Loss: 0.000199, Test Loss: 0.000169\n",
      "Epoch 11/22, Train Loss: 0.000216, Test Loss: 0.000168\n",
      "Epoch 12/22, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 13/22, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 14/22, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 15/22, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 16/22, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 17/22, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 18/22, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 19/22, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 20/22, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 21/22, Train Loss: 0.000193, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:51:03,387] Trial 23 finished with value: 0.00016666870602336764 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 34, 'layer_1_size': 142, 'dropout_rate': 0.20713961975601985, 'learning_rate': 3.709016322694123e-05, 'batch_size': 32, 'epochs': 22}. Best is trial 3 with value: 0.0001643245242128673.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/22, Train Loss: 0.000193, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33, Train Loss: 0.000231, Test Loss: 0.000170\n",
      "Epoch 2/33, Train Loss: 0.000200, Test Loss: 0.000171\n",
      "Epoch 3/33, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 4/33, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 5/33, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 6/33, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/33, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 8/33, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 9/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 11/33, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 12/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/33, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/33, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 18/33, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 19/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/33, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 21/33, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 22/33, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 23/33, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 24/33, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 25/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 26/33, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 27/33, Train Loss: 0.000188, Test Loss: 0.000163\n",
      "Epoch 28/33, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 29/33, Train Loss: 0.000188, Test Loss: 0.000163\n",
      "Epoch 30/33, Train Loss: 0.000186, Test Loss: 0.000163\n",
      "Epoch 31/33, Train Loss: 0.000184, Test Loss: 0.000167\n",
      "Epoch 32/33, Train Loss: 0.000186, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:51:36,706] Trial 24 finished with value: 0.0001642065350682192 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 74, 'layer_1_size': 127, 'layer_2_size': 46, 'dropout_rate': 0.15321517228850356, 'learning_rate': 0.00018320690287178335, 'batch_size': 32, 'epochs': 33}. Best is trial 24 with value: 0.0001642065350682192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/33, Train Loss: 0.000182, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34, Train Loss: 0.000888, Test Loss: 0.000208\n",
      "Epoch 2/34, Train Loss: 0.000239, Test Loss: 0.000177\n",
      "Epoch 3/34, Train Loss: 0.000204, Test Loss: 0.000170\n",
      "Epoch 4/34, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 5/34, Train Loss: 0.000194, Test Loss: 0.000169\n",
      "Epoch 6/34, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 7/34, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 8/34, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/34, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 10/34, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 11/34, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 12/34, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 13/34, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 14/34, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 15/34, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 16/34, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 17/34, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 18/34, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 19/34, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 20/34, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 21/34, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 22/34, Train Loss: 0.000187, Test Loss: 0.000169\n",
      "Epoch 23/34, Train Loss: 0.000187, Test Loss: 0.000173\n",
      "Epoch 24/34, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 25/34, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 26/34, Train Loss: 0.000186, Test Loss: 0.000167\n",
      "Epoch 27/34, Train Loss: 0.000185, Test Loss: 0.000166\n",
      "Epoch 28/34, Train Loss: 0.000185, Test Loss: 0.000167\n",
      "Epoch 29/34, Train Loss: 0.000185, Test Loss: 0.000167\n",
      "Epoch 30/34, Train Loss: 0.000185, Test Loss: 0.000167\n",
      "Epoch 31/34, Train Loss: 0.000183, Test Loss: 0.000167\n",
      "Epoch 32/34, Train Loss: 0.000183, Test Loss: 0.000166\n",
      "Epoch 33/34, Train Loss: 0.000183, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:51:54,781] Trial 25 finished with value: 0.0001704876383611566 and parameters: {'num_hidden_layers': 1, 'layer_0_size': 132, 'dropout_rate': 0.1495004868961642, 'learning_rate': 0.00019195005728732512, 'batch_size': 32, 'epochs': 34}. Best is trial 24 with value: 0.0001642065350682192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/34, Train Loss: 0.000182, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32, Train Loss: 0.001391, Test Loss: 0.000361\n",
      "Epoch 2/32, Train Loss: 0.000908, Test Loss: 0.000263\n",
      "Epoch 3/32, Train Loss: 0.000712, Test Loss: 0.000227\n",
      "Epoch 4/32, Train Loss: 0.000589, Test Loss: 0.000210\n",
      "Epoch 5/32, Train Loss: 0.000516, Test Loss: 0.000201\n",
      "Epoch 6/32, Train Loss: 0.000462, Test Loss: 0.000195\n",
      "Epoch 7/32, Train Loss: 0.000422, Test Loss: 0.000191\n",
      "Epoch 8/32, Train Loss: 0.000389, Test Loss: 0.000187\n",
      "Epoch 9/32, Train Loss: 0.000363, Test Loss: 0.000184\n",
      "Epoch 10/32, Train Loss: 0.000344, Test Loss: 0.000181\n",
      "Epoch 11/32, Train Loss: 0.000329, Test Loss: 0.000179\n",
      "Epoch 12/32, Train Loss: 0.000316, Test Loss: 0.000178\n",
      "Epoch 13/32, Train Loss: 0.000304, Test Loss: 0.000177\n",
      "Epoch 14/32, Train Loss: 0.000296, Test Loss: 0.000176\n",
      "Epoch 15/32, Train Loss: 0.000285, Test Loss: 0.000174\n",
      "Epoch 16/32, Train Loss: 0.000279, Test Loss: 0.000173\n",
      "Epoch 17/32, Train Loss: 0.000273, Test Loss: 0.000173\n",
      "Epoch 18/32, Train Loss: 0.000265, Test Loss: 0.000172\n",
      "Epoch 19/32, Train Loss: 0.000259, Test Loss: 0.000171\n",
      "Epoch 20/32, Train Loss: 0.000257, Test Loss: 0.000171\n",
      "Epoch 21/32, Train Loss: 0.000253, Test Loss: 0.000170\n",
      "Epoch 22/32, Train Loss: 0.000250, Test Loss: 0.000170\n",
      "Epoch 23/32, Train Loss: 0.000249, Test Loss: 0.000170\n",
      "Epoch 24/32, Train Loss: 0.000243, Test Loss: 0.000169\n",
      "Epoch 25/32, Train Loss: 0.000242, Test Loss: 0.000170\n",
      "Epoch 26/32, Train Loss: 0.000239, Test Loss: 0.000169\n",
      "Epoch 27/32, Train Loss: 0.000238, Test Loss: 0.000169\n",
      "Epoch 28/32, Train Loss: 0.000234, Test Loss: 0.000169\n",
      "Epoch 29/32, Train Loss: 0.000236, Test Loss: 0.000169\n",
      "Epoch 30/32, Train Loss: 0.000234, Test Loss: 0.000169\n",
      "Epoch 31/32, Train Loss: 0.000231, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:52:05,225] Trial 26 finished with value: 0.00016803947210431238 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 71, 'layer_1_size': 83, 'dropout_rate': 0.1319292136044077, 'learning_rate': 8.548050359693737e-06, 'batch_size': 64, 'epochs': 32}. Best is trial 24 with value: 0.0001642065350682192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/32, Train Loss: 0.000229, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39, Train Loss: 0.001180, Test Loss: 0.000221\n",
      "Epoch 2/39, Train Loss: 0.000465, Test Loss: 0.000211\n",
      "Epoch 3/39, Train Loss: 0.000404, Test Loss: 0.000202\n",
      "Epoch 4/39, Train Loss: 0.000363, Test Loss: 0.000195\n",
      "Epoch 5/39, Train Loss: 0.000329, Test Loss: 0.000184\n",
      "Epoch 6/39, Train Loss: 0.000302, Test Loss: 0.000196\n",
      "Epoch 7/39, Train Loss: 0.000280, Test Loss: 0.000179\n",
      "Epoch 8/39, Train Loss: 0.000261, Test Loss: 0.000174\n",
      "Epoch 9/39, Train Loss: 0.000244, Test Loss: 0.000175\n",
      "Epoch 10/39, Train Loss: 0.000231, Test Loss: 0.000170\n",
      "Epoch 11/39, Train Loss: 0.000222, Test Loss: 0.000168\n",
      "Epoch 12/39, Train Loss: 0.000215, Test Loss: 0.000168\n",
      "Epoch 13/39, Train Loss: 0.000210, Test Loss: 0.000166\n",
      "Epoch 14/39, Train Loss: 0.000206, Test Loss: 0.000166\n",
      "Epoch 15/39, Train Loss: 0.000203, Test Loss: 0.000167\n",
      "Epoch 16/39, Train Loss: 0.000199, Test Loss: 0.000168\n",
      "Epoch 17/39, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 18/39, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 19/39, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 20/39, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 21/39, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 22/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 23/39, Train Loss: 0.000202, Test Loss: 0.000166\n",
      "Epoch 24/39, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 25/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 26/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 27/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 28/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 29/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 30/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 31/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 32/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 33/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 34/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 35/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 36/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 37/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 38/39, Train Loss: 0.000189, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:52:20,393] Trial 27 finished with value: 0.0001642223474670074 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 163, 'layer_1_size': 158, 'layer_2_size': 32, 'dropout_rate': 0.18420059100869499, 'learning_rate': 0.00013810864124642433, 'batch_size': 128, 'epochs': 39}. Best is trial 24 with value: 0.0001642065350682192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/39, Train Loss: 0.000190, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39, Train Loss: 0.000258, Test Loss: 0.000170\n",
      "Epoch 2/39, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 3/39, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 4/39, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 5/39, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 6/39, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 7/39, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 8/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 10/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 11/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 13/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 15/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 18/39, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 19/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/39, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 21/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 23/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 26/39, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 27/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 28/39, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 29/39, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 30/39, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 31/39, Train Loss: 0.000198, Test Loss: 0.000165\n",
      "Epoch 32/39, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 33/39, Train Loss: 0.000183, Test Loss: 0.000164\n",
      "Epoch 34/39, Train Loss: 0.000185, Test Loss: 0.000166\n",
      "Epoch 35/39, Train Loss: 0.000183, Test Loss: 0.000164\n",
      "Epoch 36/39, Train Loss: 0.000180, Test Loss: 0.000167\n",
      "Epoch 37/39, Train Loss: 0.000179, Test Loss: 0.000166\n",
      "Epoch 38/39, Train Loss: 0.000180, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:52:34,070] Trial 28 finished with value: 0.00016516303211603606 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 164, 'layer_1_size': 157, 'layer_2_size': 32, 'dropout_rate': 0.1769679217970168, 'learning_rate': 0.000232071236777982, 'batch_size': 128, 'epochs': 39}. Best is trial 24 with value: 0.0001642065350682192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/39, Train Loss: 0.000183, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36, Train Loss: 0.000231, Test Loss: 0.000167\n",
      "Epoch 2/36, Train Loss: 0.000198, Test Loss: 0.000166\n",
      "Epoch 3/36, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 4/36, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 5/36, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 6/36, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/36, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/36, Train Loss: 0.000192, Test Loss: 0.000176\n",
      "Epoch 9/36, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 10/36, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 11/36, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/36, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 14/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 16/36, Train Loss: 0.000191, Test Loss: 0.000169\n",
      "Epoch 17/36, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 18/36, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 19/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 20/36, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/36, Train Loss: 0.000191, Test Loss: 0.000173\n",
      "Epoch 22/36, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 23/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 24/36, Train Loss: 0.000191, Test Loss: 0.000169\n",
      "Epoch 25/36, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 26/36, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 27/36, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 28/36, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 29/36, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 30/36, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 31/36, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 32/36, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 33/36, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 34/36, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 35/36, Train Loss: 0.000187, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:53:09,683] Trial 29 finished with value: 0.00016958291774743327 and parameters: {'num_hidden_layers': 6, 'layer_0_size': 201, 'layer_1_size': 180, 'layer_2_size': 56, 'layer_3_size': 167, 'layer_4_size': 244, 'layer_5_size': 255, 'dropout_rate': 0.11243197119749598, 'learning_rate': 0.0008331620312080111, 'batch_size': 128, 'epochs': 36}. Best is trial 24 with value: 0.0001642065350682192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/36, Train Loss: 0.000196, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Train Loss: 0.000357, Test Loss: 0.000171\n",
      "Epoch 2/40, Train Loss: 0.000216, Test Loss: 0.000177\n",
      "Epoch 3/40, Train Loss: 0.000203, Test Loss: 0.000172\n",
      "Epoch 4/40, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 5/40, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 6/40, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 7/40, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 8/40, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 9/40, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 10/40, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 11/40, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 12/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 13/40, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 14/40, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 15/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 16/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 17/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 18/40, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 19/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 20/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 21/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 22/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 23/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 24/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 25/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 26/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 27/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 28/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 29/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 30/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 31/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 32/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 33/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 34/40, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 35/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 36/40, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 37/40, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 38/40, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 39/40, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:53:33,381] Trial 30 finished with value: 0.00016601845065393247 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 158, 'layer_1_size': 147, 'layer_2_size': 54, 'layer_3_size': 81, 'layer_4_size': 169, 'dropout_rate': 0.3549570871477277, 'learning_rate': 0.00045901115824504424, 'batch_size': 128, 'epochs': 40}. Best is trial 24 with value: 0.0001642065350682192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32, Train Loss: 0.000610, Test Loss: 0.000186\n",
      "Epoch 2/32, Train Loss: 0.000269, Test Loss: 0.000207\n",
      "Epoch 3/32, Train Loss: 0.000238, Test Loss: 0.000195\n",
      "Epoch 4/32, Train Loss: 0.000226, Test Loss: 0.000194\n",
      "Epoch 5/32, Train Loss: 0.000218, Test Loss: 0.000179\n",
      "Epoch 6/32, Train Loss: 0.000214, Test Loss: 0.000179\n",
      "Epoch 7/32, Train Loss: 0.000207, Test Loss: 0.000177\n",
      "Epoch 8/32, Train Loss: 0.000207, Test Loss: 0.000174\n",
      "Epoch 9/32, Train Loss: 0.000202, Test Loss: 0.000173\n",
      "Epoch 10/32, Train Loss: 0.000200, Test Loss: 0.000171\n",
      "Epoch 11/32, Train Loss: 0.000198, Test Loss: 0.000169\n",
      "Epoch 12/32, Train Loss: 0.000200, Test Loss: 0.000168\n",
      "Epoch 13/32, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 14/32, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 15/32, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 16/32, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 17/32, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 18/32, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 19/32, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 20/32, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 21/32, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 22/32, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 23/32, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 24/32, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 25/32, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 26/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 27/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 28/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 29/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 30/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 31/32, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:53:46,371] Trial 31 finished with value: 0.000164941360811011 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 143, 'layer_1_size': 116, 'layer_2_size': 73, 'dropout_rate': 0.2059443281310537, 'learning_rate': 0.00012516747879571762, 'batch_size': 128, 'epochs': 32}. Best is trial 24 with value: 0.0001642065350682192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/32, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35, Train Loss: 0.000578, Test Loss: 0.000196\n",
      "Epoch 2/35, Train Loss: 0.000341, Test Loss: 0.000186\n",
      "Epoch 3/35, Train Loss: 0.000280, Test Loss: 0.000180\n",
      "Epoch 4/35, Train Loss: 0.000252, Test Loss: 0.000179\n",
      "Epoch 5/35, Train Loss: 0.000237, Test Loss: 0.000179\n",
      "Epoch 6/35, Train Loss: 0.000226, Test Loss: 0.000177\n",
      "Epoch 7/35, Train Loss: 0.000219, Test Loss: 0.000175\n",
      "Epoch 8/35, Train Loss: 0.000213, Test Loss: 0.000172\n",
      "Epoch 9/35, Train Loss: 0.000209, Test Loss: 0.000172\n",
      "Epoch 10/35, Train Loss: 0.000207, Test Loss: 0.000170\n",
      "Epoch 11/35, Train Loss: 0.000204, Test Loss: 0.000169\n",
      "Epoch 12/35, Train Loss: 0.000202, Test Loss: 0.000169\n",
      "Epoch 13/35, Train Loss: 0.000201, Test Loss: 0.000168\n",
      "Epoch 14/35, Train Loss: 0.000199, Test Loss: 0.000168\n",
      "Epoch 15/35, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 16/35, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 17/35, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 18/35, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 19/35, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 20/35, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 21/35, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 22/35, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 23/35, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 24/35, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 25/35, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 26/35, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 27/35, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 28/35, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 29/35, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 30/35, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 31/35, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 32/35, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 33/35, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 34/35, Train Loss: 0.000190, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:53:59,537] Trial 32 finished with value: 0.00016540010171645975 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 112, 'layer_1_size': 180, 'dropout_rate': 0.15605083063482725, 'learning_rate': 3.523438729531782e-05, 'batch_size': 64, 'epochs': 35}. Best is trial 24 with value: 0.0001642065350682192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/35, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38, Train Loss: 0.000538, Test Loss: 0.000171\n",
      "Epoch 2/38, Train Loss: 0.000258, Test Loss: 0.000170\n",
      "Epoch 3/38, Train Loss: 0.000224, Test Loss: 0.000174\n",
      "Epoch 4/38, Train Loss: 0.000214, Test Loss: 0.000172\n",
      "Epoch 5/38, Train Loss: 0.000207, Test Loss: 0.000172\n",
      "Epoch 6/38, Train Loss: 0.000202, Test Loss: 0.000172\n",
      "Epoch 7/38, Train Loss: 0.000199, Test Loss: 0.000171\n",
      "Epoch 8/38, Train Loss: 0.000197, Test Loss: 0.000171\n",
      "Epoch 9/38, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 10/38, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 11/38, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 12/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 13/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 14/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 15/38, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 16/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 18/38, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 19/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 23/38, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 24/38, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 25/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 26/38, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 27/38, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 28/38, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 29/38, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 30/38, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 31/38, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 32/38, Train Loss: 0.000189, Test Loss: 0.000163\n",
      "Epoch 33/38, Train Loss: 0.000187, Test Loss: 0.000163\n",
      "Epoch 34/38, Train Loss: 0.000187, Test Loss: 0.000163\n",
      "Epoch 35/38, Train Loss: 0.000187, Test Loss: 0.000163\n",
      "Epoch 36/38, Train Loss: 0.000184, Test Loss: 0.000165\n",
      "Epoch 37/38, Train Loss: 0.000184, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:54:39,665] Trial 33 finished with value: 0.00016667073440375604 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 91, 'layer_1_size': 92, 'layer_2_size': 45, 'layer_3_size': 207, 'dropout_rate': 0.22809318233147968, 'learning_rate': 0.00011364949779051338, 'batch_size': 32, 'epochs': 38}. Best is trial 24 with value: 0.0001642065350682192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/38, Train Loss: 0.000184, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12, Train Loss: 0.000397, Test Loss: 0.000190\n",
      "Epoch 2/12, Train Loss: 0.000220, Test Loss: 0.000179\n",
      "Epoch 3/12, Train Loss: 0.000204, Test Loss: 0.000169\n",
      "Epoch 4/12, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 5/12, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 6/12, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 7/12, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 8/12, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/12, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 10/12, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 11/12, Train Loss: 0.000192, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:54:43,743] Trial 34 finished with value: 0.00016655525095918546 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 123, 'layer_1_size': 115, 'dropout_rate': 0.194727047408133, 'learning_rate': 0.0013386541971621415, 'batch_size': 128, 'epochs': 12}. Best is trial 24 with value: 0.0001642065350682192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/12, Train Loss: 0.000192, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19, Train Loss: 0.000889, Test Loss: 0.000174\n",
      "Epoch 2/19, Train Loss: 0.000688, Test Loss: 0.000173\n",
      "Epoch 3/19, Train Loss: 0.000614, Test Loss: 0.000173\n",
      "Epoch 4/19, Train Loss: 0.000545, Test Loss: 0.000172\n",
      "Epoch 5/19, Train Loss: 0.000494, Test Loss: 0.000171\n",
      "Epoch 6/19, Train Loss: 0.000455, Test Loss: 0.000171\n",
      "Epoch 7/19, Train Loss: 0.000419, Test Loss: 0.000171\n",
      "Epoch 8/19, Train Loss: 0.000388, Test Loss: 0.000172\n",
      "Epoch 9/19, Train Loss: 0.000362, Test Loss: 0.000173\n",
      "Epoch 10/19, Train Loss: 0.000342, Test Loss: 0.000172\n",
      "Epoch 11/19, Train Loss: 0.000323, Test Loss: 0.000172\n",
      "Epoch 12/19, Train Loss: 0.000308, Test Loss: 0.000171\n",
      "Epoch 13/19, Train Loss: 0.000294, Test Loss: 0.000172\n",
      "Epoch 14/19, Train Loss: 0.000285, Test Loss: 0.000171\n",
      "Epoch 15/19, Train Loss: 0.000275, Test Loss: 0.000170\n",
      "Epoch 16/19, Train Loss: 0.000268, Test Loss: 0.000170\n",
      "Epoch 17/19, Train Loss: 0.000261, Test Loss: 0.000170\n",
      "Epoch 18/19, Train Loss: 0.000253, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:54:51,102] Trial 35 finished with value: 0.00017026391460897304 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 174, 'layer_1_size': 68, 'layer_2_size': 69, 'layer_3_size': 58, 'layer_4_size': 77, 'dropout_rate': 0.2698405740200378, 'learning_rate': 1.8779608676120002e-05, 'batch_size': 256, 'epochs': 19}. Best is trial 24 with value: 0.0001642065350682192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/19, Train Loss: 0.000251, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27, Train Loss: 0.001992, Test Loss: 0.000296\n",
      "Epoch 2/27, Train Loss: 0.000448, Test Loss: 0.000219\n",
      "Epoch 3/27, Train Loss: 0.000290, Test Loss: 0.000188\n",
      "Epoch 4/27, Train Loss: 0.000244, Test Loss: 0.000184\n",
      "Epoch 5/27, Train Loss: 0.000223, Test Loss: 0.000173\n",
      "Epoch 6/27, Train Loss: 0.000210, Test Loss: 0.000173\n",
      "Epoch 7/27, Train Loss: 0.000203, Test Loss: 0.000167\n",
      "Epoch 8/27, Train Loss: 0.000199, Test Loss: 0.000167\n",
      "Epoch 9/27, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 10/27, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 11/27, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 12/27, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 13/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 14/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 15/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/27, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 21/27, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 22/27, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 23/27, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 24/27, Train Loss: 0.000190, Test Loss: 0.000163\n",
      "Epoch 25/27, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 26/27, Train Loss: 0.000191, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:54:57,713] Trial 36 finished with value: 0.00016522769236314248 and parameters: {'num_hidden_layers': 1, 'layer_0_size': 149, 'dropout_rate': 0.22499978127584772, 'learning_rate': 0.0002846854847077619, 'batch_size': 128, 'epochs': 27}. Best is trial 24 with value: 0.0001642065350682192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/27, Train Loss: 0.000189, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37, Train Loss: 0.000475, Test Loss: 0.000170\n",
      "Epoch 2/37, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 3/37, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 4/37, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 5/37, Train Loss: 0.000197, Test Loss: 0.000172\n",
      "Epoch 6/37, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 7/37, Train Loss: 0.000198, Test Loss: 0.000172\n",
      "Epoch 8/37, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 9/37, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 10/37, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 11/37, Train Loss: 0.000199, Test Loss: 0.000173\n",
      "Epoch 12/37, Train Loss: 0.000202, Test Loss: 0.000172\n",
      "Epoch 13/37, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 14/37, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 15/37, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 16/37, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 17/37, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 18/37, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 19/37, Train Loss: 0.000200, Test Loss: 0.000171\n",
      "Epoch 20/37, Train Loss: 0.000200, Test Loss: 0.000180\n",
      "Epoch 21/37, Train Loss: 0.000200, Test Loss: 0.000274\n",
      "Epoch 22/37, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 23/37, Train Loss: 0.000199, Test Loss: 0.000171\n",
      "Epoch 24/37, Train Loss: 0.000200, Test Loss: 0.000174\n",
      "Epoch 25/37, Train Loss: 0.000200, Test Loss: 0.000171\n",
      "Epoch 26/37, Train Loss: 0.000199, Test Loss: 0.000172\n",
      "Epoch 27/37, Train Loss: 0.000198, Test Loss: 0.000170\n",
      "Epoch 28/37, Train Loss: 0.000199, Test Loss: 0.000171\n",
      "Epoch 29/37, Train Loss: 0.000198, Test Loss: 0.000171\n",
      "Epoch 30/37, Train Loss: 0.000201, Test Loss: 0.000170\n",
      "Epoch 31/37, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 32/37, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 33/37, Train Loss: 0.000200, Test Loss: 0.000171\n",
      "Epoch 34/37, Train Loss: 0.000199, Test Loss: 0.000186\n",
      "Epoch 35/37, Train Loss: 0.000200, Test Loss: 0.000171\n",
      "Epoch 36/37, Train Loss: 0.000200, Test Loss: 0.000172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:55:19,556] Trial 37 finished with value: 0.00016954692295800464 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 104, 'layer_1_size': 145, 'layer_2_size': 89, 'dropout_rate': 0.3164459078578773, 'learning_rate': 0.006850711698226453, 'batch_size': 64, 'epochs': 37}. Best is trial 24 with value: 0.0001642065350682192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/37, Train Loss: 0.000200, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32, Train Loss: 0.000290, Test Loss: 0.000178\n",
      "Epoch 2/32, Train Loss: 0.000222, Test Loss: 0.000173\n",
      "Epoch 3/32, Train Loss: 0.000205, Test Loss: 0.000169\n",
      "Epoch 4/32, Train Loss: 0.000199, Test Loss: 0.000169\n",
      "Epoch 5/32, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 6/32, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 7/32, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 8/32, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/32, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 10/32, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/32, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 22/32, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 23/32, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 24/32, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/32, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 26/32, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 27/32, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 28/32, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 29/32, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 30/32, Train Loss: 0.000189, Test Loss: 0.000163\n",
      "Epoch 31/32, Train Loss: 0.000189, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:56:02,152] Trial 38 finished with value: 0.00016344553637006885 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 76, 'layer_1_size': 211, 'layer_2_size': 33, 'dropout_rate': 0.14054577284769876, 'learning_rate': 5.194404028209359e-05, 'batch_size': 32, 'epochs': 32}. Best is trial 38 with value: 0.00016344553637006885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/32, Train Loss: 0.000189, Test Loss: 0.000163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/31, Train Loss: 0.000376, Test Loss: 0.000170\n",
      "Epoch 2/31, Train Loss: 0.000299, Test Loss: 0.000170\n",
      "Epoch 3/31, Train Loss: 0.000258, Test Loss: 0.000170\n",
      "Epoch 4/31, Train Loss: 0.000234, Test Loss: 0.000169\n",
      "Epoch 5/31, Train Loss: 0.000223, Test Loss: 0.000173\n",
      "Epoch 6/31, Train Loss: 0.000215, Test Loss: 0.000170\n",
      "Epoch 7/31, Train Loss: 0.000210, Test Loss: 0.000171\n",
      "Epoch 8/31, Train Loss: 0.000208, Test Loss: 0.000170\n",
      "Epoch 9/31, Train Loss: 0.000204, Test Loss: 0.000169\n",
      "Epoch 10/31, Train Loss: 0.000204, Test Loss: 0.000169\n",
      "Epoch 11/31, Train Loss: 0.000201, Test Loss: 0.000169\n",
      "Epoch 12/31, Train Loss: 0.000201, Test Loss: 0.000169\n",
      "Epoch 13/31, Train Loss: 0.000200, Test Loss: 0.000169\n",
      "Epoch 14/31, Train Loss: 0.000200, Test Loss: 0.000169\n",
      "Epoch 15/31, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 16/31, Train Loss: 0.000199, Test Loss: 0.000169\n",
      "Epoch 17/31, Train Loss: 0.000198, Test Loss: 0.000169\n",
      "Epoch 18/31, Train Loss: 0.000199, Test Loss: 0.000169\n",
      "Epoch 19/31, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 20/31, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 21/31, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 22/31, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 23/31, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 24/31, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 25/31, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 26/31, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 27/31, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 28/31, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 29/31, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 30/31, Train Loss: 0.000194, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:56:23,420] Trial 39 finished with value: 0.00016717841082291055 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 55, 'layer_1_size': 215, 'layer_2_size': 34, 'layer_3_size': 118, 'layer_4_size': 153, 'dropout_rate': 0.13550423404078973, 'learning_rate': 6.798424391100313e-05, 'batch_size': 256, 'epochs': 31}. Best is trial 38 with value: 0.00016344553637006885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/31, Train Loss: 0.000194, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35, Train Loss: 0.000294, Test Loss: 0.000170\n",
      "Epoch 2/35, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 3/35, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 4/35, Train Loss: 0.000196, Test Loss: 0.000172\n",
      "Epoch 5/35, Train Loss: 0.000196, Test Loss: 0.000171\n",
      "Epoch 6/35, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 7/35, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 8/35, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 9/35, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 10/35, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 11/35, Train Loss: 0.000196, Test Loss: 0.000171\n",
      "Epoch 12/35, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 13/35, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 14/35, Train Loss: 0.000195, Test Loss: 0.000171\n",
      "Epoch 15/35, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 16/35, Train Loss: 0.000195, Test Loss: 0.000176\n",
      "Epoch 17/35, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 18/35, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 19/35, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 20/35, Train Loss: 0.000196, Test Loss: 0.000175\n",
      "Epoch 21/35, Train Loss: 0.000198, Test Loss: 0.000170\n",
      "Epoch 22/35, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 23/35, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 24/35, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 25/35, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 26/35, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 27/35, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 28/35, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 29/35, Train Loss: 0.000196, Test Loss: 0.000172\n",
      "Epoch 30/35, Train Loss: 0.000196, Test Loss: 0.000171\n",
      "Epoch 31/35, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 32/35, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 33/35, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 34/35, Train Loss: 0.000196, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:56:34,419] Trial 40 finished with value: 0.0001695887313402519 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 76, 'layer_1_size': 178, 'layer_2_size': 51, 'dropout_rate': 0.4648689317121198, 'learning_rate': 0.0021858014900153593, 'batch_size': 128, 'epochs': 35}. Best is trial 38 with value: 0.00016344553637006885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/35, Train Loss: 0.000196, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21, Train Loss: 0.001334, Test Loss: 0.000239\n",
      "Epoch 2/21, Train Loss: 0.000517, Test Loss: 0.000197\n",
      "Epoch 3/21, Train Loss: 0.000373, Test Loss: 0.000176\n",
      "Epoch 4/21, Train Loss: 0.000302, Test Loss: 0.000178\n",
      "Epoch 5/21, Train Loss: 0.000267, Test Loss: 0.000173\n",
      "Epoch 6/21, Train Loss: 0.000243, Test Loss: 0.000173\n",
      "Epoch 7/21, Train Loss: 0.000228, Test Loss: 0.000170\n",
      "Epoch 8/21, Train Loss: 0.000218, Test Loss: 0.000168\n",
      "Epoch 9/21, Train Loss: 0.000212, Test Loss: 0.000169\n",
      "Epoch 10/21, Train Loss: 0.000205, Test Loss: 0.000169\n",
      "Epoch 11/21, Train Loss: 0.000203, Test Loss: 0.000168\n",
      "Epoch 12/21, Train Loss: 0.000201, Test Loss: 0.000168\n",
      "Epoch 13/21, Train Loss: 0.000199, Test Loss: 0.000168\n",
      "Epoch 14/21, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 15/21, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 16/21, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 17/21, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 18/21, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 19/21, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 20/21, Train Loss: 0.000194, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:56:46,455] Trial 41 finished with value: 0.00016664626654742717 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 63, 'layer_1_size': 216, 'dropout_rate': 0.18582886554822828, 'learning_rate': 2.6925075863089364e-05, 'batch_size': 32, 'epochs': 21}. Best is trial 38 with value: 0.00016344553637006885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/21, Train Loss: 0.000193, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Train Loss: 0.000515, Test Loss: 0.000171\n",
      "Epoch 2/24, Train Loss: 0.000273, Test Loss: 0.000170\n",
      "Epoch 3/24, Train Loss: 0.000240, Test Loss: 0.000169\n",
      "Epoch 4/24, Train Loss: 0.000227, Test Loss: 0.000170\n",
      "Epoch 5/24, Train Loss: 0.000219, Test Loss: 0.000173\n",
      "Epoch 6/24, Train Loss: 0.000214, Test Loss: 0.000169\n",
      "Epoch 7/24, Train Loss: 0.000210, Test Loss: 0.000170\n",
      "Epoch 8/24, Train Loss: 0.000206, Test Loss: 0.000169\n",
      "Epoch 9/24, Train Loss: 0.000205, Test Loss: 0.000170\n",
      "Epoch 10/24, Train Loss: 0.000203, Test Loss: 0.000168\n",
      "Epoch 11/24, Train Loss: 0.000201, Test Loss: 0.000169\n",
      "Epoch 12/24, Train Loss: 0.000199, Test Loss: 0.000167\n",
      "Epoch 13/24, Train Loss: 0.000198, Test Loss: 0.000166\n",
      "Epoch 14/24, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 15/24, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 16/24, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 17/24, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 18/24, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 19/24, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 20/24, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 21/24, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 22/24, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 23/24, Train Loss: 0.000193, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:57:02,910] Trial 42 finished with value: 0.00016513567536255704 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 49, 'layer_1_size': 116, 'layer_2_size': 65, 'layer_3_size': 101, 'dropout_rate': 0.15554962053285334, 'learning_rate': 5.256208563655055e-05, 'batch_size': 32, 'epochs': 24}. Best is trial 38 with value: 0.00016344553637006885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Train Loss: 0.000192, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29, Train Loss: 0.006667, Test Loss: 0.000316\n",
      "Epoch 2/29, Train Loss: 0.000913, Test Loss: 0.000261\n",
      "Epoch 3/29, Train Loss: 0.000737, Test Loss: 0.000244\n",
      "Epoch 4/29, Train Loss: 0.000624, Test Loss: 0.000225\n",
      "Epoch 5/29, Train Loss: 0.000546, Test Loss: 0.000210\n",
      "Epoch 6/29, Train Loss: 0.000506, Test Loss: 0.000211\n",
      "Epoch 7/29, Train Loss: 0.000465, Test Loss: 0.000202\n",
      "Epoch 8/29, Train Loss: 0.000429, Test Loss: 0.000210\n",
      "Epoch 9/29, Train Loss: 0.000398, Test Loss: 0.000203\n",
      "Epoch 10/29, Train Loss: 0.000379, Test Loss: 0.000191\n",
      "Epoch 11/29, Train Loss: 0.000357, Test Loss: 0.000193\n",
      "Epoch 12/29, Train Loss: 0.000340, Test Loss: 0.000189\n",
      "Epoch 13/29, Train Loss: 0.000326, Test Loss: 0.000185\n",
      "Epoch 14/29, Train Loss: 0.000312, Test Loss: 0.000179\n",
      "Epoch 15/29, Train Loss: 0.000297, Test Loss: 0.000182\n",
      "Epoch 16/29, Train Loss: 0.000289, Test Loss: 0.000176\n",
      "Epoch 17/29, Train Loss: 0.000281, Test Loss: 0.000178\n",
      "Epoch 18/29, Train Loss: 0.000269, Test Loss: 0.000173\n",
      "Epoch 19/29, Train Loss: 0.000264, Test Loss: 0.000176\n",
      "Epoch 20/29, Train Loss: 0.000258, Test Loss: 0.000177\n",
      "Epoch 21/29, Train Loss: 0.000251, Test Loss: 0.000172\n",
      "Epoch 22/29, Train Loss: 0.000246, Test Loss: 0.000172\n",
      "Epoch 23/29, Train Loss: 0.000240, Test Loss: 0.000169\n",
      "Epoch 24/29, Train Loss: 0.000237, Test Loss: 0.000168\n",
      "Epoch 25/29, Train Loss: 0.000233, Test Loss: 0.000170\n",
      "Epoch 26/29, Train Loss: 0.000230, Test Loss: 0.000171\n",
      "Epoch 27/29, Train Loss: 0.000225, Test Loss: 0.000170\n",
      "Epoch 28/29, Train Loss: 0.000221, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:57:21,932] Trial 43 finished with value: 0.0001702141821074439 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 98, 'layer_1_size': 163, 'layer_2_size': 45, 'dropout_rate': 0.165760336483233, 'learning_rate': 9.929305343153822e-06, 'batch_size': 32, 'epochs': 29}. Best is trial 38 with value: 0.00016344553637006885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29, Train Loss: 0.000219, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16, Train Loss: 0.001333, Test Loss: 0.000212\n",
      "Epoch 2/16, Train Loss: 0.000278, Test Loss: 0.000181\n",
      "Epoch 3/16, Train Loss: 0.000219, Test Loss: 0.000171\n",
      "Epoch 4/16, Train Loss: 0.000204, Test Loss: 0.000170\n",
      "Epoch 5/16, Train Loss: 0.000199, Test Loss: 0.000169\n",
      "Epoch 6/16, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 7/16, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 8/16, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 9/16, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 10/16, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 11/16, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 12/16, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 13/16, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 14/16, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 15/16, Train Loss: 0.000193, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:57:32,069] Trial 44 finished with value: 0.00016668645685608533 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 139, 'layer_1_size': 138, 'dropout_rate': 0.49300965709211064, 'learning_rate': 8.872122640317655e-05, 'batch_size': 32, 'epochs': 16}. Best is trial 38 with value: 0.00016344553637006885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/16, Train Loss: 0.000193, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34, Train Loss: 0.000859, Test Loss: 0.000222\n",
      "Epoch 2/34, Train Loss: 0.000255, Test Loss: 0.000183\n",
      "Epoch 3/34, Train Loss: 0.000215, Test Loss: 0.000171\n",
      "Epoch 4/34, Train Loss: 0.000201, Test Loss: 0.000170\n",
      "Epoch 5/34, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 6/34, Train Loss: 0.000194, Test Loss: 0.000171\n",
      "Epoch 7/34, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 8/34, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 9/34, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 10/34, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 11/34, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 12/34, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/34, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 14/34, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/34, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/34, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 17/34, Train Loss: 0.000191, Test Loss: 0.000168\n",
      "Epoch 18/34, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 19/34, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 20/34, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 21/34, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 22/34, Train Loss: 0.000189, Test Loss: 0.000163\n",
      "Epoch 23/34, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 24/34, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 25/34, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 26/34, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 27/34, Train Loss: 0.000187, Test Loss: 0.000163\n",
      "Epoch 28/34, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 29/34, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 30/34, Train Loss: 0.000186, Test Loss: 0.000168\n",
      "Epoch 31/34, Train Loss: 0.000186, Test Loss: 0.000164\n",
      "Epoch 32/34, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 33/34, Train Loss: 0.000185, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:57:39,996] Trial 45 finished with value: 0.00016489050242472008 and parameters: {'num_hidden_layers': 1, 'layer_0_size': 84, 'dropout_rate': 0.1200175542238452, 'learning_rate': 0.0003951755309297677, 'batch_size': 64, 'epochs': 34}. Best is trial 38 with value: 0.00016344553637006885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/34, Train Loss: 0.000186, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28, Train Loss: 0.000687, Test Loss: 0.000174\n",
      "Epoch 2/28, Train Loss: 0.000378, Test Loss: 0.000177\n",
      "Epoch 3/28, Train Loss: 0.000272, Test Loss: 0.000174\n",
      "Epoch 4/28, Train Loss: 0.000244, Test Loss: 0.000173\n",
      "Epoch 5/28, Train Loss: 0.000233, Test Loss: 0.000186\n",
      "Epoch 6/28, Train Loss: 0.000226, Test Loss: 0.000177\n",
      "Epoch 7/28, Train Loss: 0.000219, Test Loss: 0.000184\n",
      "Epoch 8/28, Train Loss: 0.000216, Test Loss: 0.000179\n",
      "Epoch 9/28, Train Loss: 0.000214, Test Loss: 0.000181\n",
      "Epoch 10/28, Train Loss: 0.000211, Test Loss: 0.000176\n",
      "Epoch 11/28, Train Loss: 0.000210, Test Loss: 0.000176\n",
      "Epoch 12/28, Train Loss: 0.000207, Test Loss: 0.000178\n",
      "Epoch 13/28, Train Loss: 0.000206, Test Loss: 0.000173\n",
      "Epoch 14/28, Train Loss: 0.000204, Test Loss: 0.000184\n",
      "Epoch 15/28, Train Loss: 0.000202, Test Loss: 0.000173\n",
      "Epoch 16/28, Train Loss: 0.000201, Test Loss: 0.000172\n",
      "Epoch 17/28, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 18/28, Train Loss: 0.000199, Test Loss: 0.000173\n",
      "Epoch 19/28, Train Loss: 0.000198, Test Loss: 0.000169\n",
      "Epoch 20/28, Train Loss: 0.000198, Test Loss: 0.000171\n",
      "Epoch 21/28, Train Loss: 0.000197, Test Loss: 0.000171\n",
      "Epoch 22/28, Train Loss: 0.000195, Test Loss: 0.000170\n",
      "Epoch 23/28, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 24/28, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 25/28, Train Loss: 0.000194, Test Loss: 0.000171\n",
      "Epoch 26/28, Train Loss: 0.000194, Test Loss: 0.000169\n",
      "Epoch 27/28, Train Loss: 0.000194, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:57:51,762] Trial 46 finished with value: 0.00016695376431133838 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 180, 'layer_1_size': 151, 'layer_2_size': 71, 'layer_3_size': 169, 'dropout_rate': 0.23148851254937358, 'learning_rate': 0.00016683818067260724, 'batch_size': 256, 'epochs': 28}. Best is trial 38 with value: 0.00016344553637006885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/28, Train Loss: 0.000193, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/31, Train Loss: 0.000379, Test Loss: 0.000180\n",
      "Epoch 2/31, Train Loss: 0.000220, Test Loss: 0.000179\n",
      "Epoch 3/31, Train Loss: 0.000207, Test Loss: 0.000171\n",
      "Epoch 4/31, Train Loss: 0.000201, Test Loss: 0.000170\n",
      "Epoch 5/31, Train Loss: 0.000198, Test Loss: 0.000169\n",
      "Epoch 6/31, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 7/31, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 8/31, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 9/31, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 10/31, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 11/31, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 12/31, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 13/31, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 14/31, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 15/31, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 16/31, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 17/31, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 18/31, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 19/31, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 20/31, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 21/31, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 22/31, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 23/31, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 24/31, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 25/31, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 26/31, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 27/31, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 28/31, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 29/31, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 30/31, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:58:19,333] Trial 47 finished with value: 0.00016587786724321337 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 215, 'layer_1_size': 211, 'layer_2_size': 32, 'dropout_rate': 0.19088471313453936, 'learning_rate': 2.863759261437726e-05, 'batch_size': 32, 'epochs': 31}. Best is trial 38 with value: 0.00016344553637006885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/31, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Train Loss: 0.000333, Test Loss: 0.000179\n",
      "Epoch 2/8, Train Loss: 0.000217, Test Loss: 0.000170\n",
      "Epoch 3/8, Train Loss: 0.000206, Test Loss: 0.000169\n",
      "Epoch 4/8, Train Loss: 0.000204, Test Loss: 0.000170\n",
      "Epoch 5/8, Train Loss: 0.000201, Test Loss: 0.000167\n",
      "Epoch 6/8, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 7/8, Train Loss: 0.000196, Test Loss: 0.000176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:58:29,492] Trial 48 finished with value: 0.00018400642479278877 and parameters: {'num_hidden_layers': 7, 'layer_0_size': 156, 'layer_1_size': 255, 'layer_2_size': 125, 'layer_3_size': 142, 'layer_4_size': 224, 'layer_5_size': 32, 'layer_6_size': 247, 'dropout_rate': 0.10527414945394287, 'learning_rate': 0.0005631482296336307, 'batch_size': 64, 'epochs': 8}. Best is trial 38 with value: 0.00016344553637006885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/8, Train Loss: 0.000195, Test Loss: 0.000184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37, Train Loss: 0.000599, Test Loss: 0.000172\n",
      "Epoch 2/37, Train Loss: 0.000261, Test Loss: 0.000170\n",
      "Epoch 3/37, Train Loss: 0.000236, Test Loss: 0.000170\n",
      "Epoch 4/37, Train Loss: 0.000223, Test Loss: 0.000169\n",
      "Epoch 5/37, Train Loss: 0.000215, Test Loss: 0.000168\n",
      "Epoch 6/37, Train Loss: 0.000208, Test Loss: 0.000166\n",
      "Epoch 7/37, Train Loss: 0.000202, Test Loss: 0.000166\n",
      "Epoch 8/37, Train Loss: 0.000199, Test Loss: 0.000166\n",
      "Epoch 9/37, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 10/37, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 11/37, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 12/37, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 13/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/37, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/37, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 16/37, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 17/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/37, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 22/37, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 23/37, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 24/37, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 25/37, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 26/37, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 27/37, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 28/37, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 29/37, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 30/37, Train Loss: 0.000186, Test Loss: 0.000163\n",
      "Epoch 31/37, Train Loss: 0.000184, Test Loss: 0.000162\n",
      "Epoch 32/37, Train Loss: 0.000180, Test Loss: 0.000165\n",
      "Epoch 33/37, Train Loss: 0.000171, Test Loss: 0.000165\n",
      "Epoch 34/37, Train Loss: 0.000170, Test Loss: 0.000165\n",
      "Epoch 35/37, Train Loss: 0.000174, Test Loss: 0.000165\n",
      "Epoch 36/37, Train Loss: 0.000178, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:59:06,959] Trial 49 finished with value: 0.0001627372559739577 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 123, 'layer_1_size': 232, 'layer_2_size': 44, 'layer_3_size': 54, 'layer_4_size': 65, 'dropout_rate': 0.13296818795370235, 'learning_rate': 0.00010347402966203976, 'batch_size': 32, 'epochs': 37}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/37, Train Loss: 0.000166, Test Loss: 0.000163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37, Train Loss: 0.000266, Test Loss: 0.000178\n",
      "Epoch 2/37, Train Loss: 0.000218, Test Loss: 0.000177\n",
      "Epoch 3/37, Train Loss: 0.000208, Test Loss: 0.000173\n",
      "Epoch 4/37, Train Loss: 0.000206, Test Loss: 0.000173\n",
      "Epoch 5/37, Train Loss: 0.000204, Test Loss: 0.000172\n",
      "Epoch 6/37, Train Loss: 0.000202, Test Loss: 0.000173\n",
      "Epoch 7/37, Train Loss: 0.000200, Test Loss: 0.000172\n",
      "Epoch 8/37, Train Loss: 0.000199, Test Loss: 0.000167\n",
      "Epoch 9/37, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 10/37, Train Loss: 0.000197, Test Loss: 0.000173\n",
      "Epoch 11/37, Train Loss: 0.000197, Test Loss: 0.000183\n",
      "Epoch 12/37, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 13/37, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 14/37, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 15/37, Train Loss: 0.000195, Test Loss: 0.000170\n",
      "Epoch 16/37, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 17/37, Train Loss: 0.000194, Test Loss: 0.000174\n",
      "Epoch 18/37, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 19/37, Train Loss: 0.000194, Test Loss: 0.000170\n",
      "Epoch 20/37, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 21/37, Train Loss: 0.000193, Test Loss: 0.000169\n",
      "Epoch 22/37, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 23/37, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 24/37, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 25/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 26/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 27/37, Train Loss: 0.000192, Test Loss: 0.000171\n",
      "Epoch 28/37, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 29/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 30/37, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 31/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 32/37, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 33/37, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 34/37, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 35/37, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 36/37, Train Loss: 0.000188, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 11:59:29,082] Trial 50 finished with value: 0.00016635147991814114 and parameters: {'num_hidden_layers': 7, 'layer_0_size': 122, 'layer_1_size': 228, 'layer_2_size': 47, 'layer_3_size': 59, 'layer_4_size': 62, 'layer_5_size': 187, 'layer_6_size': 195, 'dropout_rate': 0.12893509488244764, 'learning_rate': 0.00010751767164928035, 'batch_size': 128, 'epochs': 37}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/37, Train Loss: 0.000189, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Train Loss: 0.000604, Test Loss: 0.000174\n",
      "Epoch 2/40, Train Loss: 0.000301, Test Loss: 0.000185\n",
      "Epoch 3/40, Train Loss: 0.000259, Test Loss: 0.000179\n",
      "Epoch 4/40, Train Loss: 0.000240, Test Loss: 0.000173\n",
      "Epoch 5/40, Train Loss: 0.000232, Test Loss: 0.000171\n",
      "Epoch 6/40, Train Loss: 0.000224, Test Loss: 0.000176\n",
      "Epoch 7/40, Train Loss: 0.000220, Test Loss: 0.000175\n",
      "Epoch 8/40, Train Loss: 0.000216, Test Loss: 0.000169\n",
      "Epoch 9/40, Train Loss: 0.000212, Test Loss: 0.000168\n",
      "Epoch 10/40, Train Loss: 0.000209, Test Loss: 0.000173\n",
      "Epoch 11/40, Train Loss: 0.000206, Test Loss: 0.000167\n",
      "Epoch 12/40, Train Loss: 0.000204, Test Loss: 0.000165\n",
      "Epoch 13/40, Train Loss: 0.000201, Test Loss: 0.000167\n",
      "Epoch 14/40, Train Loss: 0.000201, Test Loss: 0.000170\n",
      "Epoch 15/40, Train Loss: 0.000201, Test Loss: 0.000168\n",
      "Epoch 16/40, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 17/40, Train Loss: 0.000198, Test Loss: 0.000166\n",
      "Epoch 18/40, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 19/40, Train Loss: 0.000196, Test Loss: 0.000165\n",
      "Epoch 20/40, Train Loss: 0.000196, Test Loss: 0.000165\n",
      "Epoch 21/40, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 22/40, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 23/40, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 24/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 25/40, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 26/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 27/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 28/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 29/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 30/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 31/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 32/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 33/40, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 34/40, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 35/40, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 36/40, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 37/40, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 38/40, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 39/40, Train Loss: 0.000187, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:00:07,246] Trial 51 finished with value: 0.00016512516286994587 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 132, 'layer_1_size': 242, 'layer_2_size': 60, 'layer_3_size': 62, 'layer_4_size': 112, 'dropout_rate': 0.1463087936972833, 'learning_rate': 5.1155719211369585e-05, 'batch_size': 32, 'epochs': 40}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40, Train Loss: 0.000186, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36, Train Loss: 0.000442, Test Loss: 0.000170\n",
      "Epoch 2/36, Train Loss: 0.000227, Test Loss: 0.000170\n",
      "Epoch 3/36, Train Loss: 0.000202, Test Loss: 0.000168\n",
      "Epoch 4/36, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 5/36, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 6/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 7/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 8/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/36, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/36, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 11/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/36, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 14/36, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/36, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 16/36, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/36, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 18/36, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 19/36, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 20/36, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 21/36, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 22/36, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 23/36, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 24/36, Train Loss: 0.000187, Test Loss: 0.000163\n",
      "Epoch 25/36, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 26/36, Train Loss: 0.000182, Test Loss: 0.000164\n",
      "Epoch 27/36, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 28/36, Train Loss: 0.000185, Test Loss: 0.000164\n",
      "Epoch 29/36, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 30/36, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 31/36, Train Loss: 0.000182, Test Loss: 0.000165\n",
      "Epoch 32/36, Train Loss: 0.000182, Test Loss: 0.000165\n",
      "Epoch 33/36, Train Loss: 0.000183, Test Loss: 0.000165\n",
      "Epoch 34/36, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 35/36, Train Loss: 0.000176, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:00:38,580] Trial 52 finished with value: 0.00016456700458522186 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 195, 'layer_1_size': 235, 'layer_2_size': 43, 'dropout_rate': 0.16740500022130864, 'learning_rate': 0.00028032474391307885, 'batch_size': 32, 'epochs': 36}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/36, Train Loss: 0.000177, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33, Train Loss: 0.000210, Test Loss: 0.000168\n",
      "Epoch 2/33, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 3/33, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 4/33, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 5/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 6/33, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 7/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/33, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 13/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/33, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 18/33, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 19/33, Train Loss: 0.000190, Test Loss: 0.000163\n",
      "Epoch 20/33, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 21/33, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 22/33, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 23/33, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 24/33, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 25/33, Train Loss: 0.000190, Test Loss: 0.000180\n",
      "Epoch 26/33, Train Loss: 0.000189, Test Loss: 0.000163\n",
      "Epoch 27/33, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 28/33, Train Loss: 0.000182, Test Loss: 0.000164\n",
      "Epoch 29/33, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 30/33, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 31/33, Train Loss: 0.000182, Test Loss: 0.000167\n",
      "Epoch 32/33, Train Loss: 0.000184, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:01:07,583] Trial 53 finished with value: 0.00016602657397822527 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 195, 'layer_1_size': 233, 'layer_2_size': 43, 'dropout_rate': 0.1675914635488286, 'learning_rate': 0.00029664527687241454, 'batch_size': 32, 'epochs': 33}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/33, Train Loss: 0.000189, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37, Train Loss: 0.000409, Test Loss: 0.000170\n",
      "Epoch 2/37, Train Loss: 0.000229, Test Loss: 0.000170\n",
      "Epoch 3/37, Train Loss: 0.000205, Test Loss: 0.000173\n",
      "Epoch 4/37, Train Loss: 0.000198, Test Loss: 0.000170\n",
      "Epoch 5/37, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 6/37, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 7/37, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 8/37, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 9/37, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 10/37, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 11/37, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/37, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 13/37, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 14/37, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/37, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 16/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/37, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 18/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 20/37, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 21/37, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 22/37, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 23/37, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 24/37, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 25/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 26/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 27/37, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 28/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 29/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 30/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 31/37, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 32/37, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 33/37, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 34/37, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 35/37, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 36/37, Train Loss: 0.000190, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:01:40,763] Trial 54 finished with value: 0.0001665101084940503 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 223, 'layer_1_size': 192, 'layer_2_size': 56, 'layer_3_size': 98, 'dropout_rate': 0.3771921820119982, 'learning_rate': 0.0001570501154208041, 'batch_size': 32, 'epochs': 37}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/37, Train Loss: 0.000191, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35, Train Loss: 0.000244, Test Loss: 0.000170\n",
      "Epoch 2/35, Train Loss: 0.000202, Test Loss: 0.000170\n",
      "Epoch 3/35, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 4/35, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 5/35, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 6/35, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/35, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 8/35, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/35, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 10/35, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/35, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/35, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/35, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/35, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 15/35, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/35, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 18/35, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 19/35, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 20/35, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 21/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 23/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 25/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 26/35, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 27/35, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 28/35, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 29/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 30/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 31/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 32/35, Train Loss: 0.000189, Test Loss: 0.000169\n",
      "Epoch 33/35, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 34/35, Train Loss: 0.000192, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:02:56,453] Trial 55 finished with value: 0.0001653246216161249 and parameters: {'num_hidden_layers': 10, 'layer_0_size': 169, 'layer_1_size': 207, 'layer_2_size': 40, 'layer_3_size': 105, 'layer_4_size': 38, 'layer_5_size': 92, 'layer_6_size': 93, 'layer_7_size': 32, 'layer_8_size': 249, 'layer_9_size': 51, 'dropout_rate': 0.12281572506413524, 'learning_rate': 0.00025688912032073303, 'batch_size': 32, 'epochs': 35}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/35, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38, Train Loss: 0.000280, Test Loss: 0.000170\n",
      "Epoch 2/38, Train Loss: 0.000212, Test Loss: 0.000169\n",
      "Epoch 3/38, Train Loss: 0.000202, Test Loss: 0.000168\n",
      "Epoch 4/38, Train Loss: 0.000198, Test Loss: 0.000167\n",
      "Epoch 5/38, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 6/38, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 7/38, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 8/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 10/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 11/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/38, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/38, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 16/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/38, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 21/38, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 22/38, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 23/38, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 24/38, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 25/38, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 26/38, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 27/38, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 28/38, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 29/38, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 30/38, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 31/38, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 32/38, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 33/38, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 34/38, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 35/38, Train Loss: 0.000188, Test Loss: 0.000167\n",
      "Epoch 36/38, Train Loss: 0.000186, Test Loss: 0.000167\n",
      "Epoch 37/38, Train Loss: 0.000187, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:03:33,916] Trial 56 finished with value: 0.00016815580379021675 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 46, 'layer_1_size': 237, 'layer_2_size': 78, 'layer_3_size': 149, 'dropout_rate': 0.16451415375335518, 'learning_rate': 8.168182413288792e-05, 'batch_size': 32, 'epochs': 38}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/38, Train Loss: 0.000186, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34, Train Loss: 0.000281, Test Loss: 0.000166\n",
      "Epoch 2/34, Train Loss: 0.000201, Test Loss: 0.000167\n",
      "Epoch 3/34, Train Loss: 0.000198, Test Loss: 0.000167\n",
      "Epoch 4/34, Train Loss: 0.000194, Test Loss: 0.000176\n",
      "Epoch 5/34, Train Loss: 0.000193, Test Loss: 0.000164\n",
      "Epoch 6/34, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 7/34, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/34, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 9/34, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 10/34, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 11/34, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 12/34, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/34, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/34, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 15/34, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 16/34, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 17/34, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 18/34, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 19/34, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/34, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 21/34, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 22/34, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 23/34, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 24/34, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 25/34, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 26/34, Train Loss: 0.000187, Test Loss: 0.000167\n",
      "Epoch 27/34, Train Loss: 0.000185, Test Loss: 0.000164\n",
      "Epoch 28/34, Train Loss: 0.000176, Test Loss: 0.000166\n",
      "Epoch 29/34, Train Loss: 0.000179, Test Loss: 0.000167\n",
      "Epoch 30/34, Train Loss: 0.000179, Test Loss: 0.000166\n",
      "Epoch 31/34, Train Loss: 0.000171, Test Loss: 0.000167\n",
      "Epoch 32/34, Train Loss: 0.000169, Test Loss: 0.000163\n",
      "Epoch 33/34, Train Loss: 0.000166, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:03:50,369] Trial 57 finished with value: 0.0001644061207659228 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 180, 'layer_1_size': 221, 'layer_2_size': 63, 'dropout_rate': 0.14748198972645582, 'learning_rate': 0.0003695468166745758, 'batch_size': 64, 'epochs': 34}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/34, Train Loss: 0.000190, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33, Train Loss: 0.000212, Test Loss: 0.000168\n",
      "Epoch 2/33, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 3/33, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 4/33, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 5/33, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 6/33, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 7/33, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 8/33, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/33, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 10/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/33, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 13/33, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 14/33, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 15/33, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 16/33, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 17/33, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 18/33, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 19/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 21/33, Train Loss: 0.000192, Test Loss: 0.000170\n",
      "Epoch 22/33, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 23/33, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 24/33, Train Loss: 0.000194, Test Loss: 0.000170\n",
      "Epoch 25/33, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 26/33, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 27/33, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 28/33, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 29/33, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 30/33, Train Loss: 0.000191, Test Loss: 0.000177\n",
      "Epoch 31/33, Train Loss: 0.000186, Test Loss: 0.000167\n",
      "Epoch 32/33, Train Loss: 0.000185, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:04:24,525] Trial 58 finished with value: 0.00016959720319171596 and parameters: {'num_hidden_layers': 6, 'layer_0_size': 177, 'layer_1_size': 220, 'layer_2_size': 181, 'layer_3_size': 136, 'layer_4_size': 70, 'layer_5_size': 132, 'dropout_rate': 0.14631028087554104, 'learning_rate': 0.0007488104411358215, 'batch_size': 64, 'epochs': 33}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/33, Train Loss: 0.000196, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.000219, Test Loss: 0.000175\n",
      "Epoch 2/30, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 3/30, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 4/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 5/30, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 6/30, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 7/30, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/30, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/30, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/30, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 11/30, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 12/30, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/30, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 14/30, Train Loss: 0.000190, Test Loss: 0.000168\n",
      "Epoch 15/30, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 16/30, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/30, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 18/30, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 19/30, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 20/30, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 21/30, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 22/30, Train Loss: 0.000188, Test Loss: 0.000167\n",
      "Epoch 23/30, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 24/30, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 25/30, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 26/30, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 27/30, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 28/30, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 29/30, Train Loss: 0.000185, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:04:42,130] Trial 59 finished with value: 0.00016519833071660902 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 65, 'layer_1_size': 171, 'layer_2_size': 94, 'layer_3_size': 163, 'dropout_rate': 0.10799101053738251, 'learning_rate': 0.00044940576904677835, 'batch_size': 64, 'epochs': 30}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.000185, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34, Train Loss: 0.000225, Test Loss: 0.000167\n",
      "Epoch 2/34, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 3/34, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 4/34, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 5/34, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 6/34, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 7/34, Train Loss: 0.000193, Test Loss: 0.000171\n",
      "Epoch 8/34, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/34, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 10/34, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 11/34, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/34, Train Loss: 0.000193, Test Loss: 0.000169\n",
      "Epoch 13/34, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 14/34, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 15/34, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 16/34, Train Loss: 0.000193, Test Loss: 0.000169\n",
      "Epoch 17/34, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 18/34, Train Loss: 0.000192, Test Loss: 0.000170\n",
      "Epoch 19/34, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 20/34, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 21/34, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 22/34, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 23/34, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 24/34, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 25/34, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 26/34, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 27/34, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 28/34, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 29/34, Train Loss: 0.000192, Test Loss: 0.000174\n",
      "Epoch 30/34, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 31/34, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 32/34, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 33/34, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:05:24,917] Trial 60 finished with value: 0.00016592413825741636 and parameters: {'num_hidden_layers': 8, 'layer_0_size': 189, 'layer_1_size': 189, 'layer_2_size': 62, 'layer_3_size': 71, 'layer_4_size': 132, 'layer_5_size': 202, 'layer_6_size': 179, 'layer_7_size': 132, 'dropout_rate': 0.13743686413638048, 'learning_rate': 0.0011117451509653929, 'batch_size': 64, 'epochs': 34}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/34, Train Loss: 0.000193, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36, Train Loss: 0.000206, Test Loss: 0.000168\n",
      "Epoch 2/36, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 3/36, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 4/36, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 5/36, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 6/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 7/36, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/36, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/36, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/36, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 11/36, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 12/36, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/36, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/36, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 15/36, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 16/36, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 17/36, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 18/36, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 19/36, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 20/36, Train Loss: 0.000192, Test Loss: 0.000163\n",
      "Epoch 21/36, Train Loss: 0.000188, Test Loss: 0.000163\n",
      "Epoch 22/36, Train Loss: 0.000188, Test Loss: 0.000182\n",
      "Epoch 23/36, Train Loss: 0.000209, Test Loss: 0.000168\n",
      "Epoch 24/36, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 25/36, Train Loss: 0.000187, Test Loss: 0.000163\n",
      "Epoch 26/36, Train Loss: 0.000186, Test Loss: 0.000163\n",
      "Epoch 27/36, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 28/36, Train Loss: 0.000183, Test Loss: 0.000163\n",
      "Epoch 29/36, Train Loss: 0.000183, Test Loss: 0.000163\n",
      "Epoch 30/36, Train Loss: 0.000183, Test Loss: 0.000166\n",
      "Epoch 31/36, Train Loss: 0.000186, Test Loss: 0.000167\n",
      "Epoch 32/36, Train Loss: 0.000178, Test Loss: 0.000163\n",
      "Epoch 33/36, Train Loss: 0.000179, Test Loss: 0.000164\n",
      "Epoch 34/36, Train Loss: 0.000184, Test Loss: 0.000162\n",
      "Epoch 35/36, Train Loss: 0.000169, Test Loss: 0.000174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:05:44,566] Trial 61 finished with value: 0.00016559309621345987 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 207, 'layer_1_size': 225, 'layer_2_size': 40, 'dropout_rate': 0.18084210997525466, 'learning_rate': 0.00021501431225984946, 'batch_size': 64, 'epochs': 36}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/36, Train Loss: 0.000161, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38, Train Loss: 0.000200, Test Loss: 0.000168\n",
      "Epoch 2/38, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 3/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 4/38, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 5/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 6/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 7/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 8/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 9/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/38, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 11/38, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 12/38, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 13/38, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 14/38, Train Loss: 0.000189, Test Loss: 0.000163\n",
      "Epoch 15/38, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 16/38, Train Loss: 0.000186, Test Loss: 0.000164\n",
      "Epoch 17/38, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 18/38, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 19/38, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 20/38, Train Loss: 0.000184, Test Loss: 0.000166\n",
      "Epoch 21/38, Train Loss: 0.000184, Test Loss: 0.000162\n",
      "Epoch 22/38, Train Loss: 0.000181, Test Loss: 0.000164\n",
      "Epoch 23/38, Train Loss: 0.000176, Test Loss: 0.000166\n",
      "Epoch 24/38, Train Loss: 0.000175, Test Loss: 0.000166\n",
      "Epoch 25/38, Train Loss: 0.000176, Test Loss: 0.000166\n",
      "Epoch 26/38, Train Loss: 0.000173, Test Loss: 0.000166\n",
      "Epoch 27/38, Train Loss: 0.000168, Test Loss: 0.000166\n",
      "Epoch 28/38, Train Loss: 0.000150, Test Loss: 0.000166\n",
      "Epoch 29/38, Train Loss: 0.000170, Test Loss: 0.000166\n",
      "Epoch 30/38, Train Loss: 0.000158, Test Loss: 0.000166\n",
      "Epoch 31/38, Train Loss: 0.000157, Test Loss: 0.000166\n",
      "Epoch 32/38, Train Loss: 0.000176, Test Loss: 0.000166\n",
      "Epoch 33/38, Train Loss: 0.000142, Test Loss: 0.000165\n",
      "Epoch 34/38, Train Loss: 0.000149, Test Loss: 0.000167\n",
      "Epoch 35/38, Train Loss: 0.000159, Test Loss: 0.000166\n",
      "Epoch 36/38, Train Loss: 0.000141, Test Loss: 0.000166\n",
      "Epoch 37/38, Train Loss: 0.000142, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:06:14,127] Trial 62 finished with value: 0.000167200408885866 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 185, 'layer_1_size': 253, 'layer_2_size': 49, 'dropout_rate': 0.1003269772197708, 'learning_rate': 0.00014816811060611144, 'batch_size': 32, 'epochs': 38}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/38, Train Loss: 0.000154, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32, Train Loss: 0.000623, Test Loss: 0.000233\n",
      "Epoch 2/32, Train Loss: 0.000337, Test Loss: 0.000202\n",
      "Epoch 3/32, Train Loss: 0.000290, Test Loss: 0.000191\n",
      "Epoch 4/32, Train Loss: 0.000255, Test Loss: 0.000181\n",
      "Epoch 5/32, Train Loss: 0.000231, Test Loss: 0.000177\n",
      "Epoch 6/32, Train Loss: 0.000217, Test Loss: 0.000174\n",
      "Epoch 7/32, Train Loss: 0.000208, Test Loss: 0.000170\n",
      "Epoch 8/32, Train Loss: 0.000202, Test Loss: 0.000168\n",
      "Epoch 9/32, Train Loss: 0.000199, Test Loss: 0.000167\n",
      "Epoch 10/32, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 11/32, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 12/32, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 13/32, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/32, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 15/32, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 16/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/32, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 18/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/32, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 20/32, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 21/32, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 22/32, Train Loss: 0.000189, Test Loss: 0.000163\n",
      "Epoch 23/32, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 24/32, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 25/32, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 26/32, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 27/32, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 28/32, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 29/32, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 30/32, Train Loss: 0.000186, Test Loss: 0.000164\n",
      "Epoch 31/32, Train Loss: 0.000186, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:06:31,749] Trial 63 finished with value: 0.00016499320316605066 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 167, 'layer_1_size': 207, 'layer_2_size': 32, 'dropout_rate': 0.19779685746077388, 'learning_rate': 9.971434134301413e-05, 'batch_size': 64, 'epochs': 32}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/32, Train Loss: 0.000184, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39, Train Loss: 0.000312, Test Loss: 0.000170\n",
      "Epoch 2/39, Train Loss: 0.000204, Test Loss: 0.000170\n",
      "Epoch 3/39, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 4/39, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 5/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 6/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 8/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 11/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/39, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 13/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/39, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 15/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/39, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 17/39, Train Loss: 0.000191, Test Loss: 0.000163\n",
      "Epoch 18/39, Train Loss: 0.000191, Test Loss: 0.000163\n",
      "Epoch 19/39, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 20/39, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 21/39, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 22/39, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 23/39, Train Loss: 0.000188, Test Loss: 0.000167\n",
      "Epoch 24/39, Train Loss: 0.000188, Test Loss: 0.000163\n",
      "Epoch 25/39, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 26/39, Train Loss: 0.000187, Test Loss: 0.000167\n",
      "Epoch 27/39, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 28/39, Train Loss: 0.000184, Test Loss: 0.000166\n",
      "Epoch 29/39, Train Loss: 0.000184, Test Loss: 0.000165\n",
      "Epoch 30/39, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 31/39, Train Loss: 0.000178, Test Loss: 0.000168\n",
      "Epoch 32/39, Train Loss: 0.000177, Test Loss: 0.000166\n",
      "Epoch 33/39, Train Loss: 0.000183, Test Loss: 0.000165\n",
      "Epoch 34/39, Train Loss: 0.000180, Test Loss: 0.000165\n",
      "Epoch 35/39, Train Loss: 0.000184, Test Loss: 0.000164\n",
      "Epoch 36/39, Train Loss: 0.000187, Test Loss: 0.000163\n",
      "Epoch 37/39, Train Loss: 0.000178, Test Loss: 0.000164\n",
      "Epoch 38/39, Train Loss: 0.000172, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:06:56,565] Trial 64 finished with value: 0.00016474458555553758 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 156, 'layer_1_size': 243, 'dropout_rate': 0.167711750143323, 'learning_rate': 0.00037943319554394983, 'batch_size': 32, 'epochs': 39}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/39, Train Loss: 0.000180, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35, Train Loss: 0.000285, Test Loss: 0.000168\n",
      "Epoch 2/35, Train Loss: 0.000240, Test Loss: 0.000170\n",
      "Epoch 3/35, Train Loss: 0.000225, Test Loss: 0.000167\n",
      "Epoch 4/35, Train Loss: 0.000218, Test Loss: 0.000166\n",
      "Epoch 5/35, Train Loss: 0.000212, Test Loss: 0.000166\n",
      "Epoch 6/35, Train Loss: 0.000208, Test Loss: 0.000166\n",
      "Epoch 7/35, Train Loss: 0.000205, Test Loss: 0.000165\n",
      "Epoch 8/35, Train Loss: 0.000205, Test Loss: 0.000166\n",
      "Epoch 9/35, Train Loss: 0.000200, Test Loss: 0.000165\n",
      "Epoch 10/35, Train Loss: 0.000199, Test Loss: 0.000166\n",
      "Epoch 11/35, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 12/35, Train Loss: 0.000196, Test Loss: 0.000165\n",
      "Epoch 13/35, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 14/35, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 15/35, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 16/35, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/35, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 18/35, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/35, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 20/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/35, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 23/35, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 24/35, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/35, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 26/35, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 27/35, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 28/35, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 29/35, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 30/35, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 31/35, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 32/35, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 33/35, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 34/35, Train Loss: 0.000184, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:07:07,841] Trial 65 finished with value: 0.00016919799928737415 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 197, 'layer_1_size': 201, 'layer_2_size': 55, 'layer_3_size': 43, 'dropout_rate': 0.14097844189432684, 'learning_rate': 0.0002171579036821676, 'batch_size': 256, 'epochs': 35}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/35, Train Loss: 0.000180, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/31, Train Loss: 0.000217, Test Loss: 0.000168\n",
      "Epoch 2/31, Train Loss: 0.000219, Test Loss: 0.000166\n",
      "Epoch 3/31, Train Loss: 0.000198, Test Loss: 0.000169\n",
      "Epoch 4/31, Train Loss: 0.000197, Test Loss: 0.000165\n",
      "Epoch 5/31, Train Loss: 0.000196, Test Loss: 0.000165\n",
      "Epoch 6/31, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 7/31, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 8/31, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/31, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/31, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/31, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/31, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/31, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/31, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/31, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/31, Train Loss: 0.000190, Test Loss: 0.000176\n",
      "Epoch 17/31, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 18/31, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 19/31, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 20/31, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 21/31, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/31, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 23/31, Train Loss: 0.000188, Test Loss: 0.000163\n",
      "Epoch 24/31, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 25/31, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 26/31, Train Loss: 0.000184, Test Loss: 0.000163\n",
      "Epoch 27/31, Train Loss: 0.000181, Test Loss: 0.000165\n",
      "Epoch 28/31, Train Loss: 0.000180, Test Loss: 0.000165\n",
      "Epoch 29/31, Train Loss: 0.000178, Test Loss: 0.000165\n",
      "Epoch 30/31, Train Loss: 0.000177, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:07:31,904] Trial 66 finished with value: 0.00016581411113835906 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 80, 'layer_1_size': 226, 'layer_2_size': 224, 'layer_3_size': 225, 'layer_4_size': 96, 'dropout_rate': 0.11939947806474593, 'learning_rate': 0.0001282819467611241, 'batch_size': 64, 'epochs': 31}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/31, Train Loss: 0.000173, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36, Train Loss: 0.000879, Test Loss: 0.000210\n",
      "Epoch 2/36, Train Loss: 0.000423, Test Loss: 0.000194\n",
      "Epoch 3/36, Train Loss: 0.000325, Test Loss: 0.000192\n",
      "Epoch 4/36, Train Loss: 0.000276, Test Loss: 0.000190\n",
      "Epoch 5/36, Train Loss: 0.000252, Test Loss: 0.000188\n",
      "Epoch 6/36, Train Loss: 0.000238, Test Loss: 0.000188\n",
      "Epoch 7/36, Train Loss: 0.000230, Test Loss: 0.000181\n",
      "Epoch 8/36, Train Loss: 0.000222, Test Loss: 0.000185\n",
      "Epoch 9/36, Train Loss: 0.000218, Test Loss: 0.000175\n",
      "Epoch 10/36, Train Loss: 0.000213, Test Loss: 0.000176\n",
      "Epoch 11/36, Train Loss: 0.000211, Test Loss: 0.000175\n",
      "Epoch 12/36, Train Loss: 0.000208, Test Loss: 0.000173\n",
      "Epoch 13/36, Train Loss: 0.000204, Test Loss: 0.000172\n",
      "Epoch 14/36, Train Loss: 0.000203, Test Loss: 0.000171\n",
      "Epoch 15/36, Train Loss: 0.000202, Test Loss: 0.000173\n",
      "Epoch 16/36, Train Loss: 0.000199, Test Loss: 0.000171\n",
      "Epoch 17/36, Train Loss: 0.000198, Test Loss: 0.000170\n",
      "Epoch 18/36, Train Loss: 0.000206, Test Loss: 0.000166\n",
      "Epoch 19/36, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 20/36, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 21/36, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 22/36, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 23/36, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 24/36, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 25/36, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 26/36, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 27/36, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 28/36, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 29/36, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 30/36, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 31/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 32/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 33/36, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 34/36, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 35/36, Train Loss: 0.000192, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:07:42,008] Trial 67 finished with value: 0.0001656198080655163 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 149, 'layer_1_size': 129, 'dropout_rate': 0.17620208451447386, 'learning_rate': 5.7269853080430715e-05, 'batch_size': 128, 'epochs': 36}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/36, Train Loss: 0.000191, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29, Train Loss: 0.000256, Test Loss: 0.000167\n",
      "Epoch 2/29, Train Loss: 0.000199, Test Loss: 0.000166\n",
      "Epoch 3/29, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 4/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 5/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 6/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 7/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/29, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 10/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/29, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 15/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/29, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 17/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 18/29, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 19/29, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 20/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 21/29, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 22/29, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 23/29, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 24/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 25/29, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 26/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 27/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 28/29, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:08:06,578] Trial 68 finished with value: 0.0001657252597110968 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 237, 'layer_1_size': 237, 'layer_2_size': 63, 'dropout_rate': 0.15428871278821604, 'learning_rate': 0.0005171788595427278, 'batch_size': 32, 'epochs': 29}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29, Train Loss: 0.000191, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34, Train Loss: 0.000298, Test Loss: 0.000173\n",
      "Epoch 2/34, Train Loss: 0.000204, Test Loss: 0.000174\n",
      "Epoch 3/34, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 4/34, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 5/34, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 6/34, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/34, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 8/34, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/34, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/34, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/34, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/34, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 13/34, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/34, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/34, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 16/34, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 17/34, Train Loss: 0.000190, Test Loss: 0.000163\n",
      "Epoch 18/34, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/34, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/34, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 21/34, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 22/34, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 23/34, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 24/34, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 25/34, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 26/34, Train Loss: 0.000269, Test Loss: 0.000168\n",
      "Epoch 27/34, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 28/34, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 29/34, Train Loss: 0.000186, Test Loss: 0.000172\n",
      "Epoch 30/34, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 31/34, Train Loss: 0.000181, Test Loss: 0.000166\n",
      "Epoch 32/34, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 33/34, Train Loss: 0.000189, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:08:25,878] Trial 69 finished with value: 0.00016745896810503366 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 96, 'layer_1_size': 186, 'dropout_rate': 0.1980602725163677, 'learning_rate': 0.0003278993260783386, 'batch_size': 32, 'epochs': 34}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/34, Train Loss: 0.000181, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27, Train Loss: 0.000481, Test Loss: 0.000179\n",
      "Epoch 2/27, Train Loss: 0.000275, Test Loss: 0.000175\n",
      "Epoch 3/27, Train Loss: 0.000239, Test Loss: 0.000172\n",
      "Epoch 4/27, Train Loss: 0.000220, Test Loss: 0.000171\n",
      "Epoch 5/27, Train Loss: 0.000207, Test Loss: 0.000169\n",
      "Epoch 6/27, Train Loss: 0.000201, Test Loss: 0.000168\n",
      "Epoch 7/27, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 8/27, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 9/27, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 10/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 11/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/27, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 13/27, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 14/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 18/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 23/27, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 24/27, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 25/27, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 26/27, Train Loss: 0.000190, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:08:41,566] Trial 70 finished with value: 0.0001642247390236662 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 205, 'layer_1_size': 170, 'layer_2_size': 40, 'layer_3_size': 49, 'dropout_rate': 0.21720892782177736, 'learning_rate': 0.0001718041570476627, 'batch_size': 64, 'epochs': 27}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/27, Train Loss: 0.000190, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27, Train Loss: 0.000640, Test Loss: 0.000170\n",
      "Epoch 2/27, Train Loss: 0.000329, Test Loss: 0.000170\n",
      "Epoch 3/27, Train Loss: 0.000268, Test Loss: 0.000171\n",
      "Epoch 4/27, Train Loss: 0.000236, Test Loss: 0.000178\n",
      "Epoch 5/27, Train Loss: 0.000218, Test Loss: 0.000174\n",
      "Epoch 6/27, Train Loss: 0.000207, Test Loss: 0.000175\n",
      "Epoch 7/27, Train Loss: 0.000200, Test Loss: 0.000169\n",
      "Epoch 8/27, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 9/27, Train Loss: 0.000195, Test Loss: 0.000170\n",
      "Epoch 10/27, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 11/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 13/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 14/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 15/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 16/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 18/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 20/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 21/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 22/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 23/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/27, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/27, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 26/27, Train Loss: 0.000191, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:08:58,068] Trial 71 finished with value: 0.00016427205268002815 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 206, 'layer_1_size': 154, 'layer_2_size': 40, 'layer_3_size': 49, 'dropout_rate': 0.23294020208165422, 'learning_rate': 0.0001810161453657087, 'batch_size': 64, 'epochs': 27}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/27, Train Loss: 0.000191, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26, Train Loss: 0.000912, Test Loss: 0.000189\n",
      "Epoch 2/26, Train Loss: 0.000308, Test Loss: 0.000215\n",
      "Epoch 3/26, Train Loss: 0.000269, Test Loss: 0.000214\n",
      "Epoch 4/26, Train Loss: 0.000248, Test Loss: 0.000199\n",
      "Epoch 5/26, Train Loss: 0.000231, Test Loss: 0.000183\n",
      "Epoch 6/26, Train Loss: 0.000221, Test Loss: 0.000188\n",
      "Epoch 7/26, Train Loss: 0.000213, Test Loss: 0.000180\n",
      "Epoch 8/26, Train Loss: 0.000208, Test Loss: 0.000177\n",
      "Epoch 9/26, Train Loss: 0.000203, Test Loss: 0.000172\n",
      "Epoch 10/26, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 11/26, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 12/26, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 13/26, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 14/26, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 15/26, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 16/26, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 17/26, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 18/26, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 19/26, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 20/26, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 21/26, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 22/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 23/26, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 24/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 25/26, Train Loss: 0.000192, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:09:12,885] Trial 72 finished with value: 0.00016510762990888436 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 207, 'layer_1_size': 153, 'layer_2_size': 39, 'layer_3_size': 52, 'dropout_rate': 0.24098881384954998, 'learning_rate': 7.587372844534632e-05, 'batch_size': 64, 'epochs': 26}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/26, Train Loss: 0.000206, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Train Loss: 0.000294, Test Loss: 0.000171\n",
      "Epoch 2/24, Train Loss: 0.000210, Test Loss: 0.000170\n",
      "Epoch 3/24, Train Loss: 0.000203, Test Loss: 0.000169\n",
      "Epoch 4/24, Train Loss: 0.000198, Test Loss: 0.000172\n",
      "Epoch 5/24, Train Loss: 0.000197, Test Loss: 0.000172\n",
      "Epoch 6/24, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 7/24, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 8/24, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 9/24, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 10/24, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 11/24, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 12/24, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 13/24, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/24, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/24, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 16/24, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 17/24, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 18/24, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/24, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/24, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/24, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/24, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 23/24, Train Loss: 0.000191, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:09:29,678] Trial 73 finished with value: 0.00016792322920141048 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 220, 'layer_1_size': 174, 'layer_2_size': 50, 'layer_3_size': 70, 'layer_4_size': 164, 'dropout_rate': 0.22073354401881778, 'learning_rate': 0.0001631863454575338, 'batch_size': 64, 'epochs': 24}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Train Loss: 0.000191, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28, Train Loss: 0.000284, Test Loss: 0.000178\n",
      "Epoch 2/28, Train Loss: 0.000206, Test Loss: 0.000174\n",
      "Epoch 3/28, Train Loss: 0.000199, Test Loss: 0.000169\n",
      "Epoch 4/28, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 5/28, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 6/28, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/28, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 8/28, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/28, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 10/28, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/28, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 12/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/28, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 15/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/28, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/28, Train Loss: 0.000193, Test Loss: 0.000164\n",
      "Epoch 19/28, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/28, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 21/28, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 22/28, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 23/28, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 24/28, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 25/28, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 26/28, Train Loss: 0.000188, Test Loss: 0.000163\n",
      "Epoch 27/28, Train Loss: 0.000186, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:09:45,460] Trial 74 finished with value: 0.00016484383359643436 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 162, 'layer_1_size': 165, 'layer_2_size': 75, 'layer_3_size': 47, 'dropout_rate': 0.214022234029332, 'learning_rate': 0.00019903207424604172, 'batch_size': 64, 'epochs': 28}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/28, Train Loss: 0.000189, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27, Train Loss: 0.000563, Test Loss: 0.000205\n",
      "Epoch 2/27, Train Loss: 0.000324, Test Loss: 0.000185\n",
      "Epoch 3/27, Train Loss: 0.000282, Test Loss: 0.000171\n",
      "Epoch 4/27, Train Loss: 0.000254, Test Loss: 0.000172\n",
      "Epoch 5/27, Train Loss: 0.000236, Test Loss: 0.000169\n",
      "Epoch 6/27, Train Loss: 0.000223, Test Loss: 0.000170\n",
      "Epoch 7/27, Train Loss: 0.000214, Test Loss: 0.000168\n",
      "Epoch 8/27, Train Loss: 0.000208, Test Loss: 0.000168\n",
      "Epoch 9/27, Train Loss: 0.000203, Test Loss: 0.000168\n",
      "Epoch 10/27, Train Loss: 0.000200, Test Loss: 0.000168\n",
      "Epoch 11/27, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 12/27, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 13/27, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 14/27, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 15/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 16/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 17/27, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 18/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 19/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 20/27, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 21/27, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 22/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 23/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/27, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 26/27, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:10:04,462] Trial 75 finished with value: 0.0001643945304771654 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 237, 'layer_1_size': 139, 'layer_2_size': 155, 'layer_3_size': 84, 'layer_4_size': 53, 'dropout_rate': 0.2580473878224059, 'learning_rate': 0.00010806812529021242, 'batch_size': 64, 'epochs': 27}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/27, Train Loss: 0.000191, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26, Train Loss: 0.000413, Test Loss: 0.000171\n",
      "Epoch 2/26, Train Loss: 0.000230, Test Loss: 0.000176\n",
      "Epoch 3/26, Train Loss: 0.000213, Test Loss: 0.000188\n",
      "Epoch 4/26, Train Loss: 0.000206, Test Loss: 0.000180\n",
      "Epoch 5/26, Train Loss: 0.000202, Test Loss: 0.000176\n",
      "Epoch 6/26, Train Loss: 0.000200, Test Loss: 0.000174\n",
      "Epoch 7/26, Train Loss: 0.000197, Test Loss: 0.000171\n",
      "Epoch 8/26, Train Loss: 0.000197, Test Loss: 0.000171\n",
      "Epoch 9/26, Train Loss: 0.000196, Test Loss: 0.000171\n",
      "Epoch 10/26, Train Loss: 0.000196, Test Loss: 0.000172\n",
      "Epoch 11/26, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 12/26, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 13/26, Train Loss: 0.000195, Test Loss: 0.000170\n",
      "Epoch 14/26, Train Loss: 0.000195, Test Loss: 0.000170\n",
      "Epoch 15/26, Train Loss: 0.000195, Test Loss: 0.000170\n",
      "Epoch 16/26, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 17/26, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 18/26, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 19/26, Train Loss: 0.000194, Test Loss: 0.000169\n",
      "Epoch 20/26, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 21/26, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 22/26, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 23/26, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 24/26, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 25/26, Train Loss: 0.000193, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:10:21,988] Trial 76 finished with value: 0.00016671891817241562 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 227, 'layer_1_size': 135, 'layer_2_size': 154, 'layer_3_size': 85, 'layer_4_size': 51, 'dropout_rate': 0.2875095078768793, 'learning_rate': 4.3923021840893825e-05, 'batch_size': 64, 'epochs': 26}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/26, Train Loss: 0.000193, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27, Train Loss: 0.000395, Test Loss: 0.000169\n",
      "Epoch 2/27, Train Loss: 0.000244, Test Loss: 0.000172\n",
      "Epoch 3/27, Train Loss: 0.000219, Test Loss: 0.000185\n",
      "Epoch 4/27, Train Loss: 0.000211, Test Loss: 0.000193\n",
      "Epoch 5/27, Train Loss: 0.000206, Test Loss: 0.000185\n",
      "Epoch 6/27, Train Loss: 0.000202, Test Loss: 0.000185\n",
      "Epoch 7/27, Train Loss: 0.000200, Test Loss: 0.000182\n",
      "Epoch 8/27, Train Loss: 0.000199, Test Loss: 0.000177\n",
      "Epoch 9/27, Train Loss: 0.000197, Test Loss: 0.000172\n",
      "Epoch 10/27, Train Loss: 0.000196, Test Loss: 0.000177\n",
      "Epoch 11/27, Train Loss: 0.000195, Test Loss: 0.000172\n",
      "Epoch 12/27, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 13/27, Train Loss: 0.000194, Test Loss: 0.000169\n",
      "Epoch 14/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 15/27, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 16/27, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 17/27, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 18/27, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 19/27, Train Loss: 0.000191, Test Loss: 0.000173\n",
      "Epoch 20/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 21/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 22/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 23/27, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 24/27, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 25/27, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 26/27, Train Loss: 0.000191, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:10:46,556] Trial 77 finished with value: 0.00016586762903018332 and parameters: {'num_hidden_layers': 6, 'layer_0_size': 236, 'layer_1_size': 124, 'layer_2_size': 156, 'layer_3_size': 71, 'layer_4_size': 82, 'layer_5_size': 254, 'dropout_rate': 0.26601582519860445, 'learning_rate': 0.00010819442095066074, 'batch_size': 64, 'epochs': 27}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/27, Train Loss: 0.000191, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23, Train Loss: 0.000495, Test Loss: 0.000169\n",
      "Epoch 2/23, Train Loss: 0.000241, Test Loss: 0.000171\n",
      "Epoch 3/23, Train Loss: 0.000222, Test Loss: 0.000177\n",
      "Epoch 4/23, Train Loss: 0.000213, Test Loss: 0.000172\n",
      "Epoch 5/23, Train Loss: 0.000207, Test Loss: 0.000174\n",
      "Epoch 6/23, Train Loss: 0.000203, Test Loss: 0.000170\n",
      "Epoch 7/23, Train Loss: 0.000200, Test Loss: 0.000171\n",
      "Epoch 8/23, Train Loss: 0.000198, Test Loss: 0.000171\n",
      "Epoch 9/23, Train Loss: 0.000197, Test Loss: 0.000171\n",
      "Epoch 10/23, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 11/23, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 12/23, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 13/23, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 14/23, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 15/23, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 16/23, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 17/23, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 18/23, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 19/23, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 20/23, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 21/23, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 22/23, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:11:05,163] Trial 78 finished with value: 0.00016579213080779981 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 213, 'layer_1_size': 158, 'layer_2_size': 167, 'layer_3_size': 89, 'layer_4_size': 61, 'dropout_rate': 0.27436284661872906, 'learning_rate': 6.757868041332979e-05, 'batch_size': 64, 'epochs': 23}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/23, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 0.001064, Test Loss: 0.000443\n",
      "Epoch 2/25, Train Loss: 0.000679, Test Loss: 0.000237\n",
      "Epoch 3/25, Train Loss: 0.000612, Test Loss: 0.000204\n",
      "Epoch 4/25, Train Loss: 0.000569, Test Loss: 0.000198\n",
      "Epoch 5/25, Train Loss: 0.000553, Test Loss: 0.000196\n",
      "Epoch 6/25, Train Loss: 0.000527, Test Loss: 0.000195\n",
      "Epoch 7/25, Train Loss: 0.000506, Test Loss: 0.000193\n",
      "Epoch 8/25, Train Loss: 0.000485, Test Loss: 0.000191\n",
      "Epoch 9/25, Train Loss: 0.000467, Test Loss: 0.000190\n",
      "Epoch 10/25, Train Loss: 0.000453, Test Loss: 0.000188\n",
      "Epoch 11/25, Train Loss: 0.000436, Test Loss: 0.000188\n",
      "Epoch 12/25, Train Loss: 0.000422, Test Loss: 0.000186\n",
      "Epoch 13/25, Train Loss: 0.000413, Test Loss: 0.000184\n",
      "Epoch 14/25, Train Loss: 0.000398, Test Loss: 0.000184\n",
      "Epoch 15/25, Train Loss: 0.000386, Test Loss: 0.000184\n",
      "Epoch 16/25, Train Loss: 0.000374, Test Loss: 0.000182\n",
      "Epoch 17/25, Train Loss: 0.000362, Test Loss: 0.000183\n",
      "Epoch 18/25, Train Loss: 0.000356, Test Loss: 0.000181\n",
      "Epoch 19/25, Train Loss: 0.000345, Test Loss: 0.000178\n",
      "Epoch 20/25, Train Loss: 0.000344, Test Loss: 0.000179\n",
      "Epoch 21/25, Train Loss: 0.000333, Test Loss: 0.000177\n",
      "Epoch 22/25, Train Loss: 0.000323, Test Loss: 0.000177\n",
      "Epoch 23/25, Train Loss: 0.000316, Test Loss: 0.000176\n",
      "Epoch 24/25, Train Loss: 0.000312, Test Loss: 0.000174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:11:15,712] Trial 79 finished with value: 0.00017393908183294116 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 255, 'layer_1_size': 124, 'layer_2_size': 123, 'layer_3_size': 113, 'dropout_rate': 0.24092605579222362, 'learning_rate': 1.92444236752148e-06, 'batch_size': 128, 'epochs': 25}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Train Loss: 0.000300, Test Loss: 0.000174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27, Train Loss: 0.000257, Test Loss: 0.000170\n",
      "Epoch 2/27, Train Loss: 0.000203, Test Loss: 0.000170\n",
      "Epoch 3/27, Train Loss: 0.000198, Test Loss: 0.000170\n",
      "Epoch 4/27, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 5/27, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 6/27, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 7/27, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 8/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 10/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/27, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 13/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 18/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 20/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/27, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 23/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/27, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 25/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 26/27, Train Loss: 0.000190, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:11:39,314] Trial 80 finished with value: 0.00016452853320779762 and parameters: {'num_hidden_layers': 6, 'layer_0_size': 241, 'layer_1_size': 142, 'layer_2_size': 134, 'layer_3_size': 41, 'layer_4_size': 123, 'layer_5_size': 176, 'dropout_rate': 0.25465953934912217, 'learning_rate': 0.00013703887048200744, 'batch_size': 64, 'epochs': 27}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/27, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.002580, Test Loss: 0.000488\n",
      "Epoch 2/30, Train Loss: 0.000920, Test Loss: 0.000336\n",
      "Epoch 3/30, Train Loss: 0.000646, Test Loss: 0.000279\n",
      "Epoch 4/30, Train Loss: 0.000500, Test Loss: 0.000216\n",
      "Epoch 5/30, Train Loss: 0.000427, Test Loss: 0.000199\n",
      "Epoch 6/30, Train Loss: 0.000353, Test Loss: 0.000184\n",
      "Epoch 7/30, Train Loss: 0.000306, Test Loss: 0.000177\n",
      "Epoch 8/30, Train Loss: 0.000273, Test Loss: 0.000174\n",
      "Epoch 9/30, Train Loss: 0.000248, Test Loss: 0.000176\n",
      "Epoch 10/30, Train Loss: 0.000228, Test Loss: 0.000178\n",
      "Epoch 11/30, Train Loss: 0.000215, Test Loss: 0.000175\n",
      "Epoch 12/30, Train Loss: 0.000208, Test Loss: 0.000172\n",
      "Epoch 13/30, Train Loss: 0.000201, Test Loss: 0.000170\n",
      "Epoch 14/30, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 15/30, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 16/30, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 17/30, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 18/30, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 19/30, Train Loss: 0.000194, Test Loss: 0.000169\n",
      "Epoch 20/30, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 21/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 22/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 23/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 24/30, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 25/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 26/30, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 27/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 28/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 29/30, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:11:57,274] Trial 81 finished with value: 0.00016561155602938662 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 185, 'layer_1_size': 149, 'layer_2_size': 38, 'layer_3_size': 33, 'dropout_rate': 0.30234809252709216, 'learning_rate': 9.19032072040412e-05, 'batch_size': 64, 'epochs': 30}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32, Train Loss: 0.000420, Test Loss: 0.000210\n",
      "Epoch 2/32, Train Loss: 0.000248, Test Loss: 0.000187\n",
      "Epoch 3/32, Train Loss: 0.000221, Test Loss: 0.000176\n",
      "Epoch 4/32, Train Loss: 0.000209, Test Loss: 0.000168\n",
      "Epoch 5/32, Train Loss: 0.000202, Test Loss: 0.000168\n",
      "Epoch 6/32, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 7/32, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 8/32, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 9/32, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 10/32, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 11/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/32, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 15/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/32, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 18/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 23/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/32, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/32, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 26/32, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 27/32, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 28/32, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 29/32, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 30/32, Train Loss: 0.000188, Test Loss: 0.000163\n",
      "Epoch 31/32, Train Loss: 0.000188, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:12:22,202] Trial 82 finished with value: 0.00016309989249777807 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 171, 'layer_1_size': 162, 'layer_2_size': 51, 'dropout_rate': 0.21746728028064116, 'learning_rate': 0.00018608769084609475, 'batch_size': 64, 'epochs': 32}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/32, Train Loss: 0.000187, Test Loss: 0.000163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.000315, Test Loss: 0.000180\n",
      "Epoch 2/30, Train Loss: 0.000207, Test Loss: 0.000170\n",
      "Epoch 3/30, Train Loss: 0.000196, Test Loss: 0.000171\n",
      "Epoch 4/30, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 5/30, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 6/30, Train Loss: 0.000195, Test Loss: 0.000170\n",
      "Epoch 7/30, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 8/30, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 9/30, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 10/30, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 11/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 13/30, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 15/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 16/30, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/30, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 18/30, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/30, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 20/30, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/30, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 22/30, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 23/30, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/30, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 25/30, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 26/30, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 27/30, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 28/30, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 29/30, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:13:00,387] Trial 83 finished with value: 0.0001644689059136703 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 145, 'layer_1_size': 161, 'layer_2_size': 147, 'layer_3_size': 54, 'layer_4_size': 33, 'dropout_rate': 0.23418465925784937, 'learning_rate': 0.00023588309514949589, 'batch_size': 64, 'epochs': 30}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.000191, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28, Train Loss: 0.000300, Test Loss: 0.000169\n",
      "Epoch 2/28, Train Loss: 0.000215, Test Loss: 0.000171\n",
      "Epoch 3/28, Train Loss: 0.000203, Test Loss: 0.000169\n",
      "Epoch 4/28, Train Loss: 0.000199, Test Loss: 0.000167\n",
      "Epoch 5/28, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 6/28, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 7/28, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 8/28, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/28, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 10/28, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 11/28, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/28, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/28, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/28, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 16/28, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/28, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/28, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/28, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 20/28, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 21/28, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 22/28, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 23/28, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 24/28, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/28, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 26/28, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 27/28, Train Loss: 0.000188, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:13:26,721] Trial 84 finished with value: 0.00016629625076802768 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 250, 'layer_1_size': 168, 'layer_2_size': 53, 'layer_3_size': 92, 'dropout_rate': 0.21555178965700134, 'learning_rate': 0.00018275438179798904, 'batch_size': 64, 'epochs': 28}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/28, Train Loss: 0.000189, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32, Train Loss: 0.006683, Test Loss: 0.000347\n",
      "Epoch 2/32, Train Loss: 0.001382, Test Loss: 0.000277\n",
      "Epoch 3/32, Train Loss: 0.001073, Test Loss: 0.000292\n",
      "Epoch 4/32, Train Loss: 0.000921, Test Loss: 0.000286\n",
      "Epoch 5/32, Train Loss: 0.000809, Test Loss: 0.000309\n",
      "Epoch 6/32, Train Loss: 0.000753, Test Loss: 0.000265\n",
      "Epoch 7/32, Train Loss: 0.000695, Test Loss: 0.000264\n",
      "Epoch 8/32, Train Loss: 0.000652, Test Loss: 0.000280\n",
      "Epoch 9/32, Train Loss: 0.000594, Test Loss: 0.000273\n",
      "Epoch 10/32, Train Loss: 0.000566, Test Loss: 0.000253\n",
      "Epoch 11/32, Train Loss: 0.000520, Test Loss: 0.000238\n",
      "Epoch 12/32, Train Loss: 0.000492, Test Loss: 0.000226\n",
      "Epoch 13/32, Train Loss: 0.000448, Test Loss: 0.000222\n",
      "Epoch 14/32, Train Loss: 0.000424, Test Loss: 0.000221\n",
      "Epoch 15/32, Train Loss: 0.000396, Test Loss: 0.000199\n",
      "Epoch 16/32, Train Loss: 0.000370, Test Loss: 0.000200\n",
      "Epoch 17/32, Train Loss: 0.000353, Test Loss: 0.000196\n",
      "Epoch 18/32, Train Loss: 0.000329, Test Loss: 0.000191\n",
      "Epoch 19/32, Train Loss: 0.000314, Test Loss: 0.000187\n",
      "Epoch 20/32, Train Loss: 0.000294, Test Loss: 0.000184\n",
      "Epoch 21/32, Train Loss: 0.000285, Test Loss: 0.000181\n",
      "Epoch 22/32, Train Loss: 0.000272, Test Loss: 0.000182\n",
      "Epoch 23/32, Train Loss: 0.000264, Test Loss: 0.000175\n",
      "Epoch 24/32, Train Loss: 0.000252, Test Loss: 0.000174\n",
      "Epoch 25/32, Train Loss: 0.000247, Test Loss: 0.000173\n",
      "Epoch 26/32, Train Loss: 0.000242, Test Loss: 0.000172\n",
      "Epoch 27/32, Train Loss: 0.000234, Test Loss: 0.000171\n",
      "Epoch 28/32, Train Loss: 0.000229, Test Loss: 0.000171\n",
      "Epoch 29/32, Train Loss: 0.000225, Test Loss: 0.000169\n",
      "Epoch 30/32, Train Loss: 0.000221, Test Loss: 0.000169\n",
      "Epoch 31/32, Train Loss: 0.000217, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:13:46,412] Trial 85 finished with value: 0.00016815587664055902 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 170, 'layer_1_size': 140, 'layer_2_size': 32, 'dropout_rate': 0.20283715957372336, 'learning_rate': 2.1205928214664684e-05, 'batch_size': 64, 'epochs': 32}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/32, Train Loss: 0.000213, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29, Train Loss: 0.001336, Test Loss: 0.000220\n",
      "Epoch 2/29, Train Loss: 0.000536, Test Loss: 0.000234\n",
      "Epoch 3/29, Train Loss: 0.000444, Test Loss: 0.000214\n",
      "Epoch 4/29, Train Loss: 0.000400, Test Loss: 0.000226\n",
      "Epoch 5/29, Train Loss: 0.000364, Test Loss: 0.000228\n",
      "Epoch 6/29, Train Loss: 0.000335, Test Loss: 0.000198\n",
      "Epoch 7/29, Train Loss: 0.000309, Test Loss: 0.000202\n",
      "Epoch 8/29, Train Loss: 0.000295, Test Loss: 0.000185\n",
      "Epoch 9/29, Train Loss: 0.000276, Test Loss: 0.000181\n",
      "Epoch 10/29, Train Loss: 0.000260, Test Loss: 0.000175\n",
      "Epoch 11/29, Train Loss: 0.000254, Test Loss: 0.000184\n",
      "Epoch 12/29, Train Loss: 0.000241, Test Loss: 0.000171\n",
      "Epoch 13/29, Train Loss: 0.000235, Test Loss: 0.000172\n",
      "Epoch 14/29, Train Loss: 0.000226, Test Loss: 0.000172\n",
      "Epoch 15/29, Train Loss: 0.000220, Test Loss: 0.000168\n",
      "Epoch 16/29, Train Loss: 0.000215, Test Loss: 0.000168\n",
      "Epoch 17/29, Train Loss: 0.000211, Test Loss: 0.000167\n",
      "Epoch 18/29, Train Loss: 0.000206, Test Loss: 0.000168\n",
      "Epoch 19/29, Train Loss: 0.000204, Test Loss: 0.000167\n",
      "Epoch 20/29, Train Loss: 0.000202, Test Loss: 0.000167\n",
      "Epoch 21/29, Train Loss: 0.000200, Test Loss: 0.000167\n",
      "Epoch 22/29, Train Loss: 0.000199, Test Loss: 0.000167\n",
      "Epoch 23/29, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 24/29, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 25/29, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 26/29, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 27/29, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 28/29, Train Loss: 0.000194, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:13:57,809] Trial 86 finished with value: 0.00016675628285156563 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 118, 'layer_1_size': 156, 'layer_2_size': 47, 'dropout_rate': 0.19305355635189894, 'learning_rate': 0.00012105216660635503, 'batch_size': 128, 'epochs': 29}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29, Train Loss: 0.000192, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/31, Train Loss: 0.001903, Test Loss: 0.000228\n",
      "Epoch 2/31, Train Loss: 0.000807, Test Loss: 0.000208\n",
      "Epoch 3/31, Train Loss: 0.000678, Test Loss: 0.000202\n",
      "Epoch 4/31, Train Loss: 0.000606, Test Loss: 0.000196\n",
      "Epoch 5/31, Train Loss: 0.000537, Test Loss: 0.000204\n",
      "Epoch 6/31, Train Loss: 0.000494, Test Loss: 0.000197\n",
      "Epoch 7/31, Train Loss: 0.000464, Test Loss: 0.000204\n",
      "Epoch 8/31, Train Loss: 0.000436, Test Loss: 0.000205\n",
      "Epoch 9/31, Train Loss: 0.000405, Test Loss: 0.000193\n",
      "Epoch 10/31, Train Loss: 0.000388, Test Loss: 0.000194\n",
      "Epoch 11/31, Train Loss: 0.000375, Test Loss: 0.000187\n",
      "Epoch 12/31, Train Loss: 0.000363, Test Loss: 0.000183\n",
      "Epoch 13/31, Train Loss: 0.000357, Test Loss: 0.000178\n",
      "Epoch 14/31, Train Loss: 0.000342, Test Loss: 0.000173\n",
      "Epoch 15/31, Train Loss: 0.000334, Test Loss: 0.000177\n",
      "Epoch 16/31, Train Loss: 0.000331, Test Loss: 0.000175\n",
      "Epoch 17/31, Train Loss: 0.000326, Test Loss: 0.000172\n",
      "Epoch 18/31, Train Loss: 0.000315, Test Loss: 0.000173\n",
      "Epoch 19/31, Train Loss: 0.000311, Test Loss: 0.000173\n",
      "Epoch 20/31, Train Loss: 0.000304, Test Loss: 0.000172\n",
      "Epoch 21/31, Train Loss: 0.000300, Test Loss: 0.000171\n",
      "Epoch 22/31, Train Loss: 0.000294, Test Loss: 0.000171\n",
      "Epoch 23/31, Train Loss: 0.000289, Test Loss: 0.000171\n",
      "Epoch 24/31, Train Loss: 0.000285, Test Loss: 0.000170\n",
      "Epoch 25/31, Train Loss: 0.000283, Test Loss: 0.000171\n",
      "Epoch 26/31, Train Loss: 0.000276, Test Loss: 0.000171\n",
      "Epoch 27/31, Train Loss: 0.000274, Test Loss: 0.000171\n",
      "Epoch 28/31, Train Loss: 0.000268, Test Loss: 0.000170\n",
      "Epoch 29/31, Train Loss: 0.000263, Test Loss: 0.000170\n",
      "Epoch 30/31, Train Loss: 0.000261, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:14:10,594] Trial 87 finished with value: 0.00017122542164044364 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 69, 'layer_1_size': 186, 'layer_2_size': 39, 'layer_3_size': 65, 'dropout_rate': 0.24915647286755713, 'learning_rate': 4.6136980278288956e-05, 'batch_size': 256, 'epochs': 31}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/31, Train Loss: 0.000259, Test Loss: 0.000171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21, Train Loss: 0.000545, Test Loss: 0.000170\n",
      "Epoch 2/21, Train Loss: 0.000379, Test Loss: 0.000169\n",
      "Epoch 3/21, Train Loss: 0.000310, Test Loss: 0.000170\n",
      "Epoch 4/21, Train Loss: 0.000266, Test Loss: 0.000170\n",
      "Epoch 5/21, Train Loss: 0.000244, Test Loss: 0.000170\n",
      "Epoch 6/21, Train Loss: 0.000230, Test Loss: 0.000170\n",
      "Epoch 7/21, Train Loss: 0.000224, Test Loss: 0.000171\n",
      "Epoch 8/21, Train Loss: 0.000220, Test Loss: 0.000169\n",
      "Epoch 9/21, Train Loss: 0.000216, Test Loss: 0.000169\n",
      "Epoch 10/21, Train Loss: 0.000215, Test Loss: 0.000169\n",
      "Epoch 11/21, Train Loss: 0.000210, Test Loss: 0.000169\n",
      "Epoch 12/21, Train Loss: 0.000207, Test Loss: 0.000169\n",
      "Epoch 13/21, Train Loss: 0.000206, Test Loss: 0.000169\n",
      "Epoch 14/21, Train Loss: 0.000205, Test Loss: 0.000169\n",
      "Epoch 15/21, Train Loss: 0.000204, Test Loss: 0.000169\n",
      "Epoch 16/21, Train Loss: 0.000203, Test Loss: 0.000168\n",
      "Epoch 17/21, Train Loss: 0.000201, Test Loss: 0.000168\n",
      "Epoch 18/21, Train Loss: 0.000200, Test Loss: 0.000168\n",
      "Epoch 19/21, Train Loss: 0.000199, Test Loss: 0.000167\n",
      "Epoch 20/21, Train Loss: 0.000199, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:14:33,138] Trial 88 finished with value: 0.00016691919201929846 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 159, 'layer_1_size': 175, 'layer_2_size': 58, 'layer_3_size': 77, 'layer_4_size': 193, 'dropout_rate': 0.22310640428794515, 'learning_rate': 3.330506014287135e-05, 'batch_size': 64, 'epochs': 21}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/21, Train Loss: 0.000199, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33, Train Loss: 0.000780, Test Loss: 0.000216\n",
      "Epoch 2/33, Train Loss: 0.000423, Test Loss: 0.000232\n",
      "Epoch 3/33, Train Loss: 0.000349, Test Loss: 0.000228\n",
      "Epoch 4/33, Train Loss: 0.000314, Test Loss: 0.000201\n",
      "Epoch 5/33, Train Loss: 0.000289, Test Loss: 0.000193\n",
      "Epoch 6/33, Train Loss: 0.000262, Test Loss: 0.000189\n",
      "Epoch 7/33, Train Loss: 0.000243, Test Loss: 0.000174\n",
      "Epoch 8/33, Train Loss: 0.000233, Test Loss: 0.000177\n",
      "Epoch 9/33, Train Loss: 0.000224, Test Loss: 0.000175\n",
      "Epoch 10/33, Train Loss: 0.000217, Test Loss: 0.000168\n",
      "Epoch 11/33, Train Loss: 0.000212, Test Loss: 0.000169\n",
      "Epoch 12/33, Train Loss: 0.000208, Test Loss: 0.000170\n",
      "Epoch 13/33, Train Loss: 0.000205, Test Loss: 0.000168\n",
      "Epoch 14/33, Train Loss: 0.000202, Test Loss: 0.000168\n",
      "Epoch 15/33, Train Loss: 0.000199, Test Loss: 0.000169\n",
      "Epoch 16/33, Train Loss: 0.000198, Test Loss: 0.000167\n",
      "Epoch 17/33, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 18/33, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 19/33, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 20/33, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 21/33, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 22/33, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 23/33, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 24/33, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 25/33, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 26/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 27/33, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 28/33, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 29/33, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 30/33, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 31/33, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 32/33, Train Loss: 0.000193, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:15:00,096] Trial 89 finished with value: 0.00016585982567932894 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 140, 'layer_1_size': 111, 'layer_2_size': 46, 'dropout_rate': 0.17664092931719433, 'learning_rate': 6.566833448490904e-05, 'batch_size': 64, 'epochs': 33}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/33, Train Loss: 0.000189, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32, Train Loss: 0.000842, Test Loss: 0.000231\n",
      "Epoch 2/32, Train Loss: 0.000451, Test Loss: 0.000213\n",
      "Epoch 3/32, Train Loss: 0.000391, Test Loss: 0.000198\n",
      "Epoch 4/32, Train Loss: 0.000367, Test Loss: 0.000194\n",
      "Epoch 5/32, Train Loss: 0.000337, Test Loss: 0.000196\n",
      "Epoch 6/32, Train Loss: 0.000317, Test Loss: 0.000184\n",
      "Epoch 7/32, Train Loss: 0.000305, Test Loss: 0.000178\n",
      "Epoch 8/32, Train Loss: 0.000291, Test Loss: 0.000174\n",
      "Epoch 9/32, Train Loss: 0.000276, Test Loss: 0.000170\n",
      "Epoch 10/32, Train Loss: 0.000267, Test Loss: 0.000168\n",
      "Epoch 11/32, Train Loss: 0.000257, Test Loss: 0.000169\n",
      "Epoch 12/32, Train Loss: 0.000252, Test Loss: 0.000174\n",
      "Epoch 13/32, Train Loss: 0.000242, Test Loss: 0.000169\n",
      "Epoch 14/32, Train Loss: 0.000235, Test Loss: 0.000170\n",
      "Epoch 15/32, Train Loss: 0.000226, Test Loss: 0.000168\n",
      "Epoch 16/32, Train Loss: 0.000228, Test Loss: 0.000169\n",
      "Epoch 17/32, Train Loss: 0.000217, Test Loss: 0.000167\n",
      "Epoch 18/32, Train Loss: 0.000214, Test Loss: 0.000166\n",
      "Epoch 19/32, Train Loss: 0.000210, Test Loss: 0.000168\n",
      "Epoch 20/32, Train Loss: 0.000207, Test Loss: 0.000166\n",
      "Epoch 21/32, Train Loss: 0.000205, Test Loss: 0.000165\n",
      "Epoch 22/32, Train Loss: 0.000203, Test Loss: 0.000169\n",
      "Epoch 23/32, Train Loss: 0.000201, Test Loss: 0.000165\n",
      "Epoch 24/32, Train Loss: 0.000198, Test Loss: 0.000166\n",
      "Epoch 25/32, Train Loss: 0.000198, Test Loss: 0.000166\n",
      "Epoch 26/32, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 27/32, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 28/32, Train Loss: 0.000196, Test Loss: 0.000172\n",
      "Epoch 29/32, Train Loss: 0.000194, Test Loss: 0.000170\n",
      "Epoch 30/32, Train Loss: 0.000193, Test Loss: 0.000170\n",
      "Epoch 31/32, Train Loss: 0.000193, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:15:16,397] Trial 90 finished with value: 0.0001698091483200598 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 131, 'layer_1_size': 134, 'layer_2_size': 183, 'layer_3_size': 47, 'dropout_rate': 0.18591833305987954, 'learning_rate': 9.248193841444867e-05, 'batch_size': 128, 'epochs': 32}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/32, Train Loss: 0.000192, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29, Train Loss: 0.000259, Test Loss: 0.000174\n",
      "Epoch 2/29, Train Loss: 0.000206, Test Loss: 0.000170\n",
      "Epoch 3/29, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 4/29, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 5/29, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 6/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 10/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 11/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 12/29, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 13/29, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 14/29, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 15/29, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 16/29, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 17/29, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 18/29, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 19/29, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 20/29, Train Loss: 0.000186, Test Loss: 0.000164\n",
      "Epoch 21/29, Train Loss: 0.000184, Test Loss: 0.000166\n",
      "Epoch 22/29, Train Loss: 0.000184, Test Loss: 0.000164\n",
      "Epoch 23/29, Train Loss: 0.000179, Test Loss: 0.000167\n",
      "Epoch 24/29, Train Loss: 0.000180, Test Loss: 0.000176\n",
      "Epoch 25/29, Train Loss: 0.000179, Test Loss: 0.000168\n",
      "Epoch 26/29, Train Loss: 0.000174, Test Loss: 0.000163\n",
      "Epoch 27/29, Train Loss: 0.000174, Test Loss: 0.000164\n",
      "Epoch 28/29, Train Loss: 0.000167, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:15:31,881] Trial 91 finished with value: 0.0001634772931883192 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 200, 'layer_1_size': 151, 'layer_2_size': 64, 'dropout_rate': 0.1555855998779536, 'learning_rate': 0.00015734048208554779, 'batch_size': 64, 'epochs': 29}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29, Train Loss: 0.000175, Test Loss: 0.000163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26, Train Loss: 0.000335, Test Loss: 0.000172\n",
      "Epoch 2/26, Train Loss: 0.000217, Test Loss: 0.000172\n",
      "Epoch 3/26, Train Loss: 0.000209, Test Loss: 0.000169\n",
      "Epoch 4/26, Train Loss: 0.000205, Test Loss: 0.000167\n",
      "Epoch 5/26, Train Loss: 0.000201, Test Loss: 0.000166\n",
      "Epoch 6/26, Train Loss: 0.000198, Test Loss: 0.000166\n",
      "Epoch 7/26, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 8/26, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 9/26, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 10/26, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 11/26, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/26, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/26, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/26, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 15/26, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 16/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/26, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 18/26, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 19/26, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 20/26, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 21/26, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 22/26, Train Loss: 0.000200, Test Loss: 0.000169\n",
      "Epoch 23/26, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 24/26, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 25/26, Train Loss: 0.000185, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:15:47,699] Trial 92 finished with value: 0.0001665070195383211 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 229, 'layer_1_size': 151, 'layer_2_size': 69, 'dropout_rate': 0.12965067712463832, 'learning_rate': 0.00013714605880769804, 'batch_size': 64, 'epochs': 26}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/26, Train Loss: 0.000185, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29, Train Loss: 0.000518, Test Loss: 0.000175\n",
      "Epoch 2/29, Train Loss: 0.000217, Test Loss: 0.000169\n",
      "Epoch 3/29, Train Loss: 0.000200, Test Loss: 0.000171\n",
      "Epoch 4/29, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 5/29, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 6/29, Train Loss: 0.000210, Test Loss: 0.000167\n",
      "Epoch 7/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 8/29, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 9/29, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 10/29, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 11/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/29, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 15/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/29, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 18/29, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 19/29, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 20/29, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 21/29, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 22/29, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 23/29, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 24/29, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 25/29, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 26/29, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 27/29, Train Loss: 0.000185, Test Loss: 0.000168\n",
      "Epoch 28/29, Train Loss: 0.000185, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:16:11,649] Trial 93 finished with value: 0.00016784876828340555 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 199, 'layer_1_size': 165, 'dropout_rate': 0.1592440117435517, 'learning_rate': 0.0001749839186873666, 'batch_size': 64, 'epochs': 29}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29, Train Loss: 0.000185, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Train Loss: 0.000269, Test Loss: 0.000192\n",
      "Epoch 2/40, Train Loss: 0.000207, Test Loss: 0.000175\n",
      "Epoch 3/40, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 4/40, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 5/40, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 6/40, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 7/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 8/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 10/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/40, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 14/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 15/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/40, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 17/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/40, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 20/40, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 21/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 23/40, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 24/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/40, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 26/40, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 27/40, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 28/40, Train Loss: 0.000187, Test Loss: 0.000163\n",
      "Epoch 29/40, Train Loss: 0.000188, Test Loss: 0.000162\n",
      "Epoch 30/40, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 31/40, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 32/40, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 33/40, Train Loss: 0.000185, Test Loss: 0.000166\n",
      "Epoch 34/40, Train Loss: 0.000187, Test Loss: 0.000167\n",
      "Epoch 35/40, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 36/40, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 37/40, Train Loss: 0.000183, Test Loss: 0.000165\n",
      "Epoch 38/40, Train Loss: 0.000185, Test Loss: 0.000168\n",
      "Epoch 39/40, Train Loss: 0.000185, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:16:35,691] Trial 94 finished with value: 0.0001689353117369812 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 105, 'layer_1_size': 145, 'layer_2_size': 51, 'dropout_rate': 0.23375032676008775, 'learning_rate': 0.00023762498980978223, 'batch_size': 64, 'epochs': 40}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40, Train Loss: 0.000182, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.000498, Test Loss: 0.000240\n",
      "Epoch 2/30, Train Loss: 0.000294, Test Loss: 0.000215\n",
      "Epoch 3/30, Train Loss: 0.000259, Test Loss: 0.000176\n",
      "Epoch 4/30, Train Loss: 0.000238, Test Loss: 0.000187\n",
      "Epoch 5/30, Train Loss: 0.000228, Test Loss: 0.000174\n",
      "Epoch 6/30, Train Loss: 0.000218, Test Loss: 0.000175\n",
      "Epoch 7/30, Train Loss: 0.000211, Test Loss: 0.000172\n",
      "Epoch 8/30, Train Loss: 0.000208, Test Loss: 0.000171\n",
      "Epoch 9/30, Train Loss: 0.000204, Test Loss: 0.000169\n",
      "Epoch 10/30, Train Loss: 0.000202, Test Loss: 0.000170\n",
      "Epoch 11/30, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 12/30, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 13/30, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 14/30, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 15/30, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 16/30, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 17/30, Train Loss: 0.000193, Test Loss: 0.000164\n",
      "Epoch 18/30, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/30, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 20/30, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/30, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 22/30, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 23/30, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 24/30, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/30, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 26/30, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 27/30, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 28/30, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 29/30, Train Loss: 0.000187, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:16:52,281] Trial 95 finished with value: 0.0001646660984731845 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 203, 'layer_1_size': 180, 'layer_2_size': 85, 'dropout_rate': 0.20774456091403654, 'learning_rate': 8.050744318726567e-05, 'batch_size': 64, 'epochs': 30}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.000188, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28, Train Loss: 0.000332, Test Loss: 0.000170\n",
      "Epoch 2/28, Train Loss: 0.000218, Test Loss: 0.000172\n",
      "Epoch 3/28, Train Loss: 0.000205, Test Loss: 0.000168\n",
      "Epoch 4/28, Train Loss: 0.000199, Test Loss: 0.000168\n",
      "Epoch 5/28, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 6/28, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 7/28, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 8/28, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 9/28, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 10/28, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 11/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 15/28, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 16/28, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 17/28, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 18/28, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 19/28, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/28, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 21/28, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 22/28, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 23/28, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 24/28, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 25/28, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 26/28, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 27/28, Train Loss: 0.000189, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:17:10,106] Trial 96 finished with value: 0.00016687191353617715 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 153, 'layer_1_size': 122, 'layer_2_size': 42, 'layer_3_size': 129, 'dropout_rate': 0.18704628200337964, 'learning_rate': 0.00030587579961179664, 'batch_size': 64, 'epochs': 28}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/28, Train Loss: 0.000189, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27, Train Loss: 0.000248, Test Loss: 0.000170\n",
      "Epoch 2/27, Train Loss: 0.000205, Test Loss: 0.000181\n",
      "Epoch 3/27, Train Loss: 0.000199, Test Loss: 0.000167\n",
      "Epoch 4/27, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 5/27, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 6/27, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 7/27, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 8/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/27, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 11/27, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 12/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/27, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 14/27, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 15/27, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 16/27, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 17/27, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 18/27, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 19/27, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 20/27, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 21/27, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 22/27, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 23/27, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 24/27, Train Loss: 0.000184, Test Loss: 0.000165\n",
      "Epoch 25/27, Train Loss: 0.000183, Test Loss: 0.000165\n",
      "Epoch 26/27, Train Loss: 0.000184, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:17:46,155] Trial 97 finished with value: 0.00016325548534906932 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 217, 'layer_1_size': 156, 'layer_2_size': 163, 'dropout_rate': 0.21746736268651876, 'learning_rate': 0.0001523451902769337, 'batch_size': 32, 'epochs': 27}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/27, Train Loss: 0.000176, Test Loss: 0.000163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Train Loss: 0.000354, Test Loss: 0.000172\n",
      "Epoch 2/24, Train Loss: 0.000223, Test Loss: 0.000172\n",
      "Epoch 3/24, Train Loss: 0.000206, Test Loss: 0.000173\n",
      "Epoch 4/24, Train Loss: 0.000199, Test Loss: 0.000169\n",
      "Epoch 5/24, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 6/24, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 7/24, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 8/24, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 9/24, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 10/24, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/24, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/24, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/24, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/24, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/24, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/24, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 17/24, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 18/24, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 19/24, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/24, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 21/24, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 22/24, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 23/24, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:18:07,413] Trial 98 finished with value: 0.00016422002880744913 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 216, 'layer_1_size': 32, 'layer_2_size': 37, 'dropout_rate': 0.15832923674420799, 'learning_rate': 0.000143478818385411, 'batch_size': 32, 'epochs': 24}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Train Loss: 0.000190, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Train Loss: 0.004144, Test Loss: 0.000340\n",
      "Epoch 2/24, Train Loss: 0.000903, Test Loss: 0.000242\n",
      "Epoch 3/24, Train Loss: 0.000653, Test Loss: 0.000212\n",
      "Epoch 4/24, Train Loss: 0.000536, Test Loss: 0.000201\n",
      "Epoch 5/24, Train Loss: 0.000464, Test Loss: 0.000199\n",
      "Epoch 6/24, Train Loss: 0.000421, Test Loss: 0.000200\n",
      "Epoch 7/24, Train Loss: 0.000386, Test Loss: 0.000185\n",
      "Epoch 8/24, Train Loss: 0.000353, Test Loss: 0.000187\n",
      "Epoch 9/24, Train Loss: 0.000327, Test Loss: 0.000189\n",
      "Epoch 10/24, Train Loss: 0.000308, Test Loss: 0.000178\n",
      "Epoch 11/24, Train Loss: 0.000281, Test Loss: 0.000179\n",
      "Epoch 12/24, Train Loss: 0.000270, Test Loss: 0.000182\n",
      "Epoch 13/24, Train Loss: 0.000254, Test Loss: 0.000173\n",
      "Epoch 14/24, Train Loss: 0.000243, Test Loss: 0.000173\n",
      "Epoch 15/24, Train Loss: 0.000235, Test Loss: 0.000174\n",
      "Epoch 16/24, Train Loss: 0.000226, Test Loss: 0.000173\n",
      "Epoch 17/24, Train Loss: 0.000221, Test Loss: 0.000171\n",
      "Epoch 18/24, Train Loss: 0.000224, Test Loss: 0.000171\n",
      "Epoch 19/24, Train Loss: 0.000210, Test Loss: 0.000169\n",
      "Epoch 20/24, Train Loss: 0.000208, Test Loss: 0.000171\n",
      "Epoch 21/24, Train Loss: 0.000205, Test Loss: 0.000171\n",
      "Epoch 22/24, Train Loss: 0.000203, Test Loss: 0.000170\n",
      "Epoch 23/24, Train Loss: 0.000200, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:18:28,533] Trial 99 finished with value: 0.00016933500433978106 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 214, 'layer_1_size': 33, 'dropout_rate': 0.1739848227050719, 'learning_rate': 1.2627689293086863e-05, 'batch_size': 32, 'epochs': 24}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Train Loss: 0.000201, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 0.000329, Test Loss: 0.000171\n",
      "Epoch 2/25, Train Loss: 0.000220, Test Loss: 0.000169\n",
      "Epoch 3/25, Train Loss: 0.000205, Test Loss: 0.000170\n",
      "Epoch 4/25, Train Loss: 0.000198, Test Loss: 0.000169\n",
      "Epoch 5/25, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 6/25, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 7/25, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 8/25, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 9/25, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 10/25, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/25, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/25, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/25, Train Loss: 0.000191, Test Loss: 0.000168\n",
      "Epoch 16/25, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 17/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 19/25, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 20/25, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 21/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 22/25, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 23/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 24/25, Train Loss: 0.000189, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:19:02,345] Trial 100 finished with value: 0.0001641337509192175 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 220, 'layer_1_size': 52, 'layer_2_size': 38, 'dropout_rate': 0.1592519995692751, 'learning_rate': 0.00015207552568177228, 'batch_size': 32, 'epochs': 25}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Train Loss: 0.000189, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Train Loss: 0.001256, Test Loss: 0.000210\n",
      "Epoch 2/24, Train Loss: 0.000395, Test Loss: 0.000202\n",
      "Epoch 3/24, Train Loss: 0.000315, Test Loss: 0.000172\n",
      "Epoch 4/24, Train Loss: 0.000259, Test Loss: 0.000166\n",
      "Epoch 5/24, Train Loss: 0.000225, Test Loss: 0.000168\n",
      "Epoch 6/24, Train Loss: 0.000211, Test Loss: 0.000167\n",
      "Epoch 7/24, Train Loss: 0.000200, Test Loss: 0.000168\n",
      "Epoch 8/24, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 9/24, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 10/24, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 11/24, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 12/24, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/24, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/24, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/24, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 16/24, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 17/24, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 18/24, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 19/24, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 20/24, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 21/24, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 22/24, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 23/24, Train Loss: 0.000186, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:19:38,928] Trial 101 finished with value: 0.00016657436973519584 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 219, 'layer_1_size': 76, 'layer_2_size': 37, 'dropout_rate': 0.13829673556216834, 'learning_rate': 0.00015314711334193492, 'batch_size': 32, 'epochs': 24}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Train Loss: 0.000185, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26, Train Loss: 0.001000, Test Loss: 0.000199\n",
      "Epoch 2/26, Train Loss: 0.000333, Test Loss: 0.000175\n",
      "Epoch 3/26, Train Loss: 0.000230, Test Loss: 0.000172\n",
      "Epoch 4/26, Train Loss: 0.000204, Test Loss: 0.000168\n",
      "Epoch 5/26, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 6/26, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 7/26, Train Loss: 0.000194, Test Loss: 0.000175\n",
      "Epoch 8/26, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 9/26, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 10/26, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/26, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/26, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 18/26, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 19/26, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 20/26, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 21/26, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 22/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 23/26, Train Loss: 0.000189, Test Loss: 0.000163\n",
      "Epoch 24/26, Train Loss: 0.000188, Test Loss: 0.000163\n",
      "Epoch 25/26, Train Loss: 0.000188, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:20:00,629] Trial 102 finished with value: 0.00016498634572635932 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 210, 'layer_1_size': 57, 'layer_2_size': 32, 'dropout_rate': 0.15703465045869885, 'learning_rate': 0.0001943514081384353, 'batch_size': 32, 'epochs': 26}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/26, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 0.000383, Test Loss: 0.000171\n",
      "Epoch 2/25, Train Loss: 0.000226, Test Loss: 0.000181\n",
      "Epoch 3/25, Train Loss: 0.000204, Test Loss: 0.000170\n",
      "Epoch 4/25, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 5/25, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 6/25, Train Loss: 0.000192, Test Loss: 0.000169\n",
      "Epoch 7/25, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 9/25, Train Loss: 0.000191, Test Loss: 0.000168\n",
      "Epoch 10/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 11/25, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 12/25, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 13/25, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 14/25, Train Loss: 0.000207, Test Loss: 0.000167\n",
      "Epoch 15/25, Train Loss: 0.000189, Test Loss: 0.000172\n",
      "Epoch 16/25, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 17/25, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 18/25, Train Loss: 0.000186, Test Loss: 0.000201\n",
      "Epoch 19/25, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 20/25, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 21/25, Train Loss: 0.000183, Test Loss: 0.000166\n",
      "Epoch 22/25, Train Loss: 0.000182, Test Loss: 0.000166\n",
      "Epoch 23/25, Train Loss: 0.000184, Test Loss: 0.000167\n",
      "Epoch 24/25, Train Loss: 0.000176, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:20:15,212] Trial 103 finished with value: 0.0001669815315219767 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 220, 'layer_1_size': 48, 'dropout_rate': 0.12449750972958327, 'learning_rate': 0.000250991498887012, 'batch_size': 32, 'epochs': 25}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Train Loss: 0.000175, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23, Train Loss: 0.001361, Test Loss: 0.000209\n",
      "Epoch 2/23, Train Loss: 0.000496, Test Loss: 0.000186\n",
      "Epoch 3/23, Train Loss: 0.000389, Test Loss: 0.000181\n",
      "Epoch 4/23, Train Loss: 0.000329, Test Loss: 0.000182\n",
      "Epoch 5/23, Train Loss: 0.000286, Test Loss: 0.000175\n",
      "Epoch 6/23, Train Loss: 0.000260, Test Loss: 0.000171\n",
      "Epoch 7/23, Train Loss: 0.000244, Test Loss: 0.000170\n",
      "Epoch 8/23, Train Loss: 0.000229, Test Loss: 0.000169\n",
      "Epoch 9/23, Train Loss: 0.000220, Test Loss: 0.000167\n",
      "Epoch 10/23, Train Loss: 0.000214, Test Loss: 0.000167\n",
      "Epoch 11/23, Train Loss: 0.000209, Test Loss: 0.000166\n",
      "Epoch 12/23, Train Loss: 0.000204, Test Loss: 0.000166\n",
      "Epoch 13/23, Train Loss: 0.000201, Test Loss: 0.000166\n",
      "Epoch 14/23, Train Loss: 0.000199, Test Loss: 0.000167\n",
      "Epoch 15/23, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 16/23, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 17/23, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 18/23, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 19/23, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 20/23, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 21/23, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 22/23, Train Loss: 0.000191, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:20:31,705] Trial 104 finished with value: 0.0001646435168896137 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 204, 'layer_1_size': 57, 'layer_2_size': 45, 'dropout_rate': 0.15003214702308143, 'learning_rate': 5.689634389939371e-05, 'batch_size': 32, 'epochs': 23}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/23, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22, Train Loss: 0.000692, Test Loss: 0.000174\n",
      "Epoch 2/22, Train Loss: 0.000248, Test Loss: 0.000175\n",
      "Epoch 3/22, Train Loss: 0.000227, Test Loss: 0.000171\n",
      "Epoch 4/22, Train Loss: 0.000214, Test Loss: 0.000170\n",
      "Epoch 5/22, Train Loss: 0.000207, Test Loss: 0.000170\n",
      "Epoch 6/22, Train Loss: 0.000201, Test Loss: 0.000169\n",
      "Epoch 7/22, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 8/22, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 9/22, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 10/22, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 11/22, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/22, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 13/22, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 14/22, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/22, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 16/22, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 17/22, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 18/22, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 19/22, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/22, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/22, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:20:46,512] Trial 105 finished with value: 0.0001700208407830741 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 193, 'layer_1_size': 45, 'layer_2_size': 56, 'dropout_rate': 0.1322835391981194, 'learning_rate': 0.00012345337341976843, 'batch_size': 32, 'epochs': 22}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/22, Train Loss: 0.000190, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 0.000310, Test Loss: 0.000168\n",
      "Epoch 2/25, Train Loss: 0.000232, Test Loss: 0.000169\n",
      "Epoch 3/25, Train Loss: 0.000218, Test Loss: 0.000166\n",
      "Epoch 4/25, Train Loss: 0.000207, Test Loss: 0.000166\n",
      "Epoch 5/25, Train Loss: 0.000202, Test Loss: 0.000170\n",
      "Epoch 6/25, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 7/25, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 8/25, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 9/25, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 10/25, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/25, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/25, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/25, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 16/25, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 17/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 18/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 19/25, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 20/25, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 21/25, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 22/25, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 23/25, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 24/25, Train Loss: 0.000187, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:21:03,229] Trial 106 finished with value: 0.0001661479863334916 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 225, 'layer_1_size': 42, 'layer_2_size': 37, 'dropout_rate': 0.11412705742416598, 'learning_rate': 0.00014984570286420522, 'batch_size': 32, 'epochs': 25}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Train Loss: 0.000185, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39, Train Loss: 0.000346, Test Loss: 0.000187\n",
      "Epoch 2/39, Train Loss: 0.000207, Test Loss: 0.000168\n",
      "Epoch 3/39, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 4/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 5/39, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 6/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 7/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 8/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/39, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 12/39, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 13/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/39, Train Loss: 0.000191, Test Loss: 0.000168\n",
      "Epoch 15/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/39, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 17/39, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 18/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/39, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 20/39, Train Loss: 0.000188, Test Loss: 0.000167\n",
      "Epoch 21/39, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 22/39, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 23/39, Train Loss: 0.000183, Test Loss: 0.000166\n",
      "Epoch 24/39, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 25/39, Train Loss: 0.000186, Test Loss: 0.000167\n",
      "Epoch 26/39, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 27/39, Train Loss: 0.000189, Test Loss: 0.000172\n",
      "Epoch 28/39, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 29/39, Train Loss: 0.000185, Test Loss: 0.000164\n",
      "Epoch 30/39, Train Loss: 0.000182, Test Loss: 0.000167\n",
      "Epoch 31/39, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 32/39, Train Loss: 0.000184, Test Loss: 0.000165\n",
      "Epoch 33/39, Train Loss: 0.000183, Test Loss: 0.000161\n",
      "Epoch 34/39, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 35/39, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 36/39, Train Loss: 0.000174, Test Loss: 0.000171\n",
      "Epoch 37/39, Train Loss: 0.000178, Test Loss: 0.000165\n",
      "Epoch 38/39, Train Loss: 0.000178, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:21:30,104] Trial 107 finished with value: 0.0001670195290985028 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 211, 'layer_1_size': 154, 'dropout_rate': 0.17109317683640574, 'learning_rate': 0.0003255101694527764, 'batch_size': 32, 'epochs': 39}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/39, Train Loss: 0.000170, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27, Train Loss: 0.000279, Test Loss: 0.000170\n",
      "Epoch 2/27, Train Loss: 0.000214, Test Loss: 0.000168\n",
      "Epoch 3/27, Train Loss: 0.000203, Test Loss: 0.000170\n",
      "Epoch 4/27, Train Loss: 0.000198, Test Loss: 0.000170\n",
      "Epoch 5/27, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 6/27, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 7/27, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 8/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 10/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/27, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 13/27, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 14/27, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 15/27, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 16/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/27, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 19/27, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 20/27, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 21/27, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 22/27, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 23/27, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 24/27, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 25/27, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 26/27, Train Loss: 0.000188, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:21:49,031] Trial 108 finished with value: 0.00016620710374031807 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 90, 'layer_1_size': 171, 'layer_2_size': 50, 'dropout_rate': 0.16188250864094808, 'learning_rate': 0.00010048970313085605, 'batch_size': 32, 'epochs': 27}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/27, Train Loss: 0.000187, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21, Train Loss: 0.000248, Test Loss: 0.000169\n",
      "Epoch 2/21, Train Loss: 0.000206, Test Loss: 0.000167\n",
      "Epoch 3/21, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 4/21, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 5/21, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 6/21, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 7/21, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/21, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/21, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 10/21, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/21, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 12/21, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/21, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 14/21, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 15/21, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 16/21, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 17/21, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 18/21, Train Loss: 0.000187, Test Loss: 0.000167\n",
      "Epoch 19/21, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 20/21, Train Loss: 0.000184, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:22:16,354] Trial 109 finished with value: 0.00016423977723250925 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 217, 'layer_1_size': 86, 'layer_2_size': 165, 'layer_3_size': 111, 'dropout_rate': 0.1430642624451872, 'learning_rate': 0.00021177200673420452, 'batch_size': 32, 'epochs': 21}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/21, Train Loss: 0.000184, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21, Train Loss: 0.000300, Test Loss: 0.000169\n",
      "Epoch 2/21, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 3/21, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 4/21, Train Loss: 0.000193, Test Loss: 0.000170\n",
      "Epoch 5/21, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 6/21, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 7/21, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 8/21, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/21, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 10/21, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/21, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/21, Train Loss: 0.000192, Test Loss: 0.000173\n",
      "Epoch 13/21, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/21, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 15/21, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/21, Train Loss: 0.000272, Test Loss: 0.000166\n",
      "Epoch 17/21, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 18/21, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 19/21, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 20/21, Train Loss: 0.000191, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:22:27,281] Trial 110 finished with value: 0.00016522551011862122 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 77, 'layer_1_size': 87, 'dropout_rate': 0.14325179176621688, 'learning_rate': 0.00045719336480127735, 'batch_size': 32, 'epochs': 21}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/21, Train Loss: 0.000192, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.000228, Test Loss: 0.000168\n",
      "Epoch 2/20, Train Loss: 0.000199, Test Loss: 0.000172\n",
      "Epoch 3/20, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 4/20, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 5/20, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 6/20, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 7/20, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 8/20, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/20, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 14/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/20, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 17/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/20, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:22:51,392] Trial 111 finished with value: 0.00016455994455466885 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 216, 'layer_1_size': 70, 'layer_2_size': 168, 'layer_3_size': 110, 'dropout_rate': 0.1835247998851617, 'learning_rate': 0.00019285679419968351, 'batch_size': 32, 'epochs': 20}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.000247, Test Loss: 0.000172\n",
      "Epoch 2/20, Train Loss: 0.000208, Test Loss: 0.000173\n",
      "Epoch 3/20, Train Loss: 0.000202, Test Loss: 0.000172\n",
      "Epoch 4/20, Train Loss: 0.000198, Test Loss: 0.000166\n",
      "Epoch 5/20, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 6/20, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 7/20, Train Loss: 0.000193, Test Loss: 0.000164\n",
      "Epoch 8/20, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/20, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 10/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/20, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 14/20, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 18/20, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 19/20, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:23:20,043] Trial 112 finished with value: 0.00016474954346695233 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 204, 'layer_1_size': 95, 'layer_2_size': 179, 'layer_3_size': 186, 'dropout_rate': 0.1484553394505526, 'learning_rate': 0.0002741292193676953, 'batch_size': 32, 'epochs': 20}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18, Train Loss: 0.000430, Test Loss: 0.000171\n",
      "Epoch 2/18, Train Loss: 0.000213, Test Loss: 0.000170\n",
      "Epoch 3/18, Train Loss: 0.000200, Test Loss: 0.000171\n",
      "Epoch 4/18, Train Loss: 0.000198, Test Loss: 0.000169\n",
      "Epoch 5/18, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 6/18, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 7/18, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 8/18, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 9/18, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 10/18, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 11/18, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 12/18, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 13/18, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 14/18, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 15/18, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 16/18, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 17/18, Train Loss: 0.000193, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:23:36,337] Trial 113 finished with value: 0.00016737954847063783 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 231, 'layer_1_size': 36, 'layer_2_size': 162, 'dropout_rate': 0.4192164228506042, 'learning_rate': 0.00022220665066247187, 'batch_size': 32, 'epochs': 18}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/18, Train Loss: 0.000193, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22, Train Loss: 0.000283, Test Loss: 0.000168\n",
      "Epoch 2/22, Train Loss: 0.000212, Test Loss: 0.000167\n",
      "Epoch 3/22, Train Loss: 0.000205, Test Loss: 0.000167\n",
      "Epoch 4/22, Train Loss: 0.000200, Test Loss: 0.000169\n",
      "Epoch 5/22, Train Loss: 0.000197, Test Loss: 0.000171\n",
      "Epoch 6/22, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 7/22, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 8/22, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 9/22, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 10/22, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/22, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/22, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/22, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 14/22, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/22, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/22, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 17/22, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/22, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 19/22, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/22, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 21/22, Train Loss: 0.000189, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:24:00,996] Trial 114 finished with value: 0.0001645754812894636 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 188, 'layer_1_size': 161, 'layer_2_size': 176, 'dropout_rate': 0.19956994382022886, 'learning_rate': 8.349088612834704e-05, 'batch_size': 32, 'epochs': 22}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/22, Train Loss: 0.000189, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23, Train Loss: 0.000671, Test Loss: 0.000179\n",
      "Epoch 2/23, Train Loss: 0.000278, Test Loss: 0.000172\n",
      "Epoch 3/23, Train Loss: 0.000241, Test Loss: 0.000170\n",
      "Epoch 4/23, Train Loss: 0.000217, Test Loss: 0.000173\n",
      "Epoch 5/23, Train Loss: 0.000206, Test Loss: 0.000170\n",
      "Epoch 6/23, Train Loss: 0.000200, Test Loss: 0.000169\n",
      "Epoch 7/23, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 8/23, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 9/23, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 10/23, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 11/23, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/23, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 13/23, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 14/23, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/23, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 16/23, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/23, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 18/23, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/23, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 20/23, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/23, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/23, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:24:18,711] Trial 115 finished with value: 0.00016465147827800813 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 56, 'layer_1_size': 149, 'layer_2_size': 43, 'layer_3_size': 33, 'dropout_rate': 0.1575895305922759, 'learning_rate': 0.00012197183950488316, 'batch_size': 32, 'epochs': 23}. Best is trial 49 with value: 0.0001627372559739577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/23, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29, Train Loss: 0.000260, Test Loss: 0.000168\n",
      "Epoch 2/29, Train Loss: 0.000205, Test Loss: 0.000169\n",
      "Epoch 3/29, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 4/29, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 5/29, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 6/29, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 7/29, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 8/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/29, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 12/29, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 13/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/29, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 15/29, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 16/29, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 17/29, Train Loss: 0.000190, Test Loss: 0.000163\n",
      "Epoch 18/29, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 19/29, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 20/29, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 21/29, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 22/29, Train Loss: 0.000189, Test Loss: 0.000162\n",
      "Epoch 23/29, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 24/29, Train Loss: 0.000186, Test Loss: 0.000163\n",
      "Epoch 25/29, Train Loss: 0.000185, Test Loss: 0.000164\n",
      "Epoch 26/29, Train Loss: 0.000185, Test Loss: 0.000163\n",
      "Epoch 27/29, Train Loss: 0.000184, Test Loss: 0.000166\n",
      "Epoch 28/29, Train Loss: 0.000184, Test Loss: 0.000163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:24:41,849] Trial 116 finished with value: 0.0001615109022571731 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 223, 'layer_1_size': 64, 'layer_2_size': 194, 'dropout_rate': 0.11419484328966484, 'learning_rate': 0.00017486754285944678, 'batch_size': 32, 'epochs': 29}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29, Train Loss: 0.000180, Test Loss: 0.000162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/31, Train Loss: 0.000285, Test Loss: 0.000169\n",
      "Epoch 2/31, Train Loss: 0.000212, Test Loss: 0.000174\n",
      "Epoch 3/31, Train Loss: 0.000200, Test Loss: 0.000168\n",
      "Epoch 4/31, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 5/31, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 6/31, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/31, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 8/31, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/31, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/31, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/31, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 12/31, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/31, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/31, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 15/31, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 16/31, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 17/31, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 18/31, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 19/31, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 20/31, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 21/31, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 22/31, Train Loss: 0.000186, Test Loss: 0.000164\n",
      "Epoch 23/31, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 24/31, Train Loss: 0.000184, Test Loss: 0.000164\n",
      "Epoch 25/31, Train Loss: 0.000184, Test Loss: 0.000166\n",
      "Epoch 26/31, Train Loss: 0.000181, Test Loss: 0.000164\n",
      "Epoch 27/31, Train Loss: 0.000177, Test Loss: 0.000166\n",
      "Epoch 28/31, Train Loss: 0.000177, Test Loss: 0.000165\n",
      "Epoch 29/31, Train Loss: 0.000180, Test Loss: 0.000164\n",
      "Epoch 30/31, Train Loss: 0.000167, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:25:06,541] Trial 117 finished with value: 0.0001656401807816755 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 223, 'layer_1_size': 50, 'layer_2_size': 220, 'dropout_rate': 0.11252991477499544, 'learning_rate': 0.00015318257841305508, 'batch_size': 32, 'epochs': 31}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/31, Train Loss: 0.000171, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38, Train Loss: 0.000398, Test Loss: 0.000182\n",
      "Epoch 2/38, Train Loss: 0.000215, Test Loss: 0.000170\n",
      "Epoch 3/38, Train Loss: 0.000202, Test Loss: 0.000167\n",
      "Epoch 4/38, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 5/38, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 6/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/38, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 8/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/38, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 10/38, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/38, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/38, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/38, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 14/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/38, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 19/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/38, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 22/38, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 23/38, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 24/38, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 25/38, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 26/38, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 27/38, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 28/38, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 29/38, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 30/38, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 31/38, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 32/38, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 33/38, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 34/38, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 35/38, Train Loss: 0.000185, Test Loss: 0.000164\n",
      "Epoch 36/38, Train Loss: 0.000185, Test Loss: 0.000164\n",
      "Epoch 37/38, Train Loss: 0.000186, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:25:30,220] Trial 118 finished with value: 0.00016502489425955638 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 217, 'layer_1_size': 61, 'dropout_rate': 0.1378657427733799, 'learning_rate': 7.20651128314417e-05, 'batch_size': 32, 'epochs': 38}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/38, Train Loss: 0.000185, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33, Train Loss: 0.000224, Test Loss: 0.000168\n",
      "Epoch 2/33, Train Loss: 0.000199, Test Loss: 0.000167\n",
      "Epoch 3/33, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 4/33, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 5/33, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 6/33, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 7/33, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 8/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/33, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 10/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/33, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 13/33, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 14/33, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/33, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 16/33, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 17/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/33, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 19/33, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 20/33, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 21/33, Train Loss: 0.000189, Test Loss: 0.000168\n",
      "Epoch 22/33, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 23/33, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 24/33, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/33, Train Loss: 0.000185, Test Loss: 0.000166\n",
      "Epoch 26/33, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 27/33, Train Loss: 0.000184, Test Loss: 0.000166\n",
      "Epoch 28/33, Train Loss: 0.000183, Test Loss: 0.000164\n",
      "Epoch 29/33, Train Loss: 0.000191, Test Loss: 0.000168\n",
      "Epoch 30/33, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 31/33, Train Loss: 0.000183, Test Loss: 0.000169\n",
      "Epoch 32/33, Train Loss: 0.000191, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:26:04,998] Trial 119 finished with value: 0.00016424512657229042 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 243, 'layer_1_size': 71, 'layer_2_size': 189, 'dropout_rate': 0.12355694234437184, 'learning_rate': 0.00039088094376410265, 'batch_size': 32, 'epochs': 33}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/33, Train Loss: 0.000182, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.000216, Test Loss: 0.000168\n",
      "Epoch 2/5, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 3/5, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 4/5, Train Loss: 0.000194, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:26:10,140] Trial 120 finished with value: 0.00016467215801372408 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 199, 'layer_1_size': 38, 'layer_2_size': 66, 'dropout_rate': 0.13000187838342805, 'learning_rate': 0.0006387602815073743, 'batch_size': 32, 'epochs': 5}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.000193, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33, Train Loss: 0.000311, Test Loss: 0.000169\n",
      "Epoch 2/33, Train Loss: 0.000212, Test Loss: 0.000178\n",
      "Epoch 3/33, Train Loss: 0.000201, Test Loss: 0.000169\n",
      "Epoch 4/33, Train Loss: 0.000197, Test Loss: 0.000172\n",
      "Epoch 5/33, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 6/33, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 7/33, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 8/33, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 9/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/33, Train Loss: 0.000192, Test Loss: 0.000172\n",
      "Epoch 11/33, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 12/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/33, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 15/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/33, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 17/33, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 18/33, Train Loss: 0.000189, Test Loss: 0.000163\n",
      "Epoch 19/33, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 20/33, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 21/33, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 22/33, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 23/33, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 24/33, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 25/33, Train Loss: 0.000182, Test Loss: 0.000166\n",
      "Epoch 26/33, Train Loss: 0.000186, Test Loss: 0.000167\n",
      "Epoch 27/33, Train Loss: 0.000187, Test Loss: 0.000167\n",
      "Epoch 28/33, Train Loss: 0.000180, Test Loss: 0.000163\n",
      "Epoch 29/33, Train Loss: 0.000180, Test Loss: 0.000166\n",
      "Epoch 30/33, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 31/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 32/33, Train Loss: 0.000192, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:26:43,514] Trial 121 finished with value: 0.00016507181877687476 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 247, 'layer_1_size': 66, 'layer_2_size': 192, 'dropout_rate': 0.12133655778504343, 'learning_rate': 0.00024937646339468297, 'batch_size': 32, 'epochs': 33}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/33, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28, Train Loss: 0.000416, Test Loss: 0.000171\n",
      "Epoch 2/28, Train Loss: 0.000228, Test Loss: 0.000167\n",
      "Epoch 3/28, Train Loss: 0.000212, Test Loss: 0.000170\n",
      "Epoch 4/28, Train Loss: 0.000205, Test Loss: 0.000168\n",
      "Epoch 5/28, Train Loss: 0.000201, Test Loss: 0.000174\n",
      "Epoch 6/28, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 7/28, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 8/28, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 9/28, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 10/28, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 11/28, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 12/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/28, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 14/28, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 15/28, Train Loss: 0.000191, Test Loss: 0.000169\n",
      "Epoch 16/28, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 17/28, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 18/28, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 19/28, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 20/28, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 21/28, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 22/28, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 23/28, Train Loss: 0.000184, Test Loss: 0.000166\n",
      "Epoch 24/28, Train Loss: 0.000182, Test Loss: 0.000167\n",
      "Epoch 25/28, Train Loss: 0.000178, Test Loss: 0.000166\n",
      "Epoch 26/28, Train Loss: 0.000178, Test Loss: 0.000165\n",
      "Epoch 27/28, Train Loss: 0.000173, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:27:07,642] Trial 122 finished with value: 0.00017491955418702878 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 233, 'layer_1_size': 75, 'layer_2_size': 203, 'dropout_rate': 0.10658194781565346, 'learning_rate': 0.00010071266240464812, 'batch_size': 32, 'epochs': 28}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/28, Train Loss: 0.000168, Test Loss: 0.000175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29, Train Loss: 0.000295, Test Loss: 0.000170\n",
      "Epoch 2/29, Train Loss: 0.000210, Test Loss: 0.000168\n",
      "Epoch 3/29, Train Loss: 0.000202, Test Loss: 0.000173\n",
      "Epoch 4/29, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 5/29, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 6/29, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 7/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 8/29, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 9/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 10/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 15/29, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 16/29, Train Loss: 0.000191, Test Loss: 0.000168\n",
      "Epoch 17/29, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 18/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/29, Train Loss: 0.000190, Test Loss: 0.000176\n",
      "Epoch 20/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/29, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 22/29, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 23/29, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 24/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 25/29, Train Loss: 0.000191, Test Loss: 0.000171\n",
      "Epoch 26/29, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 27/29, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 28/29, Train Loss: 0.000189, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:27:34,213] Trial 123 finished with value: 0.00016621011765539974 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 222, 'layer_1_size': 80, 'layer_2_size': 199, 'dropout_rate': 0.15032568447528497, 'learning_rate': 0.0003935716610392187, 'batch_size': 32, 'epochs': 29}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29, Train Loss: 0.000189, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32, Train Loss: 0.000276, Test Loss: 0.000169\n",
      "Epoch 2/32, Train Loss: 0.000200, Test Loss: 0.000167\n",
      "Epoch 3/32, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 4/32, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 5/32, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 6/32, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/32, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/32, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/32, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/32, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 14/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/32, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 16/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/32, Train Loss: 0.000191, Test Loss: 0.000168\n",
      "Epoch 19/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/32, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 22/32, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 23/32, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 24/32, Train Loss: 0.000187, Test Loss: 0.000187\n",
      "Epoch 25/32, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 26/32, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 27/32, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 28/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 29/32, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 30/32, Train Loss: 0.000180, Test Loss: 0.000167\n",
      "Epoch 31/32, Train Loss: 0.000182, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:28:03,731] Trial 124 finished with value: 0.00016546802451084512 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 243, 'layer_1_size': 64, 'layer_2_size': 142, 'dropout_rate': 0.11535787651141172, 'learning_rate': 0.0003298658636182775, 'batch_size': 32, 'epochs': 32}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/32, Train Loss: 0.000178, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35, Train Loss: 0.001943, Test Loss: 0.000278\n",
      "Epoch 2/35, Train Loss: 0.000616, Test Loss: 0.000231\n",
      "Epoch 3/35, Train Loss: 0.000458, Test Loss: 0.000220\n",
      "Epoch 4/35, Train Loss: 0.000400, Test Loss: 0.000212\n",
      "Epoch 5/35, Train Loss: 0.000378, Test Loss: 0.000215\n",
      "Epoch 6/35, Train Loss: 0.000349, Test Loss: 0.000200\n",
      "Epoch 7/35, Train Loss: 0.000342, Test Loss: 0.000196\n",
      "Epoch 8/35, Train Loss: 0.000322, Test Loss: 0.000206\n",
      "Epoch 9/35, Train Loss: 0.000315, Test Loss: 0.000194\n",
      "Epoch 10/35, Train Loss: 0.000312, Test Loss: 0.000194\n",
      "Epoch 11/35, Train Loss: 0.000302, Test Loss: 0.000182\n",
      "Epoch 12/35, Train Loss: 0.000292, Test Loss: 0.000179\n",
      "Epoch 13/35, Train Loss: 0.000286, Test Loss: 0.000183\n",
      "Epoch 14/35, Train Loss: 0.000282, Test Loss: 0.000179\n",
      "Epoch 15/35, Train Loss: 0.000273, Test Loss: 0.000175\n",
      "Epoch 16/35, Train Loss: 0.000266, Test Loss: 0.000172\n",
      "Epoch 17/35, Train Loss: 0.000261, Test Loss: 0.000177\n",
      "Epoch 18/35, Train Loss: 0.000257, Test Loss: 0.000175\n",
      "Epoch 19/35, Train Loss: 0.000252, Test Loss: 0.000173\n",
      "Epoch 20/35, Train Loss: 0.000244, Test Loss: 0.000171\n",
      "Epoch 21/35, Train Loss: 0.000243, Test Loss: 0.000178\n",
      "Epoch 22/35, Train Loss: 0.000237, Test Loss: 0.000169\n",
      "Epoch 23/35, Train Loss: 0.000231, Test Loss: 0.000173\n",
      "Epoch 24/35, Train Loss: 0.000231, Test Loss: 0.000165\n",
      "Epoch 25/35, Train Loss: 0.000225, Test Loss: 0.000166\n",
      "Epoch 26/35, Train Loss: 0.000223, Test Loss: 0.000168\n",
      "Epoch 27/35, Train Loss: 0.000219, Test Loss: 0.000165\n",
      "Epoch 28/35, Train Loss: 0.000217, Test Loss: 0.000167\n",
      "Epoch 29/35, Train Loss: 0.000214, Test Loss: 0.000165\n",
      "Epoch 30/35, Train Loss: 0.000210, Test Loss: 0.000165\n",
      "Epoch 31/35, Train Loss: 0.000209, Test Loss: 0.000165\n",
      "Epoch 32/35, Train Loss: 0.000206, Test Loss: 0.000166\n",
      "Epoch 33/35, Train Loss: 0.000203, Test Loss: 0.000166\n",
      "Epoch 34/35, Train Loss: 0.000203, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:28:14,104] Trial 125 finished with value: 0.00016678082964414985 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 227, 'layer_1_size': 55, 'dropout_rate': 0.13695259572009874, 'learning_rate': 0.00013576027664542907, 'batch_size': 256, 'epochs': 35}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/35, Train Loss: 0.000202, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37, Train Loss: 0.000284, Test Loss: 0.000169\n",
      "Epoch 2/37, Train Loss: 0.000219, Test Loss: 0.000167\n",
      "Epoch 3/37, Train Loss: 0.000208, Test Loss: 0.000167\n",
      "Epoch 4/37, Train Loss: 0.000202, Test Loss: 0.000166\n",
      "Epoch 5/37, Train Loss: 0.000200, Test Loss: 0.000167\n",
      "Epoch 6/37, Train Loss: 0.000198, Test Loss: 0.000166\n",
      "Epoch 7/37, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 8/37, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 9/37, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 10/37, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 11/37, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 12/37, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 13/37, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/37, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/37, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 18/37, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 19/37, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 20/37, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 21/37, Train Loss: 0.000187, Test Loss: 0.000169\n",
      "Epoch 22/37, Train Loss: 0.000187, Test Loss: 0.000169\n",
      "Epoch 23/37, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 24/37, Train Loss: 0.000186, Test Loss: 0.000177\n",
      "Epoch 25/37, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 26/37, Train Loss: 0.000182, Test Loss: 0.000164\n",
      "Epoch 27/37, Train Loss: 0.000182, Test Loss: 0.000166\n",
      "Epoch 28/37, Train Loss: 0.000177, Test Loss: 0.000165\n",
      "Epoch 29/37, Train Loss: 0.000183, Test Loss: 0.000166\n",
      "Epoch 30/37, Train Loss: 0.000171, Test Loss: 0.000164\n",
      "Epoch 31/37, Train Loss: 0.000176, Test Loss: 0.000165\n",
      "Epoch 32/37, Train Loss: 0.000184, Test Loss: 0.000165\n",
      "Epoch 33/37, Train Loss: 0.000169, Test Loss: 0.000163\n",
      "Epoch 34/37, Train Loss: 0.000166, Test Loss: 0.000164\n",
      "Epoch 35/37, Train Loss: 0.000169, Test Loss: 0.000165\n",
      "Epoch 36/37, Train Loss: 0.000157, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:28:29,275] Trial 126 finished with value: 0.00016367776521703138 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 210, 'layer_1_size': 74, 'layer_2_size': 188, 'dropout_rate': 0.12552564652299214, 'learning_rate': 0.00019924881875834946, 'batch_size': 128, 'epochs': 37}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/37, Train Loss: 0.000149, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37, Train Loss: 0.000214, Test Loss: 0.000171\n",
      "Epoch 2/37, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 3/37, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 4/37, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 5/37, Train Loss: 0.000193, Test Loss: 0.000169\n",
      "Epoch 6/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 7/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 11/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 12/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/37, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 17/37, Train Loss: 0.000190, Test Loss: 0.000168\n",
      "Epoch 18/37, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 19/37, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 20/37, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 21/37, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 22/37, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 23/37, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 24/37, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 25/37, Train Loss: 0.000182, Test Loss: 0.000165\n",
      "Epoch 26/37, Train Loss: 0.000182, Test Loss: 0.000167\n",
      "Epoch 27/37, Train Loss: 0.000174, Test Loss: 0.000166\n",
      "Epoch 28/37, Train Loss: 0.000181, Test Loss: 0.000166\n",
      "Epoch 29/37, Train Loss: 0.000168, Test Loss: 0.000167\n",
      "Epoch 30/37, Train Loss: 0.000174, Test Loss: 0.000185\n",
      "Epoch 31/37, Train Loss: 0.000177, Test Loss: 0.000168\n",
      "Epoch 32/37, Train Loss: 0.000164, Test Loss: 0.000166\n",
      "Epoch 33/37, Train Loss: 0.000146, Test Loss: 0.000165\n",
      "Epoch 34/37, Train Loss: 0.000170, Test Loss: 0.000167\n",
      "Epoch 35/37, Train Loss: 0.000153, Test Loss: 0.000166\n",
      "Epoch 36/37, Train Loss: 0.000133, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:28:52,482] Trial 127 finished with value: 0.0001657168374784364 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 211, 'layer_1_size': 250, 'layer_2_size': 206, 'layer_3_size': 126, 'dropout_rate': 0.16240512612911742, 'learning_rate': 0.00017038912956481966, 'batch_size': 128, 'epochs': 37}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/37, Train Loss: 0.000132, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 0.000642, Test Loss: 0.000197\n",
      "Epoch 2/25, Train Loss: 0.000289, Test Loss: 0.000178\n",
      "Epoch 3/25, Train Loss: 0.000252, Test Loss: 0.000171\n",
      "Epoch 4/25, Train Loss: 0.000237, Test Loss: 0.000173\n",
      "Epoch 5/25, Train Loss: 0.000224, Test Loss: 0.000171\n",
      "Epoch 6/25, Train Loss: 0.000218, Test Loss: 0.000171\n",
      "Epoch 7/25, Train Loss: 0.000212, Test Loss: 0.000169\n",
      "Epoch 8/25, Train Loss: 0.000208, Test Loss: 0.000169\n",
      "Epoch 9/25, Train Loss: 0.000205, Test Loss: 0.000169\n",
      "Epoch 10/25, Train Loss: 0.000201, Test Loss: 0.000168\n",
      "Epoch 11/25, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 12/25, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 13/25, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 14/25, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 15/25, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 16/25, Train Loss: 0.000194, Test Loss: 0.000171\n",
      "Epoch 17/25, Train Loss: 0.000200, Test Loss: 0.000167\n",
      "Epoch 18/25, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 19/25, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 20/25, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 21/25, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 22/25, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 23/25, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 24/25, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:28:59,601] Trial 128 finished with value: 0.00016640909640749845 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 61, 'layer_1_size': 83, 'dropout_rate': 0.14142816382958215, 'learning_rate': 0.0001993244130408903, 'batch_size': 128, 'epochs': 25}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39, Train Loss: 0.000758, Test Loss: 0.000192\n",
      "Epoch 2/39, Train Loss: 0.000365, Test Loss: 0.000173\n",
      "Epoch 3/39, Train Loss: 0.000290, Test Loss: 0.000172\n",
      "Epoch 4/39, Train Loss: 0.000253, Test Loss: 0.000171\n",
      "Epoch 5/39, Train Loss: 0.000233, Test Loss: 0.000171\n",
      "Epoch 6/39, Train Loss: 0.000221, Test Loss: 0.000170\n",
      "Epoch 7/39, Train Loss: 0.000215, Test Loss: 0.000169\n",
      "Epoch 8/39, Train Loss: 0.000209, Test Loss: 0.000169\n",
      "Epoch 9/39, Train Loss: 0.000206, Test Loss: 0.000169\n",
      "Epoch 10/39, Train Loss: 0.000205, Test Loss: 0.000169\n",
      "Epoch 11/39, Train Loss: 0.000202, Test Loss: 0.000169\n",
      "Epoch 12/39, Train Loss: 0.000201, Test Loss: 0.000169\n",
      "Epoch 13/39, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 14/39, Train Loss: 0.000199, Test Loss: 0.000169\n",
      "Epoch 15/39, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 16/39, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 17/39, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 18/39, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 19/39, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 20/39, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 21/39, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 22/39, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 23/39, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 24/39, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 25/39, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 26/39, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 27/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 28/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 29/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 30/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 31/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 32/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 33/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 34/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 35/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 36/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 37/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 38/39, Train Loss: 0.000192, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:29:11,432] Trial 129 finished with value: 0.00016509117405451347 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 42, 'layer_1_size': 54, 'layer_2_size': 172, 'dropout_rate': 0.17277275928409125, 'learning_rate': 0.00011419324142666744, 'batch_size': 128, 'epochs': 39}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/39, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36, Train Loss: 0.000246, Test Loss: 0.000170\n",
      "Epoch 2/36, Train Loss: 0.000205, Test Loss: 0.000166\n",
      "Epoch 3/36, Train Loss: 0.000199, Test Loss: 0.000166\n",
      "Epoch 4/36, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 5/36, Train Loss: 0.000194, Test Loss: 0.000171\n",
      "Epoch 6/36, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 7/36, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 8/36, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 9/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 10/36, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/36, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 12/36, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 13/36, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/36, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 15/36, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 16/36, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 17/36, Train Loss: 0.000191, Test Loss: 0.000163\n",
      "Epoch 18/36, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 19/36, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 20/36, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 21/36, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 22/36, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 23/36, Train Loss: 0.000187, Test Loss: 0.000163\n",
      "Epoch 24/36, Train Loss: 0.000188, Test Loss: 0.000162\n",
      "Epoch 25/36, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 26/36, Train Loss: 0.000184, Test Loss: 0.000165\n",
      "Epoch 27/36, Train Loss: 0.000183, Test Loss: 0.000168\n",
      "Epoch 28/36, Train Loss: 0.000182, Test Loss: 0.000166\n",
      "Epoch 29/36, Train Loss: 0.000183, Test Loss: 0.000166\n",
      "Epoch 30/36, Train Loss: 0.000175, Test Loss: 0.000164\n",
      "Epoch 31/36, Train Loss: 0.000177, Test Loss: 0.000165\n",
      "Epoch 32/36, Train Loss: 0.000167, Test Loss: 0.000167\n",
      "Epoch 33/36, Train Loss: 0.000173, Test Loss: 0.000165\n",
      "Epoch 34/36, Train Loss: 0.000169, Test Loss: 0.000166\n",
      "Epoch 35/36, Train Loss: 0.000157, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:29:25,610] Trial 130 finished with value: 0.00016588961119440125 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 182, 'layer_1_size': 100, 'layer_2_size': 161, 'dropout_rate': 0.1287033251543431, 'learning_rate': 0.0002131012978469375, 'batch_size': 128, 'epochs': 36}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/36, Train Loss: 0.000173, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33, Train Loss: 0.000253, Test Loss: 0.000173\n",
      "Epoch 2/33, Train Loss: 0.000200, Test Loss: 0.000166\n",
      "Epoch 3/33, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 4/33, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 5/33, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 6/33, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 7/33, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 8/33, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 9/33, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 10/33, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/33, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 12/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/33, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 14/33, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 15/33, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 16/33, Train Loss: 0.000190, Test Loss: 0.000176\n",
      "Epoch 17/33, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/33, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 19/33, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 20/33, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 21/33, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 22/33, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 23/33, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 24/33, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 25/33, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 26/33, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 27/33, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 28/33, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 29/33, Train Loss: 0.000181, Test Loss: 0.000165\n",
      "Epoch 30/33, Train Loss: 0.000183, Test Loss: 0.000166\n",
      "Epoch 31/33, Train Loss: 0.000176, Test Loss: 0.000166\n",
      "Epoch 32/33, Train Loss: 0.000188, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:29:57,828] Trial 131 finished with value: 0.0001653125076436188 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 209, 'layer_1_size': 73, 'layer_2_size': 191, 'dropout_rate': 0.1251990589173713, 'learning_rate': 0.00028639598730624506, 'batch_size': 32, 'epochs': 33}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/33, Train Loss: 0.000186, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.000346, Test Loss: 0.000168\n",
      "Epoch 2/30, Train Loss: 0.000219, Test Loss: 0.000168\n",
      "Epoch 3/30, Train Loss: 0.000209, Test Loss: 0.000169\n",
      "Epoch 4/30, Train Loss: 0.000203, Test Loss: 0.000168\n",
      "Epoch 5/30, Train Loss: 0.000200, Test Loss: 0.000166\n",
      "Epoch 6/30, Train Loss: 0.000198, Test Loss: 0.000167\n",
      "Epoch 7/30, Train Loss: 0.000197, Test Loss: 0.000165\n",
      "Epoch 8/30, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 9/30, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 10/30, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 11/30, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 12/30, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 13/30, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/30, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/30, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/30, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 17/30, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 18/30, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 19/30, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 20/30, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 21/30, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 22/30, Train Loss: 0.000186, Test Loss: 0.000167\n",
      "Epoch 23/30, Train Loss: 0.000182, Test Loss: 0.000166\n",
      "Epoch 24/30, Train Loss: 0.000178, Test Loss: 0.000166\n",
      "Epoch 25/30, Train Loss: 0.000180, Test Loss: 0.000164\n",
      "Epoch 26/30, Train Loss: 0.000174, Test Loss: 0.000168\n",
      "Epoch 27/30, Train Loss: 0.000168, Test Loss: 0.000177\n",
      "Epoch 28/30, Train Loss: 0.000173, Test Loss: 0.000166\n",
      "Epoch 29/30, Train Loss: 0.000159, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:30:25,729] Trial 132 finished with value: 0.00016611861142410493 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 233, 'layer_1_size': 71, 'layer_2_size': 185, 'dropout_rate': 0.10044585842828488, 'learning_rate': 0.00014812382447355687, 'batch_size': 32, 'epochs': 30}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.000157, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34, Train Loss: 0.001027, Test Loss: 0.000184\n",
      "Epoch 2/34, Train Loss: 0.000402, Test Loss: 0.000233\n",
      "Epoch 3/34, Train Loss: 0.000341, Test Loss: 0.000180\n",
      "Epoch 4/34, Train Loss: 0.000299, Test Loss: 0.000172\n",
      "Epoch 5/34, Train Loss: 0.000274, Test Loss: 0.000173\n",
      "Epoch 6/34, Train Loss: 0.000250, Test Loss: 0.000172\n",
      "Epoch 7/34, Train Loss: 0.000239, Test Loss: 0.000168\n",
      "Epoch 8/34, Train Loss: 0.000226, Test Loss: 0.000167\n",
      "Epoch 9/34, Train Loss: 0.000219, Test Loss: 0.000166\n",
      "Epoch 10/34, Train Loss: 0.000213, Test Loss: 0.000167\n",
      "Epoch 11/34, Train Loss: 0.000207, Test Loss: 0.000166\n",
      "Epoch 12/34, Train Loss: 0.000203, Test Loss: 0.000166\n",
      "Epoch 13/34, Train Loss: 0.000199, Test Loss: 0.000166\n",
      "Epoch 14/34, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 15/34, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 16/34, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 17/34, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 18/34, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 19/34, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 20/34, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/34, Train Loss: 0.000191, Test Loss: 0.000168\n",
      "Epoch 22/34, Train Loss: 0.000190, Test Loss: 0.000171\n",
      "Epoch 23/34, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 24/34, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/34, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 26/34, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 27/34, Train Loss: 0.000188, Test Loss: 0.000168\n",
      "Epoch 28/34, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 29/34, Train Loss: 0.000190, Test Loss: 0.000170\n",
      "Epoch 30/34, Train Loss: 0.000188, Test Loss: 0.000167\n",
      "Epoch 31/34, Train Loss: 0.000188, Test Loss: 0.000168\n",
      "Epoch 32/34, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 33/34, Train Loss: 0.000186, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:30:37,806] Trial 133 finished with value: 0.00016675521709980638 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 173, 'layer_1_size': 63, 'layer_2_size': 35, 'dropout_rate': 0.11793161419188308, 'learning_rate': 0.00037745086239272596, 'batch_size': 128, 'epochs': 34}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/34, Train Loss: 0.000184, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37, Train Loss: 0.000241, Test Loss: 0.000169\n",
      "Epoch 2/37, Train Loss: 0.000206, Test Loss: 0.000167\n",
      "Epoch 3/37, Train Loss: 0.000201, Test Loss: 0.000168\n",
      "Epoch 4/37, Train Loss: 0.000197, Test Loss: 0.000165\n",
      "Epoch 5/37, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 6/37, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 7/37, Train Loss: 0.000192, Test Loss: 0.000172\n",
      "Epoch 8/37, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/37, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 10/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/37, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 12/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/37, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 15/37, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 16/37, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 17/37, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 18/37, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 19/37, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 20/37, Train Loss: 0.000188, Test Loss: 0.000168\n",
      "Epoch 21/37, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 22/37, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 23/37, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 24/37, Train Loss: 0.000186, Test Loss: 0.000181\n",
      "Epoch 25/37, Train Loss: 0.000184, Test Loss: 0.000164\n",
      "Epoch 26/37, Train Loss: 0.000185, Test Loss: 0.000164\n",
      "Epoch 27/37, Train Loss: 0.000183, Test Loss: 0.000164\n",
      "Epoch 28/37, Train Loss: 0.000177, Test Loss: 0.000168\n",
      "Epoch 29/37, Train Loss: 0.000174, Test Loss: 0.000164\n",
      "Epoch 30/37, Train Loss: 0.000169, Test Loss: 0.000165\n",
      "Epoch 31/37, Train Loss: 0.000168, Test Loss: 0.000166\n",
      "Epoch 32/37, Train Loss: 0.000162, Test Loss: 0.000168\n",
      "Epoch 33/37, Train Loss: 0.000161, Test Loss: 0.000166\n",
      "Epoch 34/37, Train Loss: 0.000167, Test Loss: 0.000166\n",
      "Epoch 35/37, Train Loss: 0.000168, Test Loss: 0.000165\n",
      "Epoch 36/37, Train Loss: 0.000186, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:31:19,010] Trial 134 finished with value: 0.0001650269308327317 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 218, 'layer_1_size': 89, 'layer_2_size': 212, 'layer_3_size': 99, 'dropout_rate': 0.15320719603146513, 'learning_rate': 0.00017653629879905606, 'batch_size': 32, 'epochs': 37}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/37, Train Loss: 0.000154, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/31, Train Loss: 0.000315, Test Loss: 0.000167\n",
      "Epoch 2/31, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 3/31, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 4/31, Train Loss: 0.000197, Test Loss: 0.000171\n",
      "Epoch 5/31, Train Loss: 0.000197, Test Loss: 0.000171\n",
      "Epoch 6/31, Train Loss: 0.000198, Test Loss: 0.000219\n",
      "Epoch 7/31, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 8/31, Train Loss: 0.000200, Test Loss: 0.000217\n",
      "Epoch 9/31, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 10/31, Train Loss: 0.000199, Test Loss: 0.000174\n",
      "Epoch 11/31, Train Loss: 0.000199, Test Loss: 0.000173\n",
      "Epoch 12/31, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 13/31, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 14/31, Train Loss: 0.000199, Test Loss: 0.000175\n",
      "Epoch 15/31, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 16/31, Train Loss: 0.000198, Test Loss: 0.000170\n",
      "Epoch 17/31, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 18/31, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 19/31, Train Loss: 0.000199, Test Loss: 0.000173\n",
      "Epoch 20/31, Train Loss: 0.000199, Test Loss: 0.000172\n",
      "Epoch 21/31, Train Loss: 0.000199, Test Loss: 0.000179\n",
      "Epoch 22/31, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 23/31, Train Loss: 0.000199, Test Loss: 0.000180\n",
      "Epoch 24/31, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 25/31, Train Loss: 0.000200, Test Loss: 0.000175\n",
      "Epoch 26/31, Train Loss: 0.000199, Test Loss: 0.000171\n",
      "Epoch 27/31, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 28/31, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 29/31, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 30/31, Train Loss: 0.000199, Test Loss: 0.000171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:31:46,413] Trial 135 finished with value: 0.00017202732060688446 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 200, 'layer_1_size': 197, 'layer_2_size': 191, 'dropout_rate': 0.14345197215272254, 'learning_rate': 0.004159678908448812, 'batch_size': 32, 'epochs': 31}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/31, Train Loss: 0.000199, Test Loss: 0.000172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35, Train Loss: 0.000310, Test Loss: 0.000169\n",
      "Epoch 2/35, Train Loss: 0.000216, Test Loss: 0.000169\n",
      "Epoch 3/35, Train Loss: 0.000204, Test Loss: 0.000168\n",
      "Epoch 4/35, Train Loss: 0.000200, Test Loss: 0.000168\n",
      "Epoch 5/35, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 6/35, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 7/35, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 8/35, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 9/35, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 10/35, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 11/35, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 12/35, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/35, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/35, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/35, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/35, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 17/35, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 18/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/35, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 21/35, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 22/35, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 23/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/35, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 25/35, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 26/35, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 27/35, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 28/35, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 29/35, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 30/35, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 31/35, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 32/35, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 33/35, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 34/35, Train Loss: 0.000188, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:32:10,857] Trial 136 finished with value: 0.00016687554380628318 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 85, 'layer_1_size': 51, 'layer_2_size': 148, 'dropout_rate': 0.13307324205976995, 'learning_rate': 8.792961554444196e-05, 'batch_size': 32, 'epochs': 35}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/35, Train Loss: 0.000186, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26, Train Loss: 0.000461, Test Loss: 0.000199\n",
      "Epoch 2/26, Train Loss: 0.000253, Test Loss: 0.000186\n",
      "Epoch 3/26, Train Loss: 0.000225, Test Loss: 0.000177\n",
      "Epoch 4/26, Train Loss: 0.000209, Test Loss: 0.000175\n",
      "Epoch 5/26, Train Loss: 0.000202, Test Loss: 0.000169\n",
      "Epoch 6/26, Train Loss: 0.000198, Test Loss: 0.000170\n",
      "Epoch 7/26, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 8/26, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 9/26, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 10/26, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 11/26, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 12/26, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 13/26, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 14/26, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 15/26, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 16/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 17/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 18/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 19/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 20/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 21/26, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 22/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 23/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 25/26, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:32:18,788] Trial 137 finished with value: 0.00016527582308680717 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 214, 'layer_1_size': 43, 'dropout_rate': 0.16591174088361565, 'learning_rate': 0.00012886308776919087, 'batch_size': 128, 'epochs': 26}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/26, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38, Train Loss: 0.000257, Test Loss: 0.000170\n",
      "Epoch 2/38, Train Loss: 0.000211, Test Loss: 0.000167\n",
      "Epoch 3/38, Train Loss: 0.000203, Test Loss: 0.000166\n",
      "Epoch 4/38, Train Loss: 0.000198, Test Loss: 0.000167\n",
      "Epoch 5/38, Train Loss: 0.000196, Test Loss: 0.000165\n",
      "Epoch 6/38, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 7/38, Train Loss: 0.000193, Test Loss: 0.000171\n",
      "Epoch 8/38, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 9/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/38, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/38, Train Loss: 0.000208, Test Loss: 0.000167\n",
      "Epoch 12/38, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 13/38, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 14/38, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 15/38, Train Loss: 0.000191, Test Loss: 0.000172\n",
      "Epoch 16/38, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 17/38, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 18/38, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 19/38, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 20/38, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 21/38, Train Loss: 0.000190, Test Loss: 0.000171\n",
      "Epoch 22/38, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 23/38, Train Loss: 0.000188, Test Loss: 0.000172\n",
      "Epoch 24/38, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 25/38, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 26/38, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 27/38, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 28/38, Train Loss: 0.000180, Test Loss: 0.000165\n",
      "Epoch 29/38, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 30/38, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 31/38, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 32/38, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 33/38, Train Loss: 0.000177, Test Loss: 0.000165\n",
      "Epoch 34/38, Train Loss: 0.000180, Test Loss: 0.000165\n",
      "Epoch 35/38, Train Loss: 0.000175, Test Loss: 0.000165\n",
      "Epoch 36/38, Train Loss: 0.000168, Test Loss: 0.000166\n",
      "Epoch 37/38, Train Loss: 0.000167, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:33:07,538] Trial 138 finished with value: 0.00023049960200003096 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 241, 'layer_1_size': 67, 'layer_2_size': 47, 'layer_3_size': 158, 'dropout_rate': 0.12334922815160679, 'learning_rate': 0.0002450940956519958, 'batch_size': 32, 'epochs': 38}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/38, Train Loss: 0.000179, Test Loss: 0.000230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28, Train Loss: 0.000223, Test Loss: 0.000169\n",
      "Epoch 2/28, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 3/28, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 4/28, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 5/28, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 6/28, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 7/28, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 8/28, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 9/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/28, Train Loss: 0.000194, Test Loss: 0.000172\n",
      "Epoch 11/28, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/28, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 13/28, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 14/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 15/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/28, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 17/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 18/28, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 19/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 20/28, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 21/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 22/28, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 23/28, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 24/28, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 25/28, Train Loss: 0.000192, Test Loss: 0.000163\n",
      "Epoch 26/28, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 27/28, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:33:38,062] Trial 139 finished with value: 0.00016515983383849362 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 191, 'layer_1_size': 82, 'layer_2_size': 188, 'dropout_rate': 0.17942346244818125, 'learning_rate': 0.0005734394336150379, 'batch_size': 32, 'epochs': 28}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/28, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Train Loss: 0.000249, Test Loss: 0.000172\n",
      "Epoch 2/24, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 3/24, Train Loss: 0.000195, Test Loss: 0.000170\n",
      "Epoch 4/24, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 5/24, Train Loss: 0.000195, Test Loss: 0.000170\n",
      "Epoch 6/24, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 7/24, Train Loss: 0.000194, Test Loss: 0.000169\n",
      "Epoch 8/24, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 9/24, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 10/24, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 11/24, Train Loss: 0.000195, Test Loss: 0.000172\n",
      "Epoch 12/24, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 13/24, Train Loss: 0.000195, Test Loss: 0.000172\n",
      "Epoch 14/24, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 15/24, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 16/24, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 17/24, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 18/24, Train Loss: 0.000195, Test Loss: 0.000170\n",
      "Epoch 19/24, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 20/24, Train Loss: 0.000196, Test Loss: 0.000171\n",
      "Epoch 21/24, Train Loss: 0.000196, Test Loss: 0.000174\n",
      "Epoch 22/24, Train Loss: 0.000196, Test Loss: 0.000171\n",
      "Epoch 23/24, Train Loss: 0.000196, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:34:19,152] Trial 140 finished with value: 0.00017000107557086882 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 73, 'layer_1_size': 159, 'layer_2_size': 176, 'layer_3_size': 207, 'dropout_rate': 0.3299330498236886, 'learning_rate': 0.0008495610925106308, 'batch_size': 32, 'epochs': 24}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Train Loss: 0.000196, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27, Train Loss: 0.000291, Test Loss: 0.000185\n",
      "Epoch 2/27, Train Loss: 0.000221, Test Loss: 0.000182\n",
      "Epoch 3/27, Train Loss: 0.000210, Test Loss: 0.000193\n",
      "Epoch 4/27, Train Loss: 0.000205, Test Loss: 0.000169\n",
      "Epoch 5/27, Train Loss: 0.000211, Test Loss: 0.000172\n",
      "Epoch 6/27, Train Loss: 0.000199, Test Loss: 0.000168\n",
      "Epoch 7/27, Train Loss: 0.000197, Test Loss: 0.000175\n",
      "Epoch 8/27, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 9/27, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 10/27, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 11/27, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 12/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 13/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 15/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/27, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 19/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/27, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 23/27, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 24/27, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 25/27, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 26/27, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:34:40,147] Trial 141 finished with value: 0.0001654093650006783 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 206, 'layer_1_size': 165, 'layer_2_size': 198, 'layer_3_size': 77, 'dropout_rate': 0.21721288230403402, 'learning_rate': 0.00017956726014424807, 'batch_size': 128, 'epochs': 27}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/27, Train Loss: 0.000189, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Train Loss: 0.000275, Test Loss: 0.000173\n",
      "Epoch 2/40, Train Loss: 0.000203, Test Loss: 0.000170\n",
      "Epoch 3/40, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 4/40, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 5/40, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 6/40, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 7/40, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 8/40, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 9/40, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 10/40, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 11/40, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 12/40, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 13/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 14/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 18/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 20/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 21/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 22/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 23/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 25/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 26/40, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 27/40, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 28/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 29/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 30/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 31/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 32/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 33/40, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 34/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 35/40, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 36/40, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 37/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 38/40, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 39/40, Train Loss: 0.000188, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:34:59,984] Trial 142 finished with value: 0.00016398524167016149 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 224, 'layer_1_size': 154, 'layer_2_size': 40, 'dropout_rate': 0.18947281805331695, 'learning_rate': 0.00011168036113964936, 'batch_size': 256, 'epochs': 40}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40, Train Loss: 0.000189, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Train Loss: 0.003598, Test Loss: 0.000259\n",
      "Epoch 2/40, Train Loss: 0.000966, Test Loss: 0.000250\n",
      "Epoch 3/40, Train Loss: 0.000787, Test Loss: 0.000287\n",
      "Epoch 4/40, Train Loss: 0.000670, Test Loss: 0.000318\n",
      "Epoch 5/40, Train Loss: 0.000611, Test Loss: 0.000256\n",
      "Epoch 6/40, Train Loss: 0.000568, Test Loss: 0.000284\n",
      "Epoch 7/40, Train Loss: 0.000528, Test Loss: 0.000261\n",
      "Epoch 8/40, Train Loss: 0.000492, Test Loss: 0.000288\n",
      "Epoch 9/40, Train Loss: 0.000458, Test Loss: 0.000300\n",
      "Epoch 10/40, Train Loss: 0.000441, Test Loss: 0.000272\n",
      "Epoch 11/40, Train Loss: 0.000425, Test Loss: 0.000277\n",
      "Epoch 12/40, Train Loss: 0.000411, Test Loss: 0.000277\n",
      "Epoch 13/40, Train Loss: 0.000400, Test Loss: 0.000259\n",
      "Epoch 14/40, Train Loss: 0.000382, Test Loss: 0.000243\n",
      "Epoch 15/40, Train Loss: 0.000376, Test Loss: 0.000236\n",
      "Epoch 16/40, Train Loss: 0.000364, Test Loss: 0.000242\n",
      "Epoch 17/40, Train Loss: 0.000353, Test Loss: 0.000225\n",
      "Epoch 18/40, Train Loss: 0.000340, Test Loss: 0.000219\n",
      "Epoch 19/40, Train Loss: 0.000330, Test Loss: 0.000211\n",
      "Epoch 20/40, Train Loss: 0.000320, Test Loss: 0.000194\n",
      "Epoch 21/40, Train Loss: 0.000311, Test Loss: 0.000211\n",
      "Epoch 22/40, Train Loss: 0.000298, Test Loss: 0.000197\n",
      "Epoch 23/40, Train Loss: 0.000289, Test Loss: 0.000200\n",
      "Epoch 24/40, Train Loss: 0.000282, Test Loss: 0.000189\n",
      "Epoch 25/40, Train Loss: 0.000275, Test Loss: 0.000191\n",
      "Epoch 26/40, Train Loss: 0.000268, Test Loss: 0.000188\n",
      "Epoch 27/40, Train Loss: 0.000263, Test Loss: 0.000185\n",
      "Epoch 28/40, Train Loss: 0.000255, Test Loss: 0.000175\n",
      "Epoch 29/40, Train Loss: 0.000248, Test Loss: 0.000178\n",
      "Epoch 30/40, Train Loss: 0.000244, Test Loss: 0.000173\n",
      "Epoch 31/40, Train Loss: 0.000238, Test Loss: 0.000171\n",
      "Epoch 32/40, Train Loss: 0.000233, Test Loss: 0.000173\n",
      "Epoch 33/40, Train Loss: 0.000237, Test Loss: 0.000175\n",
      "Epoch 34/40, Train Loss: 0.000228, Test Loss: 0.000170\n",
      "Epoch 35/40, Train Loss: 0.000225, Test Loss: 0.000168\n",
      "Epoch 36/40, Train Loss: 0.000221, Test Loss: 0.000169\n",
      "Epoch 37/40, Train Loss: 0.000219, Test Loss: 0.000168\n",
      "Epoch 38/40, Train Loss: 0.000215, Test Loss: 0.000169\n",
      "Epoch 39/40, Train Loss: 0.000212, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:35:15,596] Trial 143 finished with value: 0.00016774919447104162 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 229, 'layer_1_size': 143, 'layer_2_size': 36, 'dropout_rate': 0.18999069604358176, 'learning_rate': 0.00010534297723917501, 'batch_size': 256, 'epochs': 40}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40, Train Loss: 0.000210, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39, Train Loss: 0.000265, Test Loss: 0.000170\n",
      "Epoch 2/39, Train Loss: 0.000201, Test Loss: 0.000169\n",
      "Epoch 3/39, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 4/39, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 5/39, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 6/39, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 7/39, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 8/39, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 9/39, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 10/39, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 11/39, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 12/39, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 13/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 14/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 15/39, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 16/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 17/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 18/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 19/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 20/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 21/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 22/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 23/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 25/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 26/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 27/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 28/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 29/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 30/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 31/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 32/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 33/39, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 34/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 35/39, Train Loss: 0.000194, Test Loss: 0.000164\n",
      "Epoch 36/39, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 37/39, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 38/39, Train Loss: 0.000190, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:35:27,810] Trial 144 finished with value: 0.00016422156371728277 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 222, 'layer_1_size': 147, 'layer_2_size': 42, 'dropout_rate': 0.20764109674438952, 'learning_rate': 0.00014669846601929448, 'batch_size': 256, 'epochs': 39}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/39, Train Loss: 0.000190, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Train Loss: 0.000303, Test Loss: 0.000174\n",
      "Epoch 2/40, Train Loss: 0.000204, Test Loss: 0.000170\n",
      "Epoch 3/40, Train Loss: 0.000199, Test Loss: 0.000169\n",
      "Epoch 4/40, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 5/40, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 6/40, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 7/40, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 8/40, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 9/40, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 10/40, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 11/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 13/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 14/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 15/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 17/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 18/40, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 19/40, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 20/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 21/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 22/40, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 23/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 25/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 26/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 27/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 28/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 29/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 30/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 31/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 32/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 33/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 34/40, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 35/40, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 36/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 37/40, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 38/40, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 39/40, Train Loss: 0.000191, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:35:39,483] Trial 145 finished with value: 0.00016451319900243693 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 224, 'layer_1_size': 147, 'layer_2_size': 42, 'dropout_rate': 0.20932257614395947, 'learning_rate': 0.00014235929353969087, 'batch_size': 256, 'epochs': 40}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40, Train Loss: 0.000189, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38, Train Loss: 0.002450, Test Loss: 0.000272\n",
      "Epoch 2/38, Train Loss: 0.000735, Test Loss: 0.000273\n",
      "Epoch 3/38, Train Loss: 0.000588, Test Loss: 0.000328\n",
      "Epoch 4/38, Train Loss: 0.000525, Test Loss: 0.000300\n",
      "Epoch 5/38, Train Loss: 0.000484, Test Loss: 0.000282\n",
      "Epoch 6/38, Train Loss: 0.000459, Test Loss: 0.000277\n",
      "Epoch 7/38, Train Loss: 0.000433, Test Loss: 0.000323\n",
      "Epoch 8/38, Train Loss: 0.000417, Test Loss: 0.000285\n",
      "Epoch 9/38, Train Loss: 0.000400, Test Loss: 0.000300\n",
      "Epoch 10/38, Train Loss: 0.000389, Test Loss: 0.000282\n",
      "Epoch 11/38, Train Loss: 0.000374, Test Loss: 0.000263\n",
      "Epoch 12/38, Train Loss: 0.000353, Test Loss: 0.000236\n",
      "Epoch 13/38, Train Loss: 0.000342, Test Loss: 0.000247\n",
      "Epoch 14/38, Train Loss: 0.000328, Test Loss: 0.000255\n",
      "Epoch 15/38, Train Loss: 0.000317, Test Loss: 0.000217\n",
      "Epoch 16/38, Train Loss: 0.000305, Test Loss: 0.000209\n",
      "Epoch 17/38, Train Loss: 0.000292, Test Loss: 0.000218\n",
      "Epoch 18/38, Train Loss: 0.000284, Test Loss: 0.000201\n",
      "Epoch 19/38, Train Loss: 0.000274, Test Loss: 0.000191\n",
      "Epoch 20/38, Train Loss: 0.000269, Test Loss: 0.000192\n",
      "Epoch 21/38, Train Loss: 0.000258, Test Loss: 0.000200\n",
      "Epoch 22/38, Train Loss: 0.000250, Test Loss: 0.000187\n",
      "Epoch 23/38, Train Loss: 0.000246, Test Loss: 0.000193\n",
      "Epoch 24/38, Train Loss: 0.000241, Test Loss: 0.000180\n",
      "Epoch 25/38, Train Loss: 0.000235, Test Loss: 0.000180\n",
      "Epoch 26/38, Train Loss: 0.000229, Test Loss: 0.000175\n",
      "Epoch 27/38, Train Loss: 0.000226, Test Loss: 0.000181\n",
      "Epoch 28/38, Train Loss: 0.000220, Test Loss: 0.000174\n",
      "Epoch 29/38, Train Loss: 0.000219, Test Loss: 0.000175\n",
      "Epoch 30/38, Train Loss: 0.000216, Test Loss: 0.000170\n",
      "Epoch 31/38, Train Loss: 0.000213, Test Loss: 0.000173\n",
      "Epoch 32/38, Train Loss: 0.000210, Test Loss: 0.000173\n",
      "Epoch 33/38, Train Loss: 0.000209, Test Loss: 0.000170\n",
      "Epoch 34/38, Train Loss: 0.000206, Test Loss: 0.000169\n",
      "Epoch 35/38, Train Loss: 0.000205, Test Loss: 0.000168\n",
      "Epoch 36/38, Train Loss: 0.000202, Test Loss: 0.000169\n",
      "Epoch 37/38, Train Loss: 0.000202, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:35:51,394] Trial 146 finished with value: 0.000167194814322659 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 214, 'layer_1_size': 156, 'layer_2_size': 53, 'dropout_rate': 0.1953290380975271, 'learning_rate': 0.00012036608688410044, 'batch_size': 256, 'epochs': 38}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/38, Train Loss: 0.000200, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39, Train Loss: 0.000521, Test Loss: 0.000181\n",
      "Epoch 2/39, Train Loss: 0.000309, Test Loss: 0.000192\n",
      "Epoch 3/39, Train Loss: 0.000270, Test Loss: 0.000194\n",
      "Epoch 4/39, Train Loss: 0.000248, Test Loss: 0.000201\n",
      "Epoch 5/39, Train Loss: 0.000239, Test Loss: 0.000207\n",
      "Epoch 6/39, Train Loss: 0.000231, Test Loss: 0.000192\n",
      "Epoch 7/39, Train Loss: 0.000228, Test Loss: 0.000191\n",
      "Epoch 8/39, Train Loss: 0.000222, Test Loss: 0.000185\n",
      "Epoch 9/39, Train Loss: 0.000218, Test Loss: 0.000190\n",
      "Epoch 10/39, Train Loss: 0.000216, Test Loss: 0.000178\n",
      "Epoch 11/39, Train Loss: 0.000212, Test Loss: 0.000181\n",
      "Epoch 12/39, Train Loss: 0.000210, Test Loss: 0.000177\n",
      "Epoch 13/39, Train Loss: 0.000208, Test Loss: 0.000177\n",
      "Epoch 14/39, Train Loss: 0.000206, Test Loss: 0.000174\n",
      "Epoch 15/39, Train Loss: 0.000204, Test Loss: 0.000174\n",
      "Epoch 16/39, Train Loss: 0.000205, Test Loss: 0.000172\n",
      "Epoch 17/39, Train Loss: 0.000203, Test Loss: 0.000171\n",
      "Epoch 18/39, Train Loss: 0.000201, Test Loss: 0.000172\n",
      "Epoch 19/39, Train Loss: 0.000200, Test Loss: 0.000172\n",
      "Epoch 20/39, Train Loss: 0.000200, Test Loss: 0.000171\n",
      "Epoch 21/39, Train Loss: 0.000198, Test Loss: 0.000171\n",
      "Epoch 22/39, Train Loss: 0.000198, Test Loss: 0.000170\n",
      "Epoch 23/39, Train Loss: 0.000197, Test Loss: 0.000172\n",
      "Epoch 24/39, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 25/39, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 26/39, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 27/39, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 28/39, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 29/39, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 30/39, Train Loss: 0.000194, Test Loss: 0.000169\n",
      "Epoch 31/39, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 32/39, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 33/39, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 34/39, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 35/39, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 36/39, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 37/39, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 38/39, Train Loss: 0.000193, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:36:03,088] Trial 147 finished with value: 0.00016648813429891298 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 222, 'layer_1_size': 136, 'layer_2_size': 59, 'dropout_rate': 0.22398495851140593, 'learning_rate': 5.9000618380320275e-05, 'batch_size': 256, 'epochs': 39}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/39, Train Loss: 0.000193, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39, Train Loss: 0.001011, Test Loss: 0.000215\n",
      "Epoch 2/39, Train Loss: 0.000445, Test Loss: 0.000242\n",
      "Epoch 3/39, Train Loss: 0.000337, Test Loss: 0.000227\n",
      "Epoch 4/39, Train Loss: 0.000291, Test Loss: 0.000243\n",
      "Epoch 5/39, Train Loss: 0.000268, Test Loss: 0.000229\n",
      "Epoch 6/39, Train Loss: 0.000250, Test Loss: 0.000252\n",
      "Epoch 7/39, Train Loss: 0.000241, Test Loss: 0.000230\n",
      "Epoch 8/39, Train Loss: 0.000233, Test Loss: 0.000218\n",
      "Epoch 9/39, Train Loss: 0.000226, Test Loss: 0.000208\n",
      "Epoch 10/39, Train Loss: 0.000223, Test Loss: 0.000197\n",
      "Epoch 11/39, Train Loss: 0.000218, Test Loss: 0.000194\n",
      "Epoch 12/39, Train Loss: 0.000214, Test Loss: 0.000190\n",
      "Epoch 13/39, Train Loss: 0.000211, Test Loss: 0.000183\n",
      "Epoch 14/39, Train Loss: 0.000209, Test Loss: 0.000181\n",
      "Epoch 15/39, Train Loss: 0.000209, Test Loss: 0.000177\n",
      "Epoch 16/39, Train Loss: 0.000206, Test Loss: 0.000175\n",
      "Epoch 17/39, Train Loss: 0.000203, Test Loss: 0.000179\n",
      "Epoch 18/39, Train Loss: 0.000203, Test Loss: 0.000174\n",
      "Epoch 19/39, Train Loss: 0.000201, Test Loss: 0.000172\n",
      "Epoch 20/39, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 21/39, Train Loss: 0.000198, Test Loss: 0.000171\n",
      "Epoch 22/39, Train Loss: 0.000198, Test Loss: 0.000174\n",
      "Epoch 23/39, Train Loss: 0.000197, Test Loss: 0.000173\n",
      "Epoch 24/39, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 25/39, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 26/39, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 27/39, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 28/39, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 29/39, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 30/39, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 31/39, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 32/39, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 33/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 34/39, Train Loss: 0.000193, Test Loss: 0.000169\n",
      "Epoch 35/39, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 36/39, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 37/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 38/39, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:36:14,298] Trial 148 finished with value: 0.00016748924351685997 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 219, 'layer_1_size': 169, 'dropout_rate': 0.18164392751454678, 'learning_rate': 7.689103415240941e-05, 'batch_size': 256, 'epochs': 39}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/39, Train Loss: 0.000192, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39, Train Loss: 0.002888, Test Loss: 0.000287\n",
      "Epoch 2/39, Train Loss: 0.000730, Test Loss: 0.000311\n",
      "Epoch 3/39, Train Loss: 0.000589, Test Loss: 0.000301\n",
      "Epoch 4/39, Train Loss: 0.000529, Test Loss: 0.000284\n",
      "Epoch 5/39, Train Loss: 0.000496, Test Loss: 0.000315\n",
      "Epoch 6/39, Train Loss: 0.000463, Test Loss: 0.000347\n",
      "Epoch 7/39, Train Loss: 0.000442, Test Loss: 0.000277\n",
      "Epoch 8/39, Train Loss: 0.000414, Test Loss: 0.000251\n",
      "Epoch 9/39, Train Loss: 0.000396, Test Loss: 0.000257\n",
      "Epoch 10/39, Train Loss: 0.000386, Test Loss: 0.000272\n",
      "Epoch 11/39, Train Loss: 0.000370, Test Loss: 0.000222\n",
      "Epoch 12/39, Train Loss: 0.000348, Test Loss: 0.000221\n",
      "Epoch 13/39, Train Loss: 0.000332, Test Loss: 0.000215\n",
      "Epoch 14/39, Train Loss: 0.000323, Test Loss: 0.000195\n",
      "Epoch 15/39, Train Loss: 0.000310, Test Loss: 0.000192\n",
      "Epoch 16/39, Train Loss: 0.000299, Test Loss: 0.000184\n",
      "Epoch 17/39, Train Loss: 0.000286, Test Loss: 0.000189\n",
      "Epoch 18/39, Train Loss: 0.000278, Test Loss: 0.000182\n",
      "Epoch 19/39, Train Loss: 0.000271, Test Loss: 0.000178\n",
      "Epoch 20/39, Train Loss: 0.000261, Test Loss: 0.000189\n",
      "Epoch 21/39, Train Loss: 0.000255, Test Loss: 0.000174\n",
      "Epoch 22/39, Train Loss: 0.000246, Test Loss: 0.000181\n",
      "Epoch 23/39, Train Loss: 0.000240, Test Loss: 0.000176\n",
      "Epoch 24/39, Train Loss: 0.000235, Test Loss: 0.000174\n",
      "Epoch 25/39, Train Loss: 0.000233, Test Loss: 0.000173\n",
      "Epoch 26/39, Train Loss: 0.000228, Test Loss: 0.000169\n",
      "Epoch 27/39, Train Loss: 0.000223, Test Loss: 0.000168\n",
      "Epoch 28/39, Train Loss: 0.000219, Test Loss: 0.000168\n",
      "Epoch 29/39, Train Loss: 0.000218, Test Loss: 0.000169\n",
      "Epoch 30/39, Train Loss: 0.000213, Test Loss: 0.000168\n",
      "Epoch 31/39, Train Loss: 0.000211, Test Loss: 0.000168\n",
      "Epoch 32/39, Train Loss: 0.000207, Test Loss: 0.000169\n",
      "Epoch 33/39, Train Loss: 0.000207, Test Loss: 0.000167\n",
      "Epoch 34/39, Train Loss: 0.000204, Test Loss: 0.000165\n",
      "Epoch 35/39, Train Loss: 0.000203, Test Loss: 0.000168\n",
      "Epoch 36/39, Train Loss: 0.000202, Test Loss: 0.000168\n",
      "Epoch 37/39, Train Loss: 0.000199, Test Loss: 0.000166\n",
      "Epoch 38/39, Train Loss: 0.000198, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:36:25,866] Trial 149 finished with value: 0.00016571329568602864 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 227, 'layer_1_size': 151, 'layer_2_size': 35, 'dropout_rate': 0.1566324080325678, 'learning_rate': 0.00020744092398117963, 'batch_size': 256, 'epochs': 39}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/39, Train Loss: 0.000197, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38, Train Loss: 0.002029, Test Loss: 0.000322\n",
      "Epoch 2/38, Train Loss: 0.000604, Test Loss: 0.000254\n",
      "Epoch 3/38, Train Loss: 0.000481, Test Loss: 0.000269\n",
      "Epoch 4/38, Train Loss: 0.000434, Test Loss: 0.000287\n",
      "Epoch 5/38, Train Loss: 0.000413, Test Loss: 0.000293\n",
      "Epoch 6/38, Train Loss: 0.000389, Test Loss: 0.000280\n",
      "Epoch 7/38, Train Loss: 0.000369, Test Loss: 0.000240\n",
      "Epoch 8/38, Train Loss: 0.000358, Test Loss: 0.000259\n",
      "Epoch 9/38, Train Loss: 0.000338, Test Loss: 0.000230\n",
      "Epoch 10/38, Train Loss: 0.000324, Test Loss: 0.000217\n",
      "Epoch 11/38, Train Loss: 0.000311, Test Loss: 0.000218\n",
      "Epoch 12/38, Train Loss: 0.000299, Test Loss: 0.000216\n",
      "Epoch 13/38, Train Loss: 0.000289, Test Loss: 0.000198\n",
      "Epoch 14/38, Train Loss: 0.000277, Test Loss: 0.000203\n",
      "Epoch 15/38, Train Loss: 0.000265, Test Loss: 0.000187\n",
      "Epoch 16/38, Train Loss: 0.000259, Test Loss: 0.000190\n",
      "Epoch 17/38, Train Loss: 0.000251, Test Loss: 0.000184\n",
      "Epoch 18/38, Train Loss: 0.000244, Test Loss: 0.000182\n",
      "Epoch 19/38, Train Loss: 0.000238, Test Loss: 0.000181\n",
      "Epoch 20/38, Train Loss: 0.000232, Test Loss: 0.000176\n",
      "Epoch 21/38, Train Loss: 0.000228, Test Loss: 0.000175\n",
      "Epoch 22/38, Train Loss: 0.000222, Test Loss: 0.000175\n",
      "Epoch 23/38, Train Loss: 0.000220, Test Loss: 0.000173\n",
      "Epoch 24/38, Train Loss: 0.000216, Test Loss: 0.000174\n",
      "Epoch 25/38, Train Loss: 0.000213, Test Loss: 0.000171\n",
      "Epoch 26/38, Train Loss: 0.000209, Test Loss: 0.000169\n",
      "Epoch 27/38, Train Loss: 0.000206, Test Loss: 0.000172\n",
      "Epoch 28/38, Train Loss: 0.000205, Test Loss: 0.000172\n",
      "Epoch 29/38, Train Loss: 0.000203, Test Loss: 0.000170\n",
      "Epoch 30/38, Train Loss: 0.000202, Test Loss: 0.000172\n",
      "Epoch 31/38, Train Loss: 0.000201, Test Loss: 0.000170\n",
      "Epoch 32/38, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 33/38, Train Loss: 0.000198, Test Loss: 0.000170\n",
      "Epoch 34/38, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 35/38, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 36/38, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 37/38, Train Loss: 0.000195, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:36:37,522] Trial 150 finished with value: 0.00016669537610376268 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 212, 'layer_1_size': 161, 'layer_2_size': 42, 'dropout_rate': 0.2032615910239715, 'learning_rate': 0.00013311936558939555, 'batch_size': 256, 'epochs': 38}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/38, Train Loss: 0.000194, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Train Loss: 0.000297, Test Loss: 0.000171\n",
      "Epoch 2/40, Train Loss: 0.000222, Test Loss: 0.000168\n",
      "Epoch 3/40, Train Loss: 0.000209, Test Loss: 0.000168\n",
      "Epoch 4/40, Train Loss: 0.000204, Test Loss: 0.000167\n",
      "Epoch 5/40, Train Loss: 0.000202, Test Loss: 0.000169\n",
      "Epoch 6/40, Train Loss: 0.000199, Test Loss: 0.000167\n",
      "Epoch 7/40, Train Loss: 0.000198, Test Loss: 0.000166\n",
      "Epoch 8/40, Train Loss: 0.000197, Test Loss: 0.000171\n",
      "Epoch 9/40, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 10/40, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 11/40, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 12/40, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 13/40, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 14/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 15/40, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 16/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/40, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 18/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 23/40, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 24/40, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 25/40, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 26/40, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 27/40, Train Loss: 0.000187, Test Loss: 0.000169\n",
      "Epoch 28/40, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 29/40, Train Loss: 0.000184, Test Loss: 0.000166\n",
      "Epoch 30/40, Train Loss: 0.000184, Test Loss: 0.000165\n",
      "Epoch 31/40, Train Loss: 0.000182, Test Loss: 0.000167\n",
      "Epoch 32/40, Train Loss: 0.000181, Test Loss: 0.000168\n",
      "Epoch 33/40, Train Loss: 0.000181, Test Loss: 0.000165\n",
      "Epoch 34/40, Train Loss: 0.000171, Test Loss: 0.000178\n",
      "Epoch 35/40, Train Loss: 0.000177, Test Loss: 0.000164\n",
      "Epoch 36/40, Train Loss: 0.000168, Test Loss: 0.000165\n",
      "Epoch 37/40, Train Loss: 0.000162, Test Loss: 0.000164\n",
      "Epoch 38/40, Train Loss: 0.000157, Test Loss: 0.000165\n",
      "Epoch 39/40, Train Loss: 0.000167, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:36:53,071] Trial 151 finished with value: 0.00016370869067736015 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 236, 'layer_1_size': 157, 'layer_2_size': 195, 'dropout_rate': 0.1473699486579929, 'learning_rate': 0.00015899311471122645, 'batch_size': 256, 'epochs': 40}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40, Train Loss: 0.000157, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Train Loss: 0.000314, Test Loss: 0.000170\n",
      "Epoch 2/40, Train Loss: 0.000228, Test Loss: 0.000171\n",
      "Epoch 3/40, Train Loss: 0.000213, Test Loss: 0.000171\n",
      "Epoch 4/40, Train Loss: 0.000206, Test Loss: 0.000170\n",
      "Epoch 5/40, Train Loss: 0.000202, Test Loss: 0.000167\n",
      "Epoch 6/40, Train Loss: 0.000201, Test Loss: 0.000169\n",
      "Epoch 7/40, Train Loss: 0.000198, Test Loss: 0.000167\n",
      "Epoch 8/40, Train Loss: 0.000198, Test Loss: 0.000171\n",
      "Epoch 9/40, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 10/40, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 11/40, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 12/40, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 13/40, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 14/40, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 15/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 16/40, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 17/40, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 18/40, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 19/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 20/40, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 21/40, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 22/40, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 23/40, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 24/40, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 25/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 26/40, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 27/40, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 28/40, Train Loss: 0.000188, Test Loss: 0.000168\n",
      "Epoch 29/40, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 30/40, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 31/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 32/40, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 33/40, Train Loss: 0.000184, Test Loss: 0.000167\n",
      "Epoch 34/40, Train Loss: 0.000185, Test Loss: 0.000167\n",
      "Epoch 35/40, Train Loss: 0.000182, Test Loss: 0.000168\n",
      "Epoch 36/40, Train Loss: 0.000181, Test Loss: 0.000166\n",
      "Epoch 37/40, Train Loss: 0.000180, Test Loss: 0.000165\n",
      "Epoch 38/40, Train Loss: 0.000178, Test Loss: 0.000164\n",
      "Epoch 39/40, Train Loss: 0.000171, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:37:07,131] Trial 152 finished with value: 0.0001654778370134262 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 232, 'layer_1_size': 146, 'layer_2_size': 196, 'dropout_rate': 0.14783762177173218, 'learning_rate': 0.0001597673993256306, 'batch_size': 256, 'epochs': 40}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40, Train Loss: 0.000174, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37, Train Loss: 0.000563, Test Loss: 0.000178\n",
      "Epoch 2/37, Train Loss: 0.000271, Test Loss: 0.000188\n",
      "Epoch 3/37, Train Loss: 0.000243, Test Loss: 0.000196\n",
      "Epoch 4/37, Train Loss: 0.000229, Test Loss: 0.000186\n",
      "Epoch 5/37, Train Loss: 0.000225, Test Loss: 0.000183\n",
      "Epoch 6/37, Train Loss: 0.000220, Test Loss: 0.000185\n",
      "Epoch 7/37, Train Loss: 0.000217, Test Loss: 0.000179\n",
      "Epoch 8/37, Train Loss: 0.000213, Test Loss: 0.000178\n",
      "Epoch 9/37, Train Loss: 0.000211, Test Loss: 0.000180\n",
      "Epoch 10/37, Train Loss: 0.000208, Test Loss: 0.000173\n",
      "Epoch 11/37, Train Loss: 0.000206, Test Loss: 0.000175\n",
      "Epoch 12/37, Train Loss: 0.000204, Test Loss: 0.000176\n",
      "Epoch 13/37, Train Loss: 0.000203, Test Loss: 0.000170\n",
      "Epoch 14/37, Train Loss: 0.000203, Test Loss: 0.000171\n",
      "Epoch 15/37, Train Loss: 0.000201, Test Loss: 0.000168\n",
      "Epoch 16/37, Train Loss: 0.000200, Test Loss: 0.000171\n",
      "Epoch 17/37, Train Loss: 0.000199, Test Loss: 0.000166\n",
      "Epoch 18/37, Train Loss: 0.000198, Test Loss: 0.000167\n",
      "Epoch 19/37, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 20/37, Train Loss: 0.000196, Test Loss: 0.000170\n",
      "Epoch 21/37, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 22/37, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 23/37, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 24/37, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 25/37, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 26/37, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 27/37, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 28/37, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 29/37, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 30/37, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 31/37, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 32/37, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 33/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 34/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 35/37, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 36/37, Train Loss: 0.000191, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:37:18,252] Trial 153 finished with value: 0.0001644980833178476 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 217, 'layer_1_size': 153, 'layer_2_size': 49, 'dropout_rate': 0.16095186246252288, 'learning_rate': 9.719011731573015e-05, 'batch_size': 256, 'epochs': 37}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/37, Train Loss: 0.000191, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Train Loss: 0.000600, Test Loss: 0.000177\n",
      "Epoch 2/40, Train Loss: 0.000269, Test Loss: 0.000171\n",
      "Epoch 3/40, Train Loss: 0.000237, Test Loss: 0.000184\n",
      "Epoch 4/40, Train Loss: 0.000224, Test Loss: 0.000177\n",
      "Epoch 5/40, Train Loss: 0.000216, Test Loss: 0.000182\n",
      "Epoch 6/40, Train Loss: 0.000212, Test Loss: 0.000183\n",
      "Epoch 7/40, Train Loss: 0.000210, Test Loss: 0.000178\n",
      "Epoch 8/40, Train Loss: 0.000208, Test Loss: 0.000171\n",
      "Epoch 9/40, Train Loss: 0.000207, Test Loss: 0.000170\n",
      "Epoch 10/40, Train Loss: 0.000204, Test Loss: 0.000171\n",
      "Epoch 11/40, Train Loss: 0.000204, Test Loss: 0.000173\n",
      "Epoch 12/40, Train Loss: 0.000203, Test Loss: 0.000169\n",
      "Epoch 13/40, Train Loss: 0.000200, Test Loss: 0.000168\n",
      "Epoch 14/40, Train Loss: 0.000200, Test Loss: 0.000166\n",
      "Epoch 15/40, Train Loss: 0.000199, Test Loss: 0.000171\n",
      "Epoch 16/40, Train Loss: 0.000198, Test Loss: 0.000169\n",
      "Epoch 17/40, Train Loss: 0.000198, Test Loss: 0.000167\n",
      "Epoch 18/40, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 19/40, Train Loss: 0.000196, Test Loss: 0.000165\n",
      "Epoch 20/40, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 21/40, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 22/40, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 23/40, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 24/40, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 25/40, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 26/40, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 27/40, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 28/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 29/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 30/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 31/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 32/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 33/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 34/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 35/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 36/40, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 37/40, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 38/40, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 39/40, Train Loss: 0.000189, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:37:33,610] Trial 154 finished with value: 0.00016557072687588045 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 208, 'layer_1_size': 174, 'layer_2_size': 209, 'dropout_rate': 0.17041850923857801, 'learning_rate': 0.0002294854816011317, 'batch_size': 256, 'epochs': 40}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40, Train Loss: 0.000189, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29, Train Loss: 0.002311, Test Loss: 0.000220\n",
      "Epoch 2/29, Train Loss: 0.000627, Test Loss: 0.000200\n",
      "Epoch 3/29, Train Loss: 0.000550, Test Loss: 0.000188\n",
      "Epoch 4/29, Train Loss: 0.000510, Test Loss: 0.000198\n",
      "Epoch 5/29, Train Loss: 0.000460, Test Loss: 0.000207\n",
      "Epoch 6/29, Train Loss: 0.000444, Test Loss: 0.000183\n",
      "Epoch 7/29, Train Loss: 0.000422, Test Loss: 0.000191\n",
      "Epoch 8/29, Train Loss: 0.000401, Test Loss: 0.000207\n",
      "Epoch 9/29, Train Loss: 0.000386, Test Loss: 0.000200\n",
      "Epoch 10/29, Train Loss: 0.000370, Test Loss: 0.000182\n",
      "Epoch 11/29, Train Loss: 0.000354, Test Loss: 0.000191\n",
      "Epoch 12/29, Train Loss: 0.000342, Test Loss: 0.000193\n",
      "Epoch 13/29, Train Loss: 0.000326, Test Loss: 0.000185\n",
      "Epoch 14/29, Train Loss: 0.000312, Test Loss: 0.000179\n",
      "Epoch 15/29, Train Loss: 0.000305, Test Loss: 0.000190\n",
      "Epoch 16/29, Train Loss: 0.000291, Test Loss: 0.000186\n",
      "Epoch 17/29, Train Loss: 0.000277, Test Loss: 0.000184\n",
      "Epoch 18/29, Train Loss: 0.000270, Test Loss: 0.000178\n",
      "Epoch 19/29, Train Loss: 0.000263, Test Loss: 0.000173\n",
      "Epoch 20/29, Train Loss: 0.000250, Test Loss: 0.000174\n",
      "Epoch 21/29, Train Loss: 0.000244, Test Loss: 0.000178\n",
      "Epoch 22/29, Train Loss: 0.000236, Test Loss: 0.000174\n",
      "Epoch 23/29, Train Loss: 0.000229, Test Loss: 0.000170\n",
      "Epoch 24/29, Train Loss: 0.000225, Test Loss: 0.000172\n",
      "Epoch 25/29, Train Loss: 0.000222, Test Loss: 0.000171\n",
      "Epoch 26/29, Train Loss: 0.000217, Test Loss: 0.000168\n",
      "Epoch 27/29, Train Loss: 0.000211, Test Loss: 0.000168\n",
      "Epoch 28/29, Train Loss: 0.000208, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:37:42,490] Trial 155 finished with value: 0.00016817808054545293 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 236, 'layer_1_size': 158, 'layer_2_size': 37, 'dropout_rate': 0.13627787407696712, 'learning_rate': 0.00016873547566069873, 'batch_size': 256, 'epochs': 29}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29, Train Loss: 0.000206, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38, Train Loss: 0.000597, Test Loss: 0.000200\n",
      "Epoch 2/38, Train Loss: 0.000256, Test Loss: 0.000179\n",
      "Epoch 3/38, Train Loss: 0.000220, Test Loss: 0.000175\n",
      "Epoch 4/38, Train Loss: 0.000207, Test Loss: 0.000173\n",
      "Epoch 5/38, Train Loss: 0.000202, Test Loss: 0.000172\n",
      "Epoch 6/38, Train Loss: 0.000199, Test Loss: 0.000168\n",
      "Epoch 7/38, Train Loss: 0.000197, Test Loss: 0.000172\n",
      "Epoch 8/38, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 9/38, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 10/38, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 11/38, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 12/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 13/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 14/38, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/38, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 16/38, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 17/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 18/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/38, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 21/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/38, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 23/38, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 24/38, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/38, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 26/38, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 27/38, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 28/38, Train Loss: 0.000189, Test Loss: 0.000163\n",
      "Epoch 29/38, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 30/38, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 31/38, Train Loss: 0.000189, Test Loss: 0.000163\n",
      "Epoch 32/38, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 33/38, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 34/38, Train Loss: 0.000187, Test Loss: 0.000163\n",
      "Epoch 35/38, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 36/38, Train Loss: 0.000187, Test Loss: 0.000163\n",
      "Epoch 37/38, Train Loss: 0.000189, Test Loss: 0.000163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:37:52,893] Trial 156 finished with value: 0.0001628944013528751 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 225, 'layer_1_size': 130, 'dropout_rate': 0.151564257615114, 'learning_rate': 0.000273734773795044, 'batch_size': 256, 'epochs': 38}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/38, Train Loss: 0.000185, Test Loss: 0.000163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37, Train Loss: 0.004223, Test Loss: 0.000420\n",
      "Epoch 2/37, Train Loss: 0.001600, Test Loss: 0.000309\n",
      "Epoch 3/37, Train Loss: 0.000861, Test Loss: 0.000267\n",
      "Epoch 4/37, Train Loss: 0.000577, Test Loss: 0.000239\n",
      "Epoch 5/37, Train Loss: 0.000434, Test Loss: 0.000220\n",
      "Epoch 6/37, Train Loss: 0.000346, Test Loss: 0.000207\n",
      "Epoch 7/37, Train Loss: 0.000301, Test Loss: 0.000197\n",
      "Epoch 8/37, Train Loss: 0.000269, Test Loss: 0.000191\n",
      "Epoch 9/37, Train Loss: 0.000252, Test Loss: 0.000187\n",
      "Epoch 10/37, Train Loss: 0.000237, Test Loss: 0.000182\n",
      "Epoch 11/37, Train Loss: 0.000232, Test Loss: 0.000180\n",
      "Epoch 12/37, Train Loss: 0.000220, Test Loss: 0.000178\n",
      "Epoch 13/37, Train Loss: 0.000215, Test Loss: 0.000176\n",
      "Epoch 14/37, Train Loss: 0.000210, Test Loss: 0.000175\n",
      "Epoch 15/37, Train Loss: 0.000207, Test Loss: 0.000174\n",
      "Epoch 16/37, Train Loss: 0.000204, Test Loss: 0.000173\n",
      "Epoch 17/37, Train Loss: 0.000202, Test Loss: 0.000172\n",
      "Epoch 18/37, Train Loss: 0.000201, Test Loss: 0.000171\n",
      "Epoch 19/37, Train Loss: 0.000198, Test Loss: 0.000171\n",
      "Epoch 20/37, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 21/37, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 22/37, Train Loss: 0.000196, Test Loss: 0.000169\n",
      "Epoch 23/37, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 24/37, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 25/37, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 26/37, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 27/37, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 28/37, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 29/37, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 30/37, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 31/37, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 32/37, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 33/37, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 34/37, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 35/37, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 36/37, Train Loss: 0.000191, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:38:01,711] Trial 157 finished with value: 0.00016593368086286056 and parameters: {'num_hidden_layers': 1, 'layer_0_size': 225, 'dropout_rate': 0.24024498442584974, 'learning_rate': 0.00011429317506131959, 'batch_size': 256, 'epochs': 37}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/37, Train Loss: 0.000191, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38, Train Loss: 0.000491, Test Loss: 0.000185\n",
      "Epoch 2/38, Train Loss: 0.000231, Test Loss: 0.000179\n",
      "Epoch 3/38, Train Loss: 0.000209, Test Loss: 0.000173\n",
      "Epoch 4/38, Train Loss: 0.000202, Test Loss: 0.000173\n",
      "Epoch 5/38, Train Loss: 0.000198, Test Loss: 0.000169\n",
      "Epoch 6/38, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 7/38, Train Loss: 0.000194, Test Loss: 0.000169\n",
      "Epoch 8/38, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 9/38, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 10/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 11/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/38, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 14/38, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 15/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/38, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 17/38, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 18/38, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 19/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/38, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 21/38, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 22/38, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 23/38, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 24/38, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 25/38, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 26/38, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 27/38, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 28/38, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 29/38, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 30/38, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 31/38, Train Loss: 0.000184, Test Loss: 0.000165\n",
      "Epoch 32/38, Train Loss: 0.000184, Test Loss: 0.000166\n",
      "Epoch 33/38, Train Loss: 0.000183, Test Loss: 0.000164\n",
      "Epoch 34/38, Train Loss: 0.000181, Test Loss: 0.000164\n",
      "Epoch 35/38, Train Loss: 0.000181, Test Loss: 0.000163\n",
      "Epoch 36/38, Train Loss: 0.000179, Test Loss: 0.000162\n",
      "Epoch 37/38, Train Loss: 0.000180, Test Loss: 0.000162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:38:12,290] Trial 158 finished with value: 0.0001644289963986657 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 237, 'layer_1_size': 140, 'dropout_rate': 0.1915104237598176, 'learning_rate': 0.0002909335367096033, 'batch_size': 256, 'epochs': 38}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/38, Train Loss: 0.000173, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Train Loss: 0.001669, Test Loss: 0.000227\n",
      "Epoch 2/40, Train Loss: 0.000577, Test Loss: 0.000210\n",
      "Epoch 3/40, Train Loss: 0.000416, Test Loss: 0.000207\n",
      "Epoch 4/40, Train Loss: 0.000332, Test Loss: 0.000232\n",
      "Epoch 5/40, Train Loss: 0.000290, Test Loss: 0.000214\n",
      "Epoch 6/40, Train Loss: 0.000271, Test Loss: 0.000237\n",
      "Epoch 7/40, Train Loss: 0.000258, Test Loss: 0.000208\n",
      "Epoch 8/40, Train Loss: 0.000251, Test Loss: 0.000206\n",
      "Epoch 9/40, Train Loss: 0.000242, Test Loss: 0.000200\n",
      "Epoch 10/40, Train Loss: 0.000236, Test Loss: 0.000200\n",
      "Epoch 11/40, Train Loss: 0.000233, Test Loss: 0.000196\n",
      "Epoch 12/40, Train Loss: 0.000230, Test Loss: 0.000195\n",
      "Epoch 13/40, Train Loss: 0.000227, Test Loss: 0.000182\n",
      "Epoch 14/40, Train Loss: 0.000224, Test Loss: 0.000188\n",
      "Epoch 15/40, Train Loss: 0.000222, Test Loss: 0.000185\n",
      "Epoch 16/40, Train Loss: 0.000219, Test Loss: 0.000183\n",
      "Epoch 17/40, Train Loss: 0.000219, Test Loss: 0.000184\n",
      "Epoch 18/40, Train Loss: 0.000216, Test Loss: 0.000176\n",
      "Epoch 19/40, Train Loss: 0.000214, Test Loss: 0.000184\n",
      "Epoch 20/40, Train Loss: 0.000210, Test Loss: 0.000181\n",
      "Epoch 21/40, Train Loss: 0.000209, Test Loss: 0.000177\n",
      "Epoch 22/40, Train Loss: 0.000208, Test Loss: 0.000169\n",
      "Epoch 23/40, Train Loss: 0.000207, Test Loss: 0.000177\n",
      "Epoch 24/40, Train Loss: 0.000208, Test Loss: 0.000169\n",
      "Epoch 25/40, Train Loss: 0.000204, Test Loss: 0.000170\n",
      "Epoch 26/40, Train Loss: 0.000204, Test Loss: 0.000174\n",
      "Epoch 27/40, Train Loss: 0.000203, Test Loss: 0.000169\n",
      "Epoch 28/40, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 29/40, Train Loss: 0.000199, Test Loss: 0.000171\n",
      "Epoch 30/40, Train Loss: 0.000199, Test Loss: 0.000174\n",
      "Epoch 31/40, Train Loss: 0.000199, Test Loss: 0.000169\n",
      "Epoch 32/40, Train Loss: 0.000197, Test Loss: 0.000171\n",
      "Epoch 33/40, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 34/40, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 35/40, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 36/40, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 37/40, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 38/40, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 39/40, Train Loss: 0.000196, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:38:21,779] Trial 159 finished with value: 0.00016814015402961822 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 104, 'layer_1_size': 120, 'dropout_rate': 0.1525271453921597, 'learning_rate': 0.00014948816373317722, 'batch_size': 256, 'epochs': 40}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40, Train Loss: 0.000192, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39, Train Loss: 0.001855, Test Loss: 0.000227\n",
      "Epoch 2/39, Train Loss: 0.000545, Test Loss: 0.000212\n",
      "Epoch 3/39, Train Loss: 0.000407, Test Loss: 0.000227\n",
      "Epoch 4/39, Train Loss: 0.000354, Test Loss: 0.000233\n",
      "Epoch 5/39, Train Loss: 0.000325, Test Loss: 0.000241\n",
      "Epoch 6/39, Train Loss: 0.000301, Test Loss: 0.000230\n",
      "Epoch 7/39, Train Loss: 0.000287, Test Loss: 0.000224\n",
      "Epoch 8/39, Train Loss: 0.000276, Test Loss: 0.000215\n",
      "Epoch 9/39, Train Loss: 0.000268, Test Loss: 0.000213\n",
      "Epoch 10/39, Train Loss: 0.000264, Test Loss: 0.000209\n",
      "Epoch 11/39, Train Loss: 0.000257, Test Loss: 0.000201\n",
      "Epoch 12/39, Train Loss: 0.000251, Test Loss: 0.000197\n",
      "Epoch 13/39, Train Loss: 0.000247, Test Loss: 0.000187\n",
      "Epoch 14/39, Train Loss: 0.000241, Test Loss: 0.000188\n",
      "Epoch 15/39, Train Loss: 0.000237, Test Loss: 0.000186\n",
      "Epoch 16/39, Train Loss: 0.000236, Test Loss: 0.000180\n",
      "Epoch 17/39, Train Loss: 0.000232, Test Loss: 0.000182\n",
      "Epoch 18/39, Train Loss: 0.000229, Test Loss: 0.000183\n",
      "Epoch 19/39, Train Loss: 0.000226, Test Loss: 0.000179\n",
      "Epoch 20/39, Train Loss: 0.000223, Test Loss: 0.000178\n",
      "Epoch 21/39, Train Loss: 0.000218, Test Loss: 0.000173\n",
      "Epoch 22/39, Train Loss: 0.000219, Test Loss: 0.000175\n",
      "Epoch 23/39, Train Loss: 0.000216, Test Loss: 0.000173\n",
      "Epoch 24/39, Train Loss: 0.000214, Test Loss: 0.000173\n",
      "Epoch 25/39, Train Loss: 0.000211, Test Loss: 0.000172\n",
      "Epoch 26/39, Train Loss: 0.000210, Test Loss: 0.000172\n",
      "Epoch 27/39, Train Loss: 0.000207, Test Loss: 0.000171\n",
      "Epoch 28/39, Train Loss: 0.000208, Test Loss: 0.000171\n",
      "Epoch 29/39, Train Loss: 0.000205, Test Loss: 0.000170\n",
      "Epoch 30/39, Train Loss: 0.000203, Test Loss: 0.000170\n",
      "Epoch 31/39, Train Loss: 0.000202, Test Loss: 0.000168\n",
      "Epoch 32/39, Train Loss: 0.000201, Test Loss: 0.000169\n",
      "Epoch 33/39, Train Loss: 0.000200, Test Loss: 0.000170\n",
      "Epoch 34/39, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 35/39, Train Loss: 0.000201, Test Loss: 0.000168\n",
      "Epoch 36/39, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 37/39, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 38/39, Train Loss: 0.000196, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:38:31,777] Trial 160 finished with value: 0.00016749360422123102 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 67, 'layer_1_size': 127, 'layer_2_size': 45, 'dropout_rate': 0.21039796070392278, 'learning_rate': 8.595838640215914e-05, 'batch_size': 256, 'epochs': 39}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/39, Train Loss: 0.000196, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38, Train Loss: 0.000273, Test Loss: 0.000169\n",
      "Epoch 2/38, Train Loss: 0.000221, Test Loss: 0.000170\n",
      "Epoch 3/38, Train Loss: 0.000209, Test Loss: 0.000174\n",
      "Epoch 4/38, Train Loss: 0.000206, Test Loss: 0.000175\n",
      "Epoch 5/38, Train Loss: 0.000202, Test Loss: 0.000170\n",
      "Epoch 6/38, Train Loss: 0.000199, Test Loss: 0.000172\n",
      "Epoch 7/38, Train Loss: 0.000199, Test Loss: 0.000169\n",
      "Epoch 8/38, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 9/38, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 10/38, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 11/38, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 12/38, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 13/38, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 14/38, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 15/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 16/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/38, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 18/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 20/38, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 21/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/38, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 23/38, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 24/38, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 25/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 26/38, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 27/38, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 28/38, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 29/38, Train Loss: 0.000187, Test Loss: 0.000168\n",
      "Epoch 30/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 31/38, Train Loss: 0.000188, Test Loss: 0.000163\n",
      "Epoch 32/38, Train Loss: 0.000188, Test Loss: 0.000168\n",
      "Epoch 33/38, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 34/38, Train Loss: 0.000179, Test Loss: 0.000168\n",
      "Epoch 35/38, Train Loss: 0.000187, Test Loss: 0.000169\n",
      "Epoch 36/38, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 37/38, Train Loss: 0.000192, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:38:48,709] Trial 161 finished with value: 0.00016644919795057392 and parameters: {'num_hidden_layers': 6, 'layer_0_size': 222, 'layer_1_size': 166, 'layer_2_size': 32, 'layer_3_size': 176, 'layer_4_size': 102, 'layer_5_size': 129, 'dropout_rate': 0.1434413348465674, 'learning_rate': 0.00021098859403948766, 'batch_size': 256, 'epochs': 38}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/38, Train Loss: 0.000189, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39, Train Loss: 0.000323, Test Loss: 0.000172\n",
      "Epoch 2/39, Train Loss: 0.000221, Test Loss: 0.000169\n",
      "Epoch 3/39, Train Loss: 0.000205, Test Loss: 0.000169\n",
      "Epoch 4/39, Train Loss: 0.000200, Test Loss: 0.000168\n",
      "Epoch 5/39, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 6/39, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 7/39, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 8/39, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 9/39, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 10/39, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 11/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 13/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 15/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 18/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 23/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 24/39, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 25/39, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 26/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 27/39, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 28/39, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 29/39, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 30/39, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 31/39, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 32/39, Train Loss: 0.000188, Test Loss: 0.000168\n",
      "Epoch 33/39, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 34/39, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 35/39, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 36/39, Train Loss: 0.000185, Test Loss: 0.000167\n",
      "Epoch 37/39, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 38/39, Train Loss: 0.000184, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:39:01,725] Trial 162 finished with value: 0.00016620189343220478 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 228, 'layer_1_size': 132, 'layer_2_size': 137, 'dropout_rate': 0.17118729469064956, 'learning_rate': 0.0001834446410582402, 'batch_size': 256, 'epochs': 39}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/39, Train Loss: 0.000179, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36, Train Loss: 0.001209, Test Loss: 0.000247\n",
      "Epoch 2/36, Train Loss: 0.000334, Test Loss: 0.000198\n",
      "Epoch 3/36, Train Loss: 0.000243, Test Loss: 0.000182\n",
      "Epoch 4/36, Train Loss: 0.000215, Test Loss: 0.000174\n",
      "Epoch 5/36, Train Loss: 0.000206, Test Loss: 0.000171\n",
      "Epoch 6/36, Train Loss: 0.000200, Test Loss: 0.000168\n",
      "Epoch 7/36, Train Loss: 0.000197, Test Loss: 0.000171\n",
      "Epoch 8/36, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 9/36, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 10/36, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 11/36, Train Loss: 0.000193, Test Loss: 0.000169\n",
      "Epoch 12/36, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 13/36, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 14/36, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 15/36, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 16/36, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 17/36, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 18/36, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 19/36, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 20/36, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 21/36, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 22/36, Train Loss: 0.000189, Test Loss: 0.000168\n",
      "Epoch 23/36, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 24/36, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 25/36, Train Loss: 0.000188, Test Loss: 0.000169\n",
      "Epoch 26/36, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 27/36, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 28/36, Train Loss: 0.000188, Test Loss: 0.000167\n",
      "Epoch 29/36, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 30/36, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 31/36, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 32/36, Train Loss: 0.000186, Test Loss: 0.000167\n",
      "Epoch 33/36, Train Loss: 0.000186, Test Loss: 0.000167\n",
      "Epoch 34/36, Train Loss: 0.000186, Test Loss: 0.000167\n",
      "Epoch 35/36, Train Loss: 0.000185, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:39:10,203] Trial 163 finished with value: 0.00016596005045885835 and parameters: {'num_hidden_layers': 1, 'layer_0_size': 216, 'dropout_rate': 0.1629874711960945, 'learning_rate': 0.00025919627164477325, 'batch_size': 128, 'epochs': 36}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/36, Train Loss: 0.000185, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19, Train Loss: 0.000211, Test Loss: 0.000168\n",
      "Epoch 2/19, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 3/19, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 4/19, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 5/19, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 6/19, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 7/19, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 9/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 10/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 11/19, Train Loss: 0.000191, Test Loss: 0.000169\n",
      "Epoch 12/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/19, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 15/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/19, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 17/19, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 18/19, Train Loss: 0.000189, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:39:27,985] Trial 164 finished with value: 0.00016467477334000221 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 204, 'layer_1_size': 148, 'layer_2_size': 41, 'dropout_rate': 0.13421534242978933, 'learning_rate': 0.00013714302384903524, 'batch_size': 32, 'epochs': 19}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/19, Train Loss: 0.000189, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.000575, Test Loss: 0.000210\n",
      "Epoch 2/30, Train Loss: 0.000264, Test Loss: 0.000207\n",
      "Epoch 3/30, Train Loss: 0.000234, Test Loss: 0.000187\n",
      "Epoch 4/30, Train Loss: 0.000217, Test Loss: 0.000175\n",
      "Epoch 5/30, Train Loss: 0.000207, Test Loss: 0.000173\n",
      "Epoch 6/30, Train Loss: 0.000201, Test Loss: 0.000170\n",
      "Epoch 7/30, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 8/30, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 9/30, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 10/30, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/30, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/30, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 13/30, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 14/30, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 15/30, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 16/30, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 17/30, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 18/30, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 19/30, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 20/30, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 21/30, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 22/30, Train Loss: 0.000184, Test Loss: 0.000165\n",
      "Epoch 23/30, Train Loss: 0.000186, Test Loss: 0.000167\n",
      "Epoch 24/30, Train Loss: 0.000185, Test Loss: 0.000166\n",
      "Epoch 25/30, Train Loss: 0.000180, Test Loss: 0.000166\n",
      "Epoch 26/30, Train Loss: 0.000180, Test Loss: 0.000166\n",
      "Epoch 27/30, Train Loss: 0.000180, Test Loss: 0.000165\n",
      "Epoch 28/30, Train Loss: 0.000177, Test Loss: 0.000165\n",
      "Epoch 29/30, Train Loss: 0.000176, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:39:49,042] Trial 165 finished with value: 0.0001657246181936913 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 195, 'layer_1_size': 108, 'dropout_rate': 0.15148009543106958, 'learning_rate': 0.00010706381102278196, 'batch_size': 32, 'epochs': 30}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.000174, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Train Loss: 0.000346, Test Loss: 0.000169\n",
      "Epoch 2/40, Train Loss: 0.000242, Test Loss: 0.000169\n",
      "Epoch 3/40, Train Loss: 0.000223, Test Loss: 0.000168\n",
      "Epoch 4/40, Train Loss: 0.000214, Test Loss: 0.000167\n",
      "Epoch 5/40, Train Loss: 0.000207, Test Loss: 0.000167\n",
      "Epoch 6/40, Train Loss: 0.000204, Test Loss: 0.000166\n",
      "Epoch 7/40, Train Loss: 0.000203, Test Loss: 0.000166\n",
      "Epoch 8/40, Train Loss: 0.000200, Test Loss: 0.000166\n",
      "Epoch 9/40, Train Loss: 0.000199, Test Loss: 0.000166\n",
      "Epoch 10/40, Train Loss: 0.000198, Test Loss: 0.000166\n",
      "Epoch 11/40, Train Loss: 0.000197, Test Loss: 0.000165\n",
      "Epoch 12/40, Train Loss: 0.000196, Test Loss: 0.000165\n",
      "Epoch 13/40, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 14/40, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 15/40, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 16/40, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 17/40, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 18/40, Train Loss: 0.000196, Test Loss: 0.000165\n",
      "Epoch 19/40, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 20/40, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 21/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/40, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 23/40, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/40, Train Loss: 0.000190, Test Loss: 0.000168\n",
      "Epoch 25/40, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 26/40, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 27/40, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 28/40, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 29/40, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 30/40, Train Loss: 0.000188, Test Loss: 0.000174\n",
      "Epoch 31/40, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 32/40, Train Loss: 0.000186, Test Loss: 0.000163\n",
      "Epoch 33/40, Train Loss: 0.000185, Test Loss: 0.000162\n",
      "Epoch 34/40, Train Loss: 0.000186, Test Loss: 0.000167\n",
      "Epoch 35/40, Train Loss: 0.000182, Test Loss: 0.000166\n",
      "Epoch 36/40, Train Loss: 0.000183, Test Loss: 0.000164\n",
      "Epoch 37/40, Train Loss: 0.000181, Test Loss: 0.000161\n",
      "Epoch 38/40, Train Loss: 0.000173, Test Loss: 0.000185\n",
      "Epoch 39/40, Train Loss: 0.000173, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:40:04,670] Trial 166 finished with value: 0.00016559256073378492 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 231, 'layer_1_size': 217, 'layer_2_size': 53, 'layer_3_size': 118, 'dropout_rate': 0.11018670593920998, 'learning_rate': 0.00020555287731417634, 'batch_size': 256, 'epochs': 40}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40, Train Loss: 0.000166, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26, Train Loss: 0.000659, Test Loss: 0.000244\n",
      "Epoch 2/26, Train Loss: 0.000300, Test Loss: 0.000176\n",
      "Epoch 3/26, Train Loss: 0.000248, Test Loss: 0.000178\n",
      "Epoch 4/26, Train Loss: 0.000217, Test Loss: 0.000170\n",
      "Epoch 5/26, Train Loss: 0.000206, Test Loss: 0.000167\n",
      "Epoch 6/26, Train Loss: 0.000198, Test Loss: 0.000166\n",
      "Epoch 7/26, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 8/26, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 9/26, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 10/26, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/26, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 15/26, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 16/26, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 17/26, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 18/26, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 19/26, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 20/26, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 21/26, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 22/26, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 23/26, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 24/26, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 25/26, Train Loss: 0.000187, Test Loss: 0.000163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:40:32,218] Trial 167 finished with value: 0.00016208706777327337 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 210, 'layer_1_size': 162, 'layer_2_size': 48, 'dropout_rate': 0.14284622858651028, 'learning_rate': 0.0001674454054061794, 'batch_size': 32, 'epochs': 26}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/26, Train Loss: 0.000186, Test Loss: 0.000162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26, Train Loss: 0.000277, Test Loss: 0.000169\n",
      "Epoch 2/26, Train Loss: 0.000212, Test Loss: 0.000168\n",
      "Epoch 3/26, Train Loss: 0.000202, Test Loss: 0.000170\n",
      "Epoch 4/26, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 5/26, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 6/26, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 7/26, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 8/26, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 9/26, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 10/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/26, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/26, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/26, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/26, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 17/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/26, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 21/26, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 22/26, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 23/26, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 24/26, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 25/26, Train Loss: 0.000188, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:40:45,203] Trial 168 finished with value: 0.00016634052829636681 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 210, 'layer_1_size': 155, 'layer_2_size': 236, 'dropout_rate': 0.17877985326693574, 'learning_rate': 0.00015236975270685268, 'batch_size': 128, 'epochs': 26}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/26, Train Loss: 0.000186, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 0.000217, Test Loss: 0.000170\n",
      "Epoch 2/25, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 3/25, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 4/25, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 5/25, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 6/25, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/25, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/25, Train Loss: 0.000192, Test Loss: 0.000168\n",
      "Epoch 9/25, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 10/25, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 12/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/25, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 15/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 17/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 18/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 19/25, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 20/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 21/25, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 22/25, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 23/25, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 24/25, Train Loss: 0.000188, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:41:10,258] Trial 169 finished with value: 0.00016466675797511426 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 164, 'layer_1_size': 181, 'layer_2_size': 48, 'dropout_rate': 0.2195625257498789, 'learning_rate': 0.00010682615226934513, 'batch_size': 32, 'epochs': 25}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Train Loss: 0.000188, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28, Train Loss: 0.000283, Test Loss: 0.000170\n",
      "Epoch 2/28, Train Loss: 0.000220, Test Loss: 0.000170\n",
      "Epoch 3/28, Train Loss: 0.000210, Test Loss: 0.000170\n",
      "Epoch 4/28, Train Loss: 0.000206, Test Loss: 0.000172\n",
      "Epoch 5/28, Train Loss: 0.000203, Test Loss: 0.000169\n",
      "Epoch 6/28, Train Loss: 0.000201, Test Loss: 0.000172\n",
      "Epoch 7/28, Train Loss: 0.000199, Test Loss: 0.000168\n",
      "Epoch 8/28, Train Loss: 0.000198, Test Loss: 0.000166\n",
      "Epoch 9/28, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 10/28, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 11/28, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 12/28, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 13/28, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 14/28, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 15/28, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 16/28, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 17/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 18/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 20/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 21/28, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 22/28, Train Loss: 0.000191, Test Loss: 0.000167\n",
      "Epoch 23/28, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 24/28, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 25/28, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 26/28, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 27/28, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:42:18,402] Trial 170 finished with value: 0.0001650633917070228 and parameters: {'num_hidden_layers': 7, 'layer_0_size': 79, 'layer_1_size': 164, 'layer_2_size': 39, 'layer_3_size': 247, 'layer_4_size': 221, 'layer_5_size': 78, 'layer_6_size': 191, 'dropout_rate': 0.1583669396372644, 'learning_rate': 6.895846818411452e-05, 'batch_size': 32, 'epochs': 28}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/28, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Train Loss: 0.000232, Test Loss: 0.000171\n",
      "Epoch 2/24, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 3/24, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 4/24, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 5/24, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 6/24, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 7/24, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 8/24, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/24, Train Loss: 0.000191, Test Loss: 0.000172\n",
      "Epoch 10/24, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 11/24, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 12/24, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 13/24, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 14/24, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 15/24, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 16/24, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 17/24, Train Loss: 0.000188, Test Loss: 0.000175\n",
      "Epoch 18/24, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 19/24, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 20/24, Train Loss: 0.000184, Test Loss: 0.000165\n",
      "Epoch 21/24, Train Loss: 0.000182, Test Loss: 0.000166\n",
      "Epoch 22/24, Train Loss: 0.000184, Test Loss: 0.000165\n",
      "Epoch 23/24, Train Loss: 0.000182, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:42:38,286] Trial 171 finished with value: 0.0001683160647275834 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 221, 'layer_1_size': 160, 'layer_2_size': 45, 'dropout_rate': 0.1410423694916025, 'learning_rate': 0.0001742721492612433, 'batch_size': 32, 'epochs': 24}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Train Loss: 0.000181, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26, Train Loss: 0.000277, Test Loss: 0.000170\n",
      "Epoch 2/26, Train Loss: 0.000208, Test Loss: 0.000170\n",
      "Epoch 3/26, Train Loss: 0.000199, Test Loss: 0.000170\n",
      "Epoch 4/26, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 5/26, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 6/26, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 7/26, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 8/26, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 9/26, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 10/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/26, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 12/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/26, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/26, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 15/26, Train Loss: 0.000191, Test Loss: 0.000168\n",
      "Epoch 16/26, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 17/26, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 18/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/26, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 20/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 21/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 23/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/26, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/26, Train Loss: 0.000191, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:43:32,959] Trial 172 finished with value: 0.00016459071968615864 and parameters: {'num_hidden_layers': 9, 'layer_0_size': 214, 'layer_1_size': 210, 'layer_2_size': 37, 'layer_3_size': 147, 'layer_4_size': 196, 'layer_5_size': 148, 'layer_6_size': 87, 'layer_7_size': 186, 'layer_8_size': 35, 'dropout_rate': 0.14710657003087496, 'learning_rate': 0.0002441457045314619, 'batch_size': 32, 'epochs': 26}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/26, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27, Train Loss: 0.000424, Test Loss: 0.000169\n",
      "Epoch 2/27, Train Loss: 0.000244, Test Loss: 0.000167\n",
      "Epoch 3/27, Train Loss: 0.000213, Test Loss: 0.000167\n",
      "Epoch 4/27, Train Loss: 0.000201, Test Loss: 0.000170\n",
      "Epoch 5/27, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 6/27, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 7/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/27, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 10/27, Train Loss: 0.000192, Test Loss: 0.000169\n",
      "Epoch 11/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/27, Train Loss: 0.000191, Test Loss: 0.000173\n",
      "Epoch 14/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/27, Train Loss: 0.000191, Test Loss: 0.000163\n",
      "Epoch 18/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/27, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 20/27, Train Loss: 0.000190, Test Loss: 0.000163\n",
      "Epoch 21/27, Train Loss: 0.000189, Test Loss: 0.000161\n",
      "Epoch 22/27, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 23/27, Train Loss: 0.000190, Test Loss: 0.000163\n",
      "Epoch 24/27, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 25/27, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 26/27, Train Loss: 0.000188, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:43:57,985] Trial 173 finished with value: 0.0001646265371112848 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 201, 'layer_1_size': 151, 'layer_2_size': 56, 'dropout_rate': 0.12927163829712926, 'learning_rate': 0.00033208889872930785, 'batch_size': 32, 'epochs': 27}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/27, Train Loss: 0.000186, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 0.000567, Test Loss: 0.000181\n",
      "Epoch 2/25, Train Loss: 0.000313, Test Loss: 0.000185\n",
      "Epoch 3/25, Train Loss: 0.000254, Test Loss: 0.000171\n",
      "Epoch 4/25, Train Loss: 0.000227, Test Loss: 0.000168\n",
      "Epoch 5/25, Train Loss: 0.000210, Test Loss: 0.000169\n",
      "Epoch 6/25, Train Loss: 0.000202, Test Loss: 0.000167\n",
      "Epoch 7/25, Train Loss: 0.000198, Test Loss: 0.000167\n",
      "Epoch 8/25, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 9/25, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 10/25, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 11/25, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 12/25, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/25, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 14/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/25, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 18/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 20/25, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 21/25, Train Loss: 0.000190, Test Loss: 0.000163\n",
      "Epoch 22/25, Train Loss: 0.000190, Test Loss: 0.000163\n",
      "Epoch 23/25, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 24/25, Train Loss: 0.000188, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:44:16,281] Trial 174 finished with value: 0.0001628367912666539 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 208, 'layer_1_size': 143, 'layer_2_size': 32, 'dropout_rate': 0.1402025521088287, 'learning_rate': 0.0001313795257995276, 'batch_size': 32, 'epochs': 25}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Train Loss: 0.000188, Test Loss: 0.000163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 0.000276, Test Loss: 0.000170\n",
      "Epoch 2/25, Train Loss: 0.000200, Test Loss: 0.000169\n",
      "Epoch 3/25, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 4/25, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 5/25, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 6/25, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 7/25, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/25, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/25, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/25, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 12/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/25, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 14/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 15/25, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 17/25, Train Loss: 0.000190, Test Loss: 0.000168\n",
      "Epoch 18/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 19/25, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 20/25, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 21/25, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 22/25, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 23/25, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 24/25, Train Loss: 0.000186, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:44:35,158] Trial 175 finished with value: 0.00016506333485076833 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 210, 'layer_1_size': 144, 'layer_2_size': 32, 'dropout_rate': 0.1995601104412718, 'learning_rate': 0.0001260104170182575, 'batch_size': 32, 'epochs': 25}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Train Loss: 0.000185, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37, Train Loss: 0.000530, Test Loss: 0.000222\n",
      "Epoch 2/37, Train Loss: 0.000303, Test Loss: 0.000185\n",
      "Epoch 3/37, Train Loss: 0.000256, Test Loss: 0.000179\n",
      "Epoch 4/37, Train Loss: 0.000231, Test Loss: 0.000170\n",
      "Epoch 5/37, Train Loss: 0.000215, Test Loss: 0.000168\n",
      "Epoch 6/37, Train Loss: 0.000205, Test Loss: 0.000169\n",
      "Epoch 7/37, Train Loss: 0.000200, Test Loss: 0.000168\n",
      "Epoch 8/37, Train Loss: 0.000196, Test Loss: 0.000166\n",
      "Epoch 9/37, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 10/37, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 11/37, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/37, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/37, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 14/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/37, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/37, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 18/37, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 19/37, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 20/37, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 21/37, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 22/37, Train Loss: 0.000186, Test Loss: 0.000168\n",
      "Epoch 23/37, Train Loss: 0.000187, Test Loss: 0.000168\n",
      "Epoch 24/37, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 25/37, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 26/37, Train Loss: 0.000185, Test Loss: 0.000165\n",
      "Epoch 27/37, Train Loss: 0.000185, Test Loss: 0.000166\n",
      "Epoch 28/37, Train Loss: 0.000181, Test Loss: 0.000166\n",
      "Epoch 29/37, Train Loss: 0.000183, Test Loss: 0.000167\n",
      "Epoch 30/37, Train Loss: 0.000180, Test Loss: 0.000166\n",
      "Epoch 31/37, Train Loss: 0.000172, Test Loss: 0.000178\n",
      "Epoch 32/37, Train Loss: 0.000175, Test Loss: 0.000168\n",
      "Epoch 33/37, Train Loss: 0.000172, Test Loss: 0.000168\n",
      "Epoch 34/37, Train Loss: 0.000168, Test Loss: 0.000165\n",
      "Epoch 35/37, Train Loss: 0.000168, Test Loss: 0.000166\n",
      "Epoch 36/37, Train Loss: 0.000162, Test Loss: 0.000171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:44:52,762] Trial 176 finished with value: 0.00017383564474746362 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 145, 'layer_1_size': 229, 'layer_2_size': 42, 'dropout_rate': 0.1656574469546903, 'learning_rate': 0.00015968919827423318, 'batch_size': 64, 'epochs': 37}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/37, Train Loss: 0.000148, Test Loss: 0.000174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27, Train Loss: 0.000251, Test Loss: 0.000168\n",
      "Epoch 2/27, Train Loss: 0.000205, Test Loss: 0.000168\n",
      "Epoch 3/27, Train Loss: 0.000197, Test Loss: 0.000169\n",
      "Epoch 4/27, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 5/27, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 6/27, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 8/27, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/27, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/27, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 12/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/27, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/27, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 16/27, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 17/27, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 18/27, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 19/27, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 20/27, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 21/27, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 22/27, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 23/27, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 24/27, Train Loss: 0.000366, Test Loss: 0.000163\n",
      "Epoch 25/27, Train Loss: 0.000187, Test Loss: 0.000167\n",
      "Epoch 26/27, Train Loss: 0.000188, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:45:13,356] Trial 177 finished with value: 0.0001655068655428559 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 207, 'layer_1_size': 157, 'layer_2_size': 36, 'dropout_rate': 0.13478708996967995, 'learning_rate': 0.00012824608041235952, 'batch_size': 32, 'epochs': 27}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/27, Train Loss: 0.000184, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23, Train Loss: 0.003210, Test Loss: 0.000299\n",
      "Epoch 2/23, Train Loss: 0.000843, Test Loss: 0.000230\n",
      "Epoch 3/23, Train Loss: 0.000576, Test Loss: 0.000197\n",
      "Epoch 4/23, Train Loss: 0.000427, Test Loss: 0.000187\n",
      "Epoch 5/23, Train Loss: 0.000335, Test Loss: 0.000197\n",
      "Epoch 6/23, Train Loss: 0.000291, Test Loss: 0.000199\n",
      "Epoch 7/23, Train Loss: 0.000269, Test Loss: 0.000206\n",
      "Epoch 8/23, Train Loss: 0.000256, Test Loss: 0.000201\n",
      "Epoch 9/23, Train Loss: 0.000246, Test Loss: 0.000194\n",
      "Epoch 10/23, Train Loss: 0.000239, Test Loss: 0.000195\n",
      "Epoch 11/23, Train Loss: 0.000236, Test Loss: 0.000196\n",
      "Epoch 12/23, Train Loss: 0.000232, Test Loss: 0.000197\n",
      "Epoch 13/23, Train Loss: 0.000227, Test Loss: 0.000191\n",
      "Epoch 14/23, Train Loss: 0.000224, Test Loss: 0.000191\n",
      "Epoch 15/23, Train Loss: 0.000223, Test Loss: 0.000179\n",
      "Epoch 16/23, Train Loss: 0.000222, Test Loss: 0.000182\n",
      "Epoch 17/23, Train Loss: 0.000220, Test Loss: 0.000184\n",
      "Epoch 18/23, Train Loss: 0.000216, Test Loss: 0.000178\n",
      "Epoch 19/23, Train Loss: 0.000214, Test Loss: 0.000176\n",
      "Epoch 20/23, Train Loss: 0.000214, Test Loss: 0.000174\n",
      "Epoch 21/23, Train Loss: 0.000212, Test Loss: 0.000175\n",
      "Epoch 22/23, Train Loss: 0.000209, Test Loss: 0.000176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:45:19,669] Trial 178 finished with value: 0.00017140544232754638 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 225, 'layer_1_size': 139, 'dropout_rate': 0.2279927552608139, 'learning_rate': 8.993518304497909e-05, 'batch_size': 256, 'epochs': 23}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/23, Train Loss: 0.000209, Test Loss: 0.000171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 0.000829, Test Loss: 0.000178\n",
      "Epoch 2/25, Train Loss: 0.000351, Test Loss: 0.000201\n",
      "Epoch 3/25, Train Loss: 0.000315, Test Loss: 0.000197\n",
      "Epoch 4/25, Train Loss: 0.000292, Test Loss: 0.000191\n",
      "Epoch 5/25, Train Loss: 0.000282, Test Loss: 0.000183\n",
      "Epoch 6/25, Train Loss: 0.000268, Test Loss: 0.000193\n",
      "Epoch 7/25, Train Loss: 0.000257, Test Loss: 0.000182\n",
      "Epoch 8/25, Train Loss: 0.000246, Test Loss: 0.000177\n",
      "Epoch 9/25, Train Loss: 0.000235, Test Loss: 0.000177\n",
      "Epoch 10/25, Train Loss: 0.000226, Test Loss: 0.000169\n",
      "Epoch 11/25, Train Loss: 0.000225, Test Loss: 0.000168\n",
      "Epoch 12/25, Train Loss: 0.000216, Test Loss: 0.000167\n",
      "Epoch 13/25, Train Loss: 0.000212, Test Loss: 0.000168\n",
      "Epoch 14/25, Train Loss: 0.000208, Test Loss: 0.000170\n",
      "Epoch 15/25, Train Loss: 0.000205, Test Loss: 0.000170\n",
      "Epoch 16/25, Train Loss: 0.000202, Test Loss: 0.000167\n",
      "Epoch 17/25, Train Loss: 0.000199, Test Loss: 0.000167\n",
      "Epoch 18/25, Train Loss: 0.000199, Test Loss: 0.000166\n",
      "Epoch 19/25, Train Loss: 0.000198, Test Loss: 0.000166\n",
      "Epoch 20/25, Train Loss: 0.000195, Test Loss: 0.000164\n",
      "Epoch 21/25, Train Loss: 0.000193, Test Loss: 0.000164\n",
      "Epoch 22/25, Train Loss: 0.000199, Test Loss: 0.000165\n",
      "Epoch 23/25, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 24/25, Train Loss: 0.000191, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:45:28,690] Trial 179 finished with value: 0.0001660318281621233 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 198, 'layer_1_size': 170, 'layer_2_size': 50, 'dropout_rate': 0.11453228548324723, 'learning_rate': 0.00018639922500279164, 'batch_size': 128, 'epochs': 25}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Train Loss: 0.000189, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39, Train Loss: 0.000238, Test Loss: 0.000170\n",
      "Epoch 2/39, Train Loss: 0.000198, Test Loss: 0.000167\n",
      "Epoch 3/39, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 4/39, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 5/39, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 6/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 7/39, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 8/39, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/39, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 10/39, Train Loss: 0.000192, Test Loss: 0.000164\n",
      "Epoch 11/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 12/39, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/39, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 14/39, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 15/39, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 16/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 17/39, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 18/39, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 19/39, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 20/39, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 21/39, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 22/39, Train Loss: 0.000185, Test Loss: 0.000164\n",
      "Epoch 23/39, Train Loss: 0.000187, Test Loss: 0.000163\n",
      "Epoch 24/39, Train Loss: 0.000186, Test Loss: 0.000163\n",
      "Epoch 25/39, Train Loss: 0.000181, Test Loss: 0.000160\n",
      "Epoch 26/39, Train Loss: 0.000184, Test Loss: 0.000163\n",
      "Epoch 27/39, Train Loss: 0.000178, Test Loss: 0.000161\n",
      "Epoch 28/39, Train Loss: 0.000177, Test Loss: 0.000164\n",
      "Epoch 29/39, Train Loss: 0.000178, Test Loss: 0.000163\n",
      "Epoch 30/39, Train Loss: 0.000180, Test Loss: 0.000197\n",
      "Epoch 31/39, Train Loss: 0.000181, Test Loss: 0.000163\n",
      "Epoch 32/39, Train Loss: 0.000170, Test Loss: 0.000162\n",
      "Epoch 33/39, Train Loss: 0.000172, Test Loss: 0.000163\n",
      "Epoch 34/39, Train Loss: 0.000170, Test Loss: 0.000170\n",
      "Epoch 35/39, Train Loss: 0.000158, Test Loss: 0.000163\n",
      "Epoch 36/39, Train Loss: 0.000158, Test Loss: 0.000164\n",
      "Epoch 37/39, Train Loss: 0.000153, Test Loss: 0.000164\n",
      "Epoch 38/39, Train Loss: 0.000148, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:45:56,909] Trial 180 finished with value: 0.0001645958649452305 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 135, 'layer_1_size': 162, 'layer_2_size': 111, 'dropout_rate': 0.15547507277161232, 'learning_rate': 0.00014770390465010958, 'batch_size': 32, 'epochs': 39}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/39, Train Loss: 0.000159, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26, Train Loss: 0.000327, Test Loss: 0.000178\n",
      "Epoch 2/26, Train Loss: 0.000228, Test Loss: 0.000170\n",
      "Epoch 3/26, Train Loss: 0.000212, Test Loss: 0.000166\n",
      "Epoch 4/26, Train Loss: 0.000203, Test Loss: 0.000166\n",
      "Epoch 5/26, Train Loss: 0.000199, Test Loss: 0.000166\n",
      "Epoch 6/26, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 7/26, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 8/26, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/26, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/26, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/26, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/26, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/26, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 14/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/26, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/26, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 17/26, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 18/26, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 19/26, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 20/26, Train Loss: 0.000185, Test Loss: 0.000166\n",
      "Epoch 21/26, Train Loss: 0.000187, Test Loss: 0.000164\n",
      "Epoch 22/26, Train Loss: 0.000190, Test Loss: 0.000163\n",
      "Epoch 23/26, Train Loss: 0.000186, Test Loss: 0.000165\n",
      "Epoch 24/26, Train Loss: 0.000182, Test Loss: 0.000167\n",
      "Epoch 25/26, Train Loss: 0.000176, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:46:28,343] Trial 181 finished with value: 0.00016601174065598452 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 219, 'layer_1_size': 153, 'layer_2_size': 130, 'layer_3_size': 93, 'dropout_rate': 0.14355689113280654, 'learning_rate': 0.00021682159819014837, 'batch_size': 32, 'epochs': 26}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/26, Train Loss: 0.000179, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32, Train Loss: 0.000429, Test Loss: 0.000172\n",
      "Epoch 2/32, Train Loss: 0.000232, Test Loss: 0.000180\n",
      "Epoch 3/32, Train Loss: 0.000216, Test Loss: 0.000175\n",
      "Epoch 4/32, Train Loss: 0.000208, Test Loss: 0.000166\n",
      "Epoch 5/32, Train Loss: 0.000201, Test Loss: 0.000166\n",
      "Epoch 6/32, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 7/32, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 8/32, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 9/32, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/32, Train Loss: 0.000192, Test Loss: 0.000170\n",
      "Epoch 11/32, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 12/32, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 13/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/32, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 15/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/32, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 17/32, Train Loss: 0.000188, Test Loss: 0.000167\n",
      "Epoch 18/32, Train Loss: 0.000189, Test Loss: 0.000169\n",
      "Epoch 19/32, Train Loss: 0.000185, Test Loss: 0.000167\n",
      "Epoch 20/32, Train Loss: 0.000184, Test Loss: 0.000167\n",
      "Epoch 21/32, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 22/32, Train Loss: 0.000181, Test Loss: 0.000166\n",
      "Epoch 23/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 24/32, Train Loss: 0.000184, Test Loss: 0.000166\n",
      "Epoch 25/32, Train Loss: 0.000178, Test Loss: 0.000165\n",
      "Epoch 26/32, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 27/32, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 28/32, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 29/32, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 30/32, Train Loss: 0.000183, Test Loss: 0.000165\n",
      "Epoch 31/32, Train Loss: 0.000198, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:46:56,442] Trial 182 finished with value: 0.00016647067089769325 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 215, 'layer_1_size': 144, 'layer_2_size': 98, 'dropout_rate': 0.12790595010825978, 'learning_rate': 0.00026831417482755144, 'batch_size': 32, 'epochs': 32}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/32, Train Loss: 0.000188, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7, Train Loss: 0.000641, Test Loss: 0.000180\n",
      "Epoch 2/7, Train Loss: 0.000330, Test Loss: 0.000174\n",
      "Epoch 3/7, Train Loss: 0.000259, Test Loss: 0.000167\n",
      "Epoch 4/7, Train Loss: 0.000226, Test Loss: 0.000170\n",
      "Epoch 5/7, Train Loss: 0.000210, Test Loss: 0.000167\n",
      "Epoch 6/7, Train Loss: 0.000201, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:47:01,846] Trial 183 finished with value: 0.00016783678857413794 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 203, 'layer_1_size': 129, 'layer_2_size': 32, 'dropout_rate': 0.14058652477084949, 'learning_rate': 0.0001788846689003355, 'batch_size': 32, 'epochs': 7}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7, Train Loss: 0.000195, Test Loss: 0.000168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Train Loss: 0.000385, Test Loss: 0.000207\n",
      "Epoch 2/24, Train Loss: 0.000259, Test Loss: 0.000179\n",
      "Epoch 3/24, Train Loss: 0.000230, Test Loss: 0.000179\n",
      "Epoch 4/24, Train Loss: 0.000217, Test Loss: 0.000166\n",
      "Epoch 5/24, Train Loss: 0.000208, Test Loss: 0.000180\n",
      "Epoch 6/24, Train Loss: 0.000203, Test Loss: 0.000167\n",
      "Epoch 7/24, Train Loss: 0.000199, Test Loss: 0.000165\n",
      "Epoch 8/24, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 9/24, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 10/24, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 11/24, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/24, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/24, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 14/24, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 15/24, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 16/24, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 17/24, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 18/24, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 19/24, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 20/24, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 21/24, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 22/24, Train Loss: 0.000187, Test Loss: 0.000166\n",
      "Epoch 23/24, Train Loss: 0.000186, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:47:20,876] Trial 184 finished with value: 0.000166284606211225 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 221, 'layer_1_size': 148, 'layer_2_size': 46, 'dropout_rate': 0.14495312709846178, 'learning_rate': 0.00012031572319442613, 'batch_size': 32, 'epochs': 24}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Train Loss: 0.000186, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38, Train Loss: 0.000523, Test Loss: 0.000171\n",
      "Epoch 2/38, Train Loss: 0.000240, Test Loss: 0.000170\n",
      "Epoch 3/38, Train Loss: 0.000221, Test Loss: 0.000170\n",
      "Epoch 4/38, Train Loss: 0.000209, Test Loss: 0.000169\n",
      "Epoch 5/38, Train Loss: 0.000202, Test Loss: 0.000169\n",
      "Epoch 6/38, Train Loss: 0.000199, Test Loss: 0.000167\n",
      "Epoch 7/38, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 8/38, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 9/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 10/38, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 11/38, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/38, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/38, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 15/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/38, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 17/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/38, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 19/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 20/38, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 21/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 22/38, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 23/38, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 24/38, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 25/38, Train Loss: 0.000190, Test Loss: 0.000169\n",
      "Epoch 26/38, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 27/38, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 28/38, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 29/38, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 30/38, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 31/38, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 32/38, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 33/38, Train Loss: 0.000188, Test Loss: 0.000168\n",
      "Epoch 34/38, Train Loss: 0.000187, Test Loss: 0.000167\n",
      "Epoch 35/38, Train Loss: 0.000187, Test Loss: 0.000167\n",
      "Epoch 36/38, Train Loss: 0.000182, Test Loss: 0.000166\n",
      "Epoch 37/38, Train Loss: 0.000183, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:47:50,063] Trial 185 finished with value: 0.00016582033345919684 and parameters: {'num_hidden_layers': 4, 'layer_0_size': 211, 'layer_1_size': 37, 'layer_2_size': 40, 'layer_3_size': 135, 'dropout_rate': 0.15137188194253384, 'learning_rate': 0.00021625985605058893, 'batch_size': 32, 'epochs': 38}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/38, Train Loss: 0.000189, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36, Train Loss: 0.000381, Test Loss: 0.000172\n",
      "Epoch 2/36, Train Loss: 0.000235, Test Loss: 0.000169\n",
      "Epoch 3/36, Train Loss: 0.000218, Test Loss: 0.000168\n",
      "Epoch 4/36, Train Loss: 0.000213, Test Loss: 0.000168\n",
      "Epoch 5/36, Train Loss: 0.000209, Test Loss: 0.000166\n",
      "Epoch 6/36, Train Loss: 0.000205, Test Loss: 0.000166\n",
      "Epoch 7/36, Train Loss: 0.000204, Test Loss: 0.000166\n",
      "Epoch 8/36, Train Loss: 0.000201, Test Loss: 0.000171\n",
      "Epoch 9/36, Train Loss: 0.000199, Test Loss: 0.000165\n",
      "Epoch 10/36, Train Loss: 0.000197, Test Loss: 0.000165\n",
      "Epoch 11/36, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 12/36, Train Loss: 0.000196, Test Loss: 0.000165\n",
      "Epoch 13/36, Train Loss: 0.000195, Test Loss: 0.000165\n",
      "Epoch 14/36, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 15/36, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 16/36, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 17/36, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 18/36, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/36, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 20/36, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 21/36, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 22/36, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 23/36, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 24/36, Train Loss: 0.000189, Test Loss: 0.000167\n",
      "Epoch 25/36, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 26/36, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 27/36, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 28/36, Train Loss: 0.000186, Test Loss: 0.000166\n",
      "Epoch 29/36, Train Loss: 0.000184, Test Loss: 0.000166\n",
      "Epoch 30/36, Train Loss: 0.000180, Test Loss: 0.000172\n",
      "Epoch 31/36, Train Loss: 0.000183, Test Loss: 0.000167\n",
      "Epoch 32/36, Train Loss: 0.000179, Test Loss: 0.000167\n",
      "Epoch 33/36, Train Loss: 0.000172, Test Loss: 0.000167\n",
      "Epoch 34/36, Train Loss: 0.000160, Test Loss: 0.000166\n",
      "Epoch 35/36, Train Loss: 0.000160, Test Loss: 0.000170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:48:13,617] Trial 186 finished with value: 0.0001692523411942338 and parameters: {'num_hidden_layers': 5, 'layer_0_size': 217, 'layer_1_size': 77, 'layer_2_size': 161, 'layer_3_size': 61, 'layer_4_size': 150, 'dropout_rate': 0.12412218421115676, 'learning_rate': 0.00015753431189311715, 'batch_size': 64, 'epochs': 36}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/36, Train Loss: 0.000147, Test Loss: 0.000169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21, Train Loss: 0.000419, Test Loss: 0.000171\n",
      "Epoch 2/21, Train Loss: 0.000209, Test Loss: 0.000168\n",
      "Epoch 3/21, Train Loss: 0.000197, Test Loss: 0.000166\n",
      "Epoch 4/21, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 5/21, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 6/21, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 7/21, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 8/21, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/21, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 10/21, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 11/21, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 12/21, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/21, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 14/21, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 15/21, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 16/21, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 17/21, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 18/21, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 19/21, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 20/21, Train Loss: 0.000193, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:48:29,799] Trial 187 finished with value: 0.0001630119671799988 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 227, 'layer_1_size': 246, 'dropout_rate': 0.18428652967360235, 'learning_rate': 0.00010671020774665292, 'batch_size': 32, 'epochs': 21}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/21, Train Loss: 0.000186, Test Loss: 0.000163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22, Train Loss: 0.000492, Test Loss: 0.000174\n",
      "Epoch 2/22, Train Loss: 0.000214, Test Loss: 0.000168\n",
      "Epoch 3/22, Train Loss: 0.000199, Test Loss: 0.000167\n",
      "Epoch 4/22, Train Loss: 0.000195, Test Loss: 0.000169\n",
      "Epoch 5/22, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 6/22, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/22, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 8/22, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/22, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 10/22, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 11/22, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 12/22, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/22, Train Loss: 0.000190, Test Loss: 0.000168\n",
      "Epoch 14/22, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 15/22, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 16/22, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 17/22, Train Loss: 0.000189, Test Loss: 0.000165\n",
      "Epoch 18/22, Train Loss: 0.000188, Test Loss: 0.000166\n",
      "Epoch 19/22, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 20/22, Train Loss: 0.000188, Test Loss: 0.000167\n",
      "Epoch 21/22, Train Loss: 0.000187, Test Loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:49:03,544] Trial 188 finished with value: 0.00016511133036044244 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 229, 'layer_1_size': 248, 'dropout_rate': 0.18575817933799446, 'learning_rate': 0.00010538116628392374, 'batch_size': 32, 'epochs': 22}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/22, Train Loss: 0.000186, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14, Train Loss: 0.001720, Test Loss: 0.000363\n",
      "Epoch 2/14, Train Loss: 0.001454, Test Loss: 0.000301\n",
      "Epoch 3/14, Train Loss: 0.001289, Test Loss: 0.000267\n",
      "Epoch 4/14, Train Loss: 0.001127, Test Loss: 0.000246\n",
      "Epoch 5/14, Train Loss: 0.001017, Test Loss: 0.000238\n",
      "Epoch 6/14, Train Loss: 0.000918, Test Loss: 0.000230\n",
      "Epoch 7/14, Train Loss: 0.000840, Test Loss: 0.000225\n",
      "Epoch 8/14, Train Loss: 0.000778, Test Loss: 0.000219\n",
      "Epoch 9/14, Train Loss: 0.000728, Test Loss: 0.000214\n",
      "Epoch 10/14, Train Loss: 0.000671, Test Loss: 0.000213\n",
      "Epoch 11/14, Train Loss: 0.000625, Test Loss: 0.000213\n",
      "Epoch 12/14, Train Loss: 0.000595, Test Loss: 0.000209\n",
      "Epoch 13/14, Train Loss: 0.000565, Test Loss: 0.000206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:49:10,321] Trial 189 finished with value: 0.00020431052079431772 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 235, 'layer_1_size': 241, 'dropout_rate': 0.20417639451513733, 'learning_rate': 3.931751168990131e-06, 'batch_size': 256, 'epochs': 14}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/14, Train Loss: 0.000541, Test Loss: 0.000204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29, Train Loss: 0.000780, Test Loss: 0.000176\n",
      "Epoch 2/29, Train Loss: 0.000286, Test Loss: 0.000181\n",
      "Epoch 3/29, Train Loss: 0.000227, Test Loss: 0.000171\n",
      "Epoch 4/29, Train Loss: 0.000210, Test Loss: 0.000168\n",
      "Epoch 5/29, Train Loss: 0.000201, Test Loss: 0.000168\n",
      "Epoch 6/29, Train Loss: 0.000198, Test Loss: 0.000168\n",
      "Epoch 7/29, Train Loss: 0.000197, Test Loss: 0.000167\n",
      "Epoch 8/29, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 9/29, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 10/29, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 11/29, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 12/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/29, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 14/29, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/29, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 16/29, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 17/29, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 18/29, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/29, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 20/29, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 21/29, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 22/29, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 23/29, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 24/29, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 25/29, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 26/29, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 27/29, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 28/29, Train Loss: 0.000189, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:49:28,085] Trial 190 finished with value: 0.00016600680541500878 and parameters: {'num_hidden_layers': 2, 'layer_0_size': 92, 'layer_1_size': 244, 'dropout_rate': 0.21348822829618533, 'learning_rate': 7.760473841707447e-05, 'batch_size': 32, 'epochs': 29}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/29, Train Loss: 0.000188, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22, Train Loss: 0.000374, Test Loss: 0.000196\n",
      "Epoch 2/22, Train Loss: 0.000250, Test Loss: 0.000174\n",
      "Epoch 3/22, Train Loss: 0.000222, Test Loss: 0.000169\n",
      "Epoch 4/22, Train Loss: 0.000211, Test Loss: 0.000170\n",
      "Epoch 5/22, Train Loss: 0.000203, Test Loss: 0.000167\n",
      "Epoch 6/22, Train Loss: 0.000198, Test Loss: 0.000172\n",
      "Epoch 7/22, Train Loss: 0.000196, Test Loss: 0.000165\n",
      "Epoch 8/22, Train Loss: 0.000194, Test Loss: 0.000165\n",
      "Epoch 9/22, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 10/22, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 11/22, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/22, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 13/22, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 14/22, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 15/22, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 16/22, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 17/22, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 18/22, Train Loss: 0.000187, Test Loss: 0.000165\n",
      "Epoch 19/22, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Epoch 20/22, Train Loss: 0.000188, Test Loss: 0.000165\n",
      "Epoch 21/22, Train Loss: 0.000188, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:49:46,219] Trial 191 finished with value: 0.00016401928943863704 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 223, 'layer_1_size': 136, 'layer_2_size': 60, 'dropout_rate': 0.17480216337875165, 'learning_rate': 0.00013433048028486965, 'batch_size': 32, 'epochs': 22}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/22, Train Loss: 0.000186, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.000219, Test Loss: 0.000171\n",
      "Epoch 2/20, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 3/20, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 4/20, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 5/20, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 6/20, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/20, Train Loss: 0.000191, Test Loss: 0.000168\n",
      "Epoch 11/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/20, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 14/20, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 15/20, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 16/20, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 17/20, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 18/20, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 19/20, Train Loss: 0.000190, Test Loss: 0.000163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:50:05,987] Trial 192 finished with value: 0.00016315633797236637 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 126, 'layer_1_size': 134, 'layer_2_size': 54, 'dropout_rate': 0.17905981791234113, 'learning_rate': 0.0001344838321314009, 'batch_size': 32, 'epochs': 20}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Train Loss: 0.000189, Test Loss: 0.000163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19, Train Loss: 0.000301, Test Loss: 0.000177\n",
      "Epoch 2/19, Train Loss: 0.000216, Test Loss: 0.000168\n",
      "Epoch 3/19, Train Loss: 0.000202, Test Loss: 0.000167\n",
      "Epoch 4/19, Train Loss: 0.000198, Test Loss: 0.000167\n",
      "Epoch 5/19, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 6/19, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 7/19, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 8/19, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/19, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 11/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 12/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/19, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 16/19, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 17/19, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 18/19, Train Loss: 0.000190, Test Loss: 0.000163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:50:20,459] Trial 193 finished with value: 0.00016359042089125216 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 118, 'layer_1_size': 136, 'layer_2_size': 53, 'dropout_rate': 0.17505397444795523, 'learning_rate': 0.00013296126362177425, 'batch_size': 32, 'epochs': 19}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/19, Train Loss: 0.000190, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18, Train Loss: 0.000401, Test Loss: 0.000172\n",
      "Epoch 2/18, Train Loss: 0.000230, Test Loss: 0.000187\n",
      "Epoch 3/18, Train Loss: 0.000219, Test Loss: 0.000192\n",
      "Epoch 4/18, Train Loss: 0.000210, Test Loss: 0.000183\n",
      "Epoch 5/18, Train Loss: 0.000206, Test Loss: 0.000169\n",
      "Epoch 6/18, Train Loss: 0.000202, Test Loss: 0.000173\n",
      "Epoch 7/18, Train Loss: 0.000200, Test Loss: 0.000171\n",
      "Epoch 8/18, Train Loss: 0.000196, Test Loss: 0.000171\n",
      "Epoch 9/18, Train Loss: 0.000195, Test Loss: 0.000166\n",
      "Epoch 10/18, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 11/18, Train Loss: 0.000193, Test Loss: 0.000169\n",
      "Epoch 12/18, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 13/18, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/18, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 15/18, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 16/18, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 17/18, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:50:56,947] Trial 194 finished with value: 0.0001650208932401696 and parameters: {'num_hidden_layers': 8, 'layer_0_size': 117, 'layer_1_size': 130, 'layer_2_size': 65, 'layer_3_size': 215, 'layer_4_size': 83, 'layer_5_size': 32, 'layer_6_size': 216, 'layer_7_size': 87, 'dropout_rate': 0.16952977716710474, 'learning_rate': 9.711825688811384e-05, 'batch_size': 32, 'epochs': 18}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/18, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.000237, Test Loss: 0.000173\n",
      "Epoch 2/20, Train Loss: 0.000200, Test Loss: 0.000169\n",
      "Epoch 3/20, Train Loss: 0.000196, Test Loss: 0.000167\n",
      "Epoch 4/20, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 5/20, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 6/20, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/20, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 8/20, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 9/20, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 10/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 12/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/20, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 17/20, Train Loss: 0.000191, Test Loss: 0.000164\n",
      "Epoch 18/20, Train Loss: 0.000190, Test Loss: 0.000164\n",
      "Epoch 19/20, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:51:12,759] Trial 195 finished with value: 0.0001639785806996623 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 129, 'layer_1_size': 120, 'layer_2_size': 61, 'dropout_rate': 0.17512062012740195, 'learning_rate': 0.0001348446604386036, 'batch_size': 32, 'epochs': 20}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Train Loss: 0.000190, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19, Train Loss: 0.000396, Test Loss: 0.000202\n",
      "Epoch 2/19, Train Loss: 0.000228, Test Loss: 0.000179\n",
      "Epoch 3/19, Train Loss: 0.000208, Test Loss: 0.000176\n",
      "Epoch 4/19, Train Loss: 0.000201, Test Loss: 0.000168\n",
      "Epoch 5/19, Train Loss: 0.000196, Test Loss: 0.000168\n",
      "Epoch 6/19, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 7/19, Train Loss: 0.000194, Test Loss: 0.000169\n",
      "Epoch 8/19, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 9/19, Train Loss: 0.000193, Test Loss: 0.000167\n",
      "Epoch 10/19, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 11/19, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 12/19, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 13/19, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/19, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 18/19, Train Loss: 0.000204, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:51:29,141] Trial 196 finished with value: 0.0001645602457147693 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 123, 'layer_1_size': 134, 'layer_2_size': 53, 'dropout_rate': 0.17998492753838044, 'learning_rate': 0.00011975059611911026, 'batch_size': 32, 'epochs': 19}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/19, Train Loss: 0.000191, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.000247, Test Loss: 0.000170\n",
      "Epoch 2/20, Train Loss: 0.000201, Test Loss: 0.000169\n",
      "Epoch 3/20, Train Loss: 0.000197, Test Loss: 0.000168\n",
      "Epoch 4/20, Train Loss: 0.000195, Test Loss: 0.000168\n",
      "Epoch 5/20, Train Loss: 0.000194, Test Loss: 0.000168\n",
      "Epoch 6/20, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 7/20, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 8/20, Train Loss: 0.000193, Test Loss: 0.000165\n",
      "Epoch 9/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 10/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 11/20, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 12/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 13/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 14/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/20, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 17/20, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 18/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 19/20, Train Loss: 0.000190, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:51:45,768] Trial 197 finished with value: 0.00016464130844027632 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 124, 'layer_1_size': 122, 'layer_2_size': 60, 'dropout_rate': 0.17360702145042384, 'learning_rate': 8.762817777779419e-05, 'batch_size': 32, 'epochs': 20}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Train Loss: 0.000190, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21, Train Loss: 0.000208, Test Loss: 0.000168\n",
      "Epoch 2/21, Train Loss: 0.000194, Test Loss: 0.000167\n",
      "Epoch 3/21, Train Loss: 0.000193, Test Loss: 0.000166\n",
      "Epoch 4/21, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 5/21, Train Loss: 0.000192, Test Loss: 0.000169\n",
      "Epoch 6/21, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 7/21, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 8/21, Train Loss: 0.000192, Test Loss: 0.000165\n",
      "Epoch 9/21, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 10/21, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 11/21, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 12/21, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 13/21, Train Loss: 0.000190, Test Loss: 0.000167\n",
      "Epoch 14/21, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 15/21, Train Loss: 0.000189, Test Loss: 0.000164\n",
      "Epoch 16/21, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 17/21, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 18/21, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 19/21, Train Loss: 0.000188, Test Loss: 0.000164\n",
      "Epoch 20/21, Train Loss: 0.000188, Test Loss: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:52:03,992] Trial 198 finished with value: 0.000164326951118798 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 130, 'layer_1_size': 256, 'layer_2_size': 68, 'dropout_rate': 0.16189932310130667, 'learning_rate': 0.00013411898995653205, 'batch_size': 32, 'epochs': 21}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/21, Train Loss: 0.000187, Test Loss: 0.000164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/var/folders/nd/fsmv2lz93k3_cjwz_1lx75j80000gn/T/ipykernel_92891/2404448442.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.000350, Test Loss: 0.000187\n",
      "Epoch 2/20, Train Loss: 0.000240, Test Loss: 0.000177\n",
      "Epoch 3/20, Train Loss: 0.000218, Test Loss: 0.000169\n",
      "Epoch 4/20, Train Loss: 0.000206, Test Loss: 0.000169\n",
      "Epoch 5/20, Train Loss: 0.000200, Test Loss: 0.000171\n",
      "Epoch 6/20, Train Loss: 0.000197, Test Loss: 0.000170\n",
      "Epoch 7/20, Train Loss: 0.000195, Test Loss: 0.000167\n",
      "Epoch 8/20, Train Loss: 0.000194, Test Loss: 0.000166\n",
      "Epoch 9/20, Train Loss: 0.000193, Test Loss: 0.000168\n",
      "Epoch 10/20, Train Loss: 0.000192, Test Loss: 0.000167\n",
      "Epoch 11/20, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 12/20, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 13/20, Train Loss: 0.000192, Test Loss: 0.000166\n",
      "Epoch 14/20, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 15/20, Train Loss: 0.000191, Test Loss: 0.000165\n",
      "Epoch 16/20, Train Loss: 0.000190, Test Loss: 0.000166\n",
      "Epoch 17/20, Train Loss: 0.000191, Test Loss: 0.000166\n",
      "Epoch 18/20, Train Loss: 0.000190, Test Loss: 0.000165\n",
      "Epoch 19/20, Train Loss: 0.000190, Test Loss: 0.000166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-26 12:52:21,080] Trial 199 finished with value: 0.0001657463940337185 and parameters: {'num_hidden_layers': 3, 'layer_0_size': 116, 'layer_1_size': 114, 'layer_2_size': 74, 'dropout_rate': 0.17670923888807585, 'learning_rate': 0.00011454734538579538, 'batch_size': 32, 'epochs': 20}. Best is trial 116 with value: 0.0001615109022571731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Train Loss: 0.000189, Test Loss: 0.000166\n",
      "Best trial:\n",
      "  Value: 0.0001615109022571731\n",
      "  Params:\n",
      "    num_hidden_layers: 3\n",
      "    layer_0_size: 223\n",
      "    layer_1_size: 64\n",
      "    layer_2_size: 194\n",
      "    dropout_rate: 0.11419484328966484\n",
      "    learning_rate: 0.00017486754285944678\n",
      "    batch_size: 32\n",
      "    epochs: 29\n"
     ]
    }
   ],
   "source": [
    "# Creating function for training and evaluating the model\n",
    "def train_and_evaluate_model(model, train_loader, test_loader, criterion, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0.0\n",
    "            for inputs, targets in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                test_loss += loss.item()\n",
    "            test_loss /= len(test_loader)\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}')\n",
    "    \n",
    "    return test_loss\n",
    "\n",
    "# Creating function for selection of best hyperparameters \n",
    "def objective(trial):\n",
    "    # Defining hyperparameters\n",
    "    num_hidden_layers = trial.suggest_int('num_hidden_layers', 1, 10)\n",
    "    hidden_layer_sizes = [\n",
    "        trial.suggest_int(f'layer_{i}_size', 32, 256)\n",
    "        for i in range(num_hidden_layers)\n",
    "    ]\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "    epochs = trial.suggest_int('epochs', 5, 40)\n",
    "    input_size = 59\n",
    "\n",
    "    news_df = pd.read_csv('./prep_news_data.csv')\n",
    "\n",
    "    X = news_df.iloc[:, :-1].values\n",
    "    y = news_df.iloc[:, -1].values\n",
    "    y = y.reshape(-1, 1)\n",
    "\n",
    "    # Data normalization\n",
    "    scaler_X = MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "    scaler_y = MinMaxScaler()\n",
    "    y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "    # Splitting data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convertation data to PyTorch tensors\n",
    "    train_features = torch.tensor(X_train, dtype=torch.float32)\n",
    "    test_features = torch.tensor(X_test, dtype=torch.float32)\n",
    "    train_targets = torch.tensor(y_train, dtype=torch.float32)\n",
    "    test_targets = torch.tensor(y_test, dtype=torch.float32)    \n",
    "\n",
    "    # Creating DataLoader\n",
    "    train_data = TensorDataset(train_features, train_targets)\n",
    "    test_data = TensorDataset(test_features, test_targets)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Creating a model and defining of optimizer\n",
    "    model = FlexibleRegressionNN(input_size, hidden_layer_sizes, dropout_rate)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training launch and return the test loss\n",
    "    return train_and_evaluate_model(model, train_loader, test_loader, criterion, optimizer, epochs)\n",
    "\n",
    "# Settings of searching by Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "# Getting the best hyperparameters\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
