{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract MLP's matrix of weights for news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all needed dependencies\n",
    "# ! pip install git+https://github.com/aimclub/eXplain-NNs &> /dev/null\n",
    "# ! pip install torchmetrics &> /dev/null\n",
    "# ! pip install giotto-ph==0.2.2 &> /dev/null\n",
    "# ! pip install giotto-tda==0.6.0 &> /dev/null\n",
    "# ! pip install umap-learn==0.5.3 &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import eXNN.topology\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 70)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank( timedelta)</th>\n",
       "      <th>rank( n_tokens_title)</th>\n",
       "      <th>rank( n_tokens_content)</th>\n",
       "      <th>rank( n_unique_tokens)</th>\n",
       "      <th>rank( n_non_stop_words)</th>\n",
       "      <th>rank( n_non_stop_unique_tokens)</th>\n",
       "      <th>rank( num_hrefs)</th>\n",
       "      <th>rank( num_self_hrefs)</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>rank( average_token_length)</th>\n",
       "      <th>rank( num_keywords)</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>rank( kw_max_min)</th>\n",
       "      <th>rank( kw_avg_min)</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>rank( kw_avg_max)</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>rank( kw_max_avg)</th>\n",
       "      <th>rank( kw_avg_avg)</th>\n",
       "      <th>rank( self_reference_min_shares)</th>\n",
       "      <th>rank( self_reference_max_shares)</th>\n",
       "      <th>rank( self_reference_avg_sharess)</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>rank( LDA_00)</th>\n",
       "      <th>rank( LDA_01)</th>\n",
       "      <th>rank( LDA_02)</th>\n",
       "      <th>rank( LDA_03)</th>\n",
       "      <th>rank( LDA_04)</th>\n",
       "      <th>rank( global_subjectivity)</th>\n",
       "      <th>rank( global_sentiment_polarity)</th>\n",
       "      <th>rank( global_rate_positive_words)</th>\n",
       "      <th>rank( global_rate_negative_words)</th>\n",
       "      <th>rank( rate_positive_words)</th>\n",
       "      <th>rank( rate_negative_words)</th>\n",
       "      <th>rank( avg_positive_polarity)</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>rank( avg_negative_polarity)</th>\n",
       "      <th>rank( min_negative_polarity)</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.091313</td>\n",
       "      <td>0.746312</td>\n",
       "      <td>-0.830751</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>-0.859076</td>\n",
       "      <td>1.250329</td>\n",
       "      <td>-0.773700</td>\n",
       "      <td>-0.247319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060832</td>\n",
       "      <td>-1.077791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.314162</td>\n",
       "      <td>-2.013451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-0.809729</td>\n",
       "      <td>-0.897243</td>\n",
       "      <td>-0.895353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.011874</td>\n",
       "      <td>1.107189</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.133906</td>\n",
       "      <td>-0.019697</td>\n",
       "      <td>0.834551</td>\n",
       "      <td>-0.299737</td>\n",
       "      <td>0.407371</td>\n",
       "      <td>-0.186943</td>\n",
       "      <td>0.425334</td>\n",
       "      <td>-0.344559</td>\n",
       "      <td>0.257404</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.840613</td>\n",
       "      <td>-0.309042</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.091313</td>\n",
       "      <td>-0.627749</td>\n",
       "      <td>-0.629945</td>\n",
       "      <td>0.636396</td>\n",
       "      <td>-0.682170</td>\n",
       "      <td>1.037852</td>\n",
       "      <td>-1.082209</td>\n",
       "      <td>-0.770293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874264</td>\n",
       "      <td>-1.654145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.314162</td>\n",
       "      <td>-2.013451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-1.337803</td>\n",
       "      <td>-1.337726</td>\n",
       "      <td>-1.337803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.506066</td>\n",
       "      <td>0.481113</td>\n",
       "      <td>0.164789</td>\n",
       "      <td>0.215657</td>\n",
       "      <td>0.071541</td>\n",
       "      <td>-1.206170</td>\n",
       "      <td>0.345029</td>\n",
       "      <td>0.255150</td>\n",
       "      <td>0.038674</td>\n",
       "      <td>0.167738</td>\n",
       "      <td>-0.092096</td>\n",
       "      <td>-0.900984</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.303623</td>\n",
       "      <td>1.355812</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.091313</td>\n",
       "      <td>-0.627749</td>\n",
       "      <td>-0.877419</td>\n",
       "      <td>0.346405</td>\n",
       "      <td>-0.977397</td>\n",
       "      <td>-0.284000</td>\n",
       "      <td>-1.082209</td>\n",
       "      <td>-0.770293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.983430</td>\n",
       "      <td>-0.561454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.314162</td>\n",
       "      <td>-2.013451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-0.314418</td>\n",
       "      <td>-0.753138</td>\n",
       "      <td>-0.722589</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628018</td>\n",
       "      <td>-0.102896</td>\n",
       "      <td>-0.194219</td>\n",
       "      <td>-0.319837</td>\n",
       "      <td>1.102533</td>\n",
       "      <td>2.439542</td>\n",
       "      <td>2.017790</td>\n",
       "      <td>1.034661</td>\n",
       "      <td>-0.690612</td>\n",
       "      <td>1.106431</td>\n",
       "      <td>-0.977397</td>\n",
       "      <td>1.564511</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.637609</td>\n",
       "      <td>-0.868165</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.091313</td>\n",
       "      <td>-0.627749</td>\n",
       "      <td>0.309539</td>\n",
       "      <td>-0.344123</td>\n",
       "      <td>0.321434</td>\n",
       "      <td>-0.264207</td>\n",
       "      <td>0.207090</td>\n",
       "      <td>-1.494860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.947209</td>\n",
       "      <td>-0.086922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.314162</td>\n",
       "      <td>-2.013451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-1.337803</td>\n",
       "      <td>-1.337726</td>\n",
       "      <td>-1.337803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.437130</td>\n",
       "      <td>1.172315</td>\n",
       "      <td>0.875191</td>\n",
       "      <td>-0.392816</td>\n",
       "      <td>-0.811837</td>\n",
       "      <td>-0.291810</td>\n",
       "      <td>-0.208737</td>\n",
       "      <td>0.150161</td>\n",
       "      <td>0.574307</td>\n",
       "      <td>-0.284132</td>\n",
       "      <td>0.363172</td>\n",
       "      <td>0.351546</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.984764</td>\n",
       "      <td>-0.309042</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.091313</td>\n",
       "      <td>1.191898</td>\n",
       "      <td>1.253929</td>\n",
       "      <td>-1.200952</td>\n",
       "      <td>1.406604</td>\n",
       "      <td>-1.358432</td>\n",
       "      <td>1.046996</td>\n",
       "      <td>2.268357</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069322</td>\n",
       "      <td>-0.086922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.314162</td>\n",
       "      <td>-2.013451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-3.091313</td>\n",
       "      <td>-0.768720</td>\n",
       "      <td>1.144183</td>\n",
       "      <td>0.294747</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.314651</td>\n",
       "      <td>-0.220448</td>\n",
       "      <td>-0.531720</td>\n",
       "      <td>-0.626094</td>\n",
       "      <td>1.680026</td>\n",
       "      <td>0.738234</td>\n",
       "      <td>1.686806</td>\n",
       "      <td>1.934743</td>\n",
       "      <td>-0.367261</td>\n",
       "      <td>1.143818</td>\n",
       "      <td>-1.009924</td>\n",
       "      <td>0.671991</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.327633</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>-3.716757</td>\n",
       "      <td>0.299307</td>\n",
       "      <td>-0.208059</td>\n",
       "      <td>-0.100354</td>\n",
       "      <td>-0.394045</td>\n",
       "      <td>-0.060357</td>\n",
       "      <td>0.207090</td>\n",
       "      <td>1.378593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.507837</td>\n",
       "      <td>0.343989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.024409</td>\n",
       "      <td>-0.424676</td>\n",
       "      <td>26900.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>0.911184</td>\n",
       "      <td>2514.742857</td>\n",
       "      <td>-0.200666</td>\n",
       "      <td>0.179677</td>\n",
       "      <td>1.547643</td>\n",
       "      <td>1.792045</td>\n",
       "      <td>1.960439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.686325</td>\n",
       "      <td>-0.822431</td>\n",
       "      <td>0.344962</td>\n",
       "      <td>-0.966295</td>\n",
       "      <td>1.300303</td>\n",
       "      <td>0.369968</td>\n",
       "      <td>0.265549</td>\n",
       "      <td>-0.088382</td>\n",
       "      <td>-0.099273</td>\n",
       "      <td>0.086256</td>\n",
       "      <td>-0.011160</td>\n",
       "      <td>-0.331371</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.056493</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39640</th>\n",
       "      <td>-3.716757</td>\n",
       "      <td>0.746312</td>\n",
       "      <td>-0.278442</td>\n",
       "      <td>1.442174</td>\n",
       "      <td>-0.472542</td>\n",
       "      <td>1.915979</td>\n",
       "      <td>0.207090</td>\n",
       "      <td>1.378593</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-0.944538</td>\n",
       "      <td>-0.086922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.111863</td>\n",
       "      <td>-0.343553</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>-0.463864</td>\n",
       "      <td>1664.267857</td>\n",
       "      <td>0.457255</td>\n",
       "      <td>0.522204</td>\n",
       "      <td>0.512085</td>\n",
       "      <td>-0.200537</td>\n",
       "      <td>-0.045952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.229267</td>\n",
       "      <td>-0.398422</td>\n",
       "      <td>0.508340</td>\n",
       "      <td>1.064995</td>\n",
       "      <td>-0.650512</td>\n",
       "      <td>1.306810</td>\n",
       "      <td>0.854330</td>\n",
       "      <td>0.039433</td>\n",
       "      <td>-0.730368</td>\n",
       "      <td>0.757048</td>\n",
       "      <td>-0.660623</td>\n",
       "      <td>0.203796</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.416663</td>\n",
       "      <td>0.394831</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39641</th>\n",
       "      <td>-3.716757</td>\n",
       "      <td>-0.158415</td>\n",
       "      <td>0.091302</td>\n",
       "      <td>-0.222587</td>\n",
       "      <td>0.147508</td>\n",
       "      <td>-0.491646</td>\n",
       "      <td>1.335872</td>\n",
       "      <td>-0.770293</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.415071</td>\n",
       "      <td>0.343989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.072048</td>\n",
       "      <td>-0.460873</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>0.404934</td>\n",
       "      <td>1753.882353</td>\n",
       "      <td>0.855287</td>\n",
       "      <td>1.068122</td>\n",
       "      <td>0.159376</td>\n",
       "      <td>-0.483671</td>\n",
       "      <td>-0.385722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505177</td>\n",
       "      <td>-0.640777</td>\n",
       "      <td>-0.697652</td>\n",
       "      <td>1.015044</td>\n",
       "      <td>0.250808</td>\n",
       "      <td>0.697813</td>\n",
       "      <td>-0.997733</td>\n",
       "      <td>-0.324699</td>\n",
       "      <td>0.953765</td>\n",
       "      <td>-0.792776</td>\n",
       "      <td>0.900083</td>\n",
       "      <td>-0.660859</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.892713</td>\n",
       "      <td>-0.868165</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39642</th>\n",
       "      <td>-3.716757</td>\n",
       "      <td>-2.153192</td>\n",
       "      <td>0.617082</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.705942</td>\n",
       "      <td>0.023808</td>\n",
       "      <td>0.329067</td>\n",
       "      <td>-0.770293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.082436</td>\n",
       "      <td>-1.077791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.314162</td>\n",
       "      <td>-2.375909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>0.081465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.198484</td>\n",
       "      <td>-1.659634</td>\n",
       "      <td>-0.842009</td>\n",
       "      <td>-0.902979</td>\n",
       "      <td>-0.902124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193188</td>\n",
       "      <td>0.241684</td>\n",
       "      <td>1.515967</td>\n",
       "      <td>0.021404</td>\n",
       "      <td>-0.064950</td>\n",
       "      <td>-1.048091</td>\n",
       "      <td>-1.469914</td>\n",
       "      <td>-1.181859</td>\n",
       "      <td>0.827942</td>\n",
       "      <td>-1.331563</td>\n",
       "      <td>1.541598</td>\n",
       "      <td>-1.397816</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.475867</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39643</th>\n",
       "      <td>-3.716757</td>\n",
       "      <td>-0.158415</td>\n",
       "      <td>-1.245233</td>\n",
       "      <td>1.489854</td>\n",
       "      <td>-1.299567</td>\n",
       "      <td>1.540148</td>\n",
       "      <td>-1.696325</td>\n",
       "      <td>-0.770293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.700679</td>\n",
       "      <td>-1.654145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.622922</td>\n",
       "      <td>-1.749738</td>\n",
       "      <td>205600.0</td>\n",
       "      <td>843300.0</td>\n",
       "      <td>0.859487</td>\n",
       "      <td>3035.080555</td>\n",
       "      <td>-0.473319</td>\n",
       "      <td>0.424711</td>\n",
       "      <td>0.512085</td>\n",
       "      <td>-0.200537</td>\n",
       "      <td>-0.045952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309937</td>\n",
       "      <td>1.816184</td>\n",
       "      <td>0.115936</td>\n",
       "      <td>0.239210</td>\n",
       "      <td>0.067294</td>\n",
       "      <td>0.792819</td>\n",
       "      <td>-0.159920</td>\n",
       "      <td>1.407029</td>\n",
       "      <td>-0.296564</td>\n",
       "      <td>0.920030</td>\n",
       "      <td>-0.810958</td>\n",
       "      <td>-1.304289</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.532339</td>\n",
       "      <td>0.988570</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39644 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rank( timedelta)  rank( n_tokens_title)  rank( n_tokens_content)  \\\n",
       "0              3.091313               0.746312                -0.830751   \n",
       "1              3.091313              -0.627749                -0.629945   \n",
       "2              3.091313              -0.627749                -0.877419   \n",
       "3              3.091313              -0.627749                 0.309539   \n",
       "4              3.091313               1.191898                 1.253929   \n",
       "...                 ...                    ...                      ...   \n",
       "39639         -3.716757               0.299307                -0.208059   \n",
       "39640         -3.716757               0.746312                -0.278442   \n",
       "39641         -3.716757              -0.158415                 0.091302   \n",
       "39642         -3.716757              -2.153192                 0.617082   \n",
       "39643         -3.716757              -0.158415                -1.245233   \n",
       "\n",
       "       rank( n_unique_tokens)  rank( n_non_stop_words)  \\\n",
       "0                    1.171875                -0.859076   \n",
       "1                    0.636396                -0.682170   \n",
       "2                    0.346405                -0.977397   \n",
       "3                   -0.344123                 0.321434   \n",
       "4                   -1.200952                 1.406604   \n",
       "...                       ...                      ...   \n",
       "39639               -0.100354                -0.394045   \n",
       "39640                1.442174                -0.472542   \n",
       "39641               -0.222587                 0.147508   \n",
       "39642                0.002434                 0.705942   \n",
       "39643                1.489854                -1.299567   \n",
       "\n",
       "       rank( n_non_stop_unique_tokens)  rank( num_hrefs)  \\\n",
       "0                             1.250329         -0.773700   \n",
       "1                             1.037852         -1.082209   \n",
       "2                            -0.284000         -1.082209   \n",
       "3                            -0.264207          0.207090   \n",
       "4                            -1.358432          1.046996   \n",
       "...                                ...               ...   \n",
       "39639                        -0.060357          0.207090   \n",
       "39640                         1.915979          0.207090   \n",
       "39641                        -0.491646          1.335872   \n",
       "39642                         0.023808          0.329067   \n",
       "39643                         1.540148         -1.696325   \n",
       "\n",
       "       rank( num_self_hrefs)   num_imgs   num_videos  \\\n",
       "0                  -0.247319        1.0          0.0   \n",
       "1                  -0.770293        1.0          0.0   \n",
       "2                  -0.770293        1.0          0.0   \n",
       "3                  -1.494860        1.0          0.0   \n",
       "4                   2.268357       20.0          0.0   \n",
       "...                      ...        ...          ...   \n",
       "39639               1.378593        1.0          1.0   \n",
       "39640               1.378593        3.0         48.0   \n",
       "39641              -0.770293       12.0          1.0   \n",
       "39642              -0.770293        1.0          0.0   \n",
       "39643              -0.770293        0.0          2.0   \n",
       "\n",
       "       rank( average_token_length)  rank( num_keywords)  \\\n",
       "0                         0.060832            -1.077791   \n",
       "1                         0.874264            -1.654145   \n",
       "2                        -0.983430            -0.561454   \n",
       "3                        -0.947209            -0.086922   \n",
       "4                         0.069322            -0.086922   \n",
       "...                            ...                  ...   \n",
       "39639                    -0.507837             0.343989   \n",
       "39640                    -0.944538            -0.086922   \n",
       "39641                     1.415071             0.343989   \n",
       "39642                     1.082436            -1.077791   \n",
       "39643                    -0.700679            -1.654145   \n",
       "\n",
       "        data_channel_is_lifestyle   data_channel_is_entertainment  \\\n",
       "0                             0.0                             1.0   \n",
       "1                             0.0                             0.0   \n",
       "2                             0.0                             0.0   \n",
       "3                             0.0                             1.0   \n",
       "4                             0.0                             0.0   \n",
       "...                           ...                             ...   \n",
       "39639                         0.0                             0.0   \n",
       "39640                         0.0                             0.0   \n",
       "39641                         0.0                             0.0   \n",
       "39642                         0.0                             0.0   \n",
       "39643                         0.0                             1.0   \n",
       "\n",
       "        data_channel_is_bus   data_channel_is_socmed   data_channel_is_tech  \\\n",
       "0                       0.0                      0.0                    0.0   \n",
       "1                       1.0                      0.0                    0.0   \n",
       "2                       1.0                      0.0                    0.0   \n",
       "3                       0.0                      0.0                    0.0   \n",
       "4                       0.0                      0.0                    1.0   \n",
       "...                     ...                      ...                    ...   \n",
       "39639                   0.0                      0.0                    1.0   \n",
       "39640                   0.0                      1.0                    0.0   \n",
       "39641                   0.0                      0.0                    0.0   \n",
       "39642                   0.0                      0.0                    0.0   \n",
       "39643                   0.0                      0.0                    0.0   \n",
       "\n",
       "        data_channel_is_world   kw_min_min  rank( kw_max_min)  \\\n",
       "0                         0.0          0.0          -2.314162   \n",
       "1                         0.0          0.0          -2.314162   \n",
       "2                         0.0          0.0          -2.314162   \n",
       "3                         0.0          0.0          -2.314162   \n",
       "4                         0.0          0.0          -2.314162   \n",
       "...                       ...          ...                ...   \n",
       "39639                     0.0         -1.0           0.024409   \n",
       "39640                     0.0         -1.0          -0.111863   \n",
       "39641                     0.0         -1.0           0.072048   \n",
       "39642                     1.0         -1.0          -2.314162   \n",
       "39643                     0.0         -1.0          -1.622922   \n",
       "\n",
       "       rank( kw_avg_min)   kw_min_max   kw_max_max  rank( kw_avg_max)  \\\n",
       "0              -2.013451          0.0          0.0          -3.091313   \n",
       "1              -2.013451          0.0          0.0          -3.091313   \n",
       "2              -2.013451          0.0          0.0          -3.091313   \n",
       "3              -2.013451          0.0          0.0          -3.091313   \n",
       "4              -2.013451          0.0          0.0          -3.091313   \n",
       "...                  ...          ...          ...                ...   \n",
       "39639          -0.424676      26900.0     843300.0           0.911184   \n",
       "39640          -0.343553       6500.0     843300.0          -0.463864   \n",
       "39641          -0.460873       6200.0     843300.0           0.404934   \n",
       "39642          -2.375909          0.0     843300.0           0.081465   \n",
       "39643          -1.749738     205600.0     843300.0           0.859487   \n",
       "\n",
       "        kw_min_avg  rank( kw_max_avg)  rank( kw_avg_avg)  \\\n",
       "0         0.000000          -3.091313          -3.091313   \n",
       "1         0.000000          -3.091313          -3.091313   \n",
       "2         0.000000          -3.091313          -3.091313   \n",
       "3         0.000000          -3.091313          -3.091313   \n",
       "4         0.000000          -3.091313          -3.091313   \n",
       "...            ...                ...                ...   \n",
       "39639  2514.742857          -0.200666           0.179677   \n",
       "39640  1664.267857           0.457255           0.522204   \n",
       "39641  1753.882353           0.855287           1.068122   \n",
       "39642     0.000000          -1.198484          -1.659634   \n",
       "39643  3035.080555          -0.473319           0.424711   \n",
       "\n",
       "       rank( self_reference_min_shares)  rank( self_reference_max_shares)  \\\n",
       "0                             -0.809729                         -0.897243   \n",
       "1                             -1.337803                         -1.337726   \n",
       "2                             -0.314418                         -0.753138   \n",
       "3                             -1.337803                         -1.337726   \n",
       "4                             -0.768720                          1.144183   \n",
       "...                                 ...                               ...   \n",
       "39639                          1.547643                          1.792045   \n",
       "39640                          0.512085                         -0.200537   \n",
       "39641                          0.159376                         -0.483671   \n",
       "39642                         -0.842009                         -0.902979   \n",
       "39643                          0.512085                         -0.200537   \n",
       "\n",
       "       rank( self_reference_avg_sharess)   weekday_is_monday  \\\n",
       "0                              -0.895353                 1.0   \n",
       "1                              -1.337803                 1.0   \n",
       "2                              -0.722589                 1.0   \n",
       "3                              -1.337803                 1.0   \n",
       "4                               0.294747                 1.0   \n",
       "...                                  ...                 ...   \n",
       "39639                           1.960439                 0.0   \n",
       "39640                          -0.045952                 0.0   \n",
       "39641                          -0.385722                 0.0   \n",
       "39642                          -0.902124                 0.0   \n",
       "39643                          -0.045952                 0.0   \n",
       "\n",
       "        weekday_is_tuesday   weekday_is_wednesday   weekday_is_thursday  \\\n",
       "0                      0.0                    0.0                   0.0   \n",
       "1                      0.0                    0.0                   0.0   \n",
       "2                      0.0                    0.0                   0.0   \n",
       "3                      0.0                    0.0                   0.0   \n",
       "4                      0.0                    0.0                   0.0   \n",
       "...                    ...                    ...                   ...   \n",
       "39639                  0.0                    1.0                   0.0   \n",
       "39640                  0.0                    1.0                   0.0   \n",
       "39641                  0.0                    1.0                   0.0   \n",
       "39642                  0.0                    1.0                   0.0   \n",
       "39643                  0.0                    1.0                   0.0   \n",
       "\n",
       "        weekday_is_friday   weekday_is_saturday   weekday_is_sunday  \\\n",
       "0                     0.0                   0.0                 0.0   \n",
       "1                     0.0                   0.0                 0.0   \n",
       "2                     0.0                   0.0                 0.0   \n",
       "3                     0.0                   0.0                 0.0   \n",
       "4                     0.0                   0.0                 0.0   \n",
       "...                   ...                   ...                 ...   \n",
       "39639                 0.0                   0.0                 0.0   \n",
       "39640                 0.0                   0.0                 0.0   \n",
       "39641                 0.0                   0.0                 0.0   \n",
       "39642                 0.0                   0.0                 0.0   \n",
       "39643                 0.0                   0.0                 0.0   \n",
       "\n",
       "        is_weekend  rank( LDA_00)  rank( LDA_01)  rank( LDA_02)  \\\n",
       "0              0.0       1.011874       1.107189       0.003762   \n",
       "1              0.0       1.506066       0.481113       0.164789   \n",
       "2              0.0       0.628018      -0.102896      -0.194219   \n",
       "3              0.0      -0.437130       1.172315       0.875191   \n",
       "4              0.0      -0.314651      -0.220448      -0.531720   \n",
       "...            ...            ...            ...            ...   \n",
       "39639          0.0      -0.686325      -0.822431       0.344962   \n",
       "39640          0.0      -0.229267      -0.398422       0.508340   \n",
       "39641          0.0       0.505177      -0.640777      -0.697652   \n",
       "39642          0.0       0.193188       0.241684       1.515967   \n",
       "39643          0.0       0.309937       1.816184       0.115936   \n",
       "\n",
       "       rank( LDA_03)  rank( LDA_04)  rank( global_subjectivity)  \\\n",
       "0           0.133906      -0.019697                    0.834551   \n",
       "1           0.215657       0.071541                   -1.206170   \n",
       "2          -0.319837       1.102533                    2.439542   \n",
       "3          -0.392816      -0.811837                   -0.291810   \n",
       "4          -0.626094       1.680026                    0.738234   \n",
       "...              ...            ...                         ...   \n",
       "39639      -0.966295       1.300303                    0.369968   \n",
       "39640       1.064995      -0.650512                    1.306810   \n",
       "39641       1.015044       0.250808                    0.697813   \n",
       "39642       0.021404      -0.064950                   -1.048091   \n",
       "39643       0.239210       0.067294                    0.792819   \n",
       "\n",
       "       rank( global_sentiment_polarity)  rank( global_rate_positive_words)  \\\n",
       "0                             -0.299737                           0.407371   \n",
       "1                              0.345029                           0.255150   \n",
       "2                              2.017790                           1.034661   \n",
       "3                             -0.208737                           0.150161   \n",
       "4                              1.686806                           1.934743   \n",
       "...                                 ...                                ...   \n",
       "39639                          0.265549                          -0.088382   \n",
       "39640                          0.854330                           0.039433   \n",
       "39641                         -0.997733                          -0.324699   \n",
       "39642                         -1.469914                          -1.181859   \n",
       "39643                         -0.159920                           1.407029   \n",
       "\n",
       "       rank( global_rate_negative_words)  rank( rate_positive_words)  \\\n",
       "0                              -0.186943                    0.425334   \n",
       "1                               0.038674                    0.167738   \n",
       "2                              -0.690612                    1.106431   \n",
       "3                               0.574307                   -0.284132   \n",
       "4                              -0.367261                    1.143818   \n",
       "...                                  ...                         ...   \n",
       "39639                          -0.099273                    0.086256   \n",
       "39640                          -0.730368                    0.757048   \n",
       "39641                           0.953765                   -0.792776   \n",
       "39642                           0.827942                   -1.331563   \n",
       "39643                          -0.296564                    0.920030   \n",
       "\n",
       "       rank( rate_negative_words)  rank( avg_positive_polarity)  \\\n",
       "0                       -0.344559                      0.257404   \n",
       "1                       -0.092096                     -0.900984   \n",
       "2                       -0.977397                      1.564511   \n",
       "3                        0.363172                      0.351546   \n",
       "4                       -1.009924                      0.671991   \n",
       "...                           ...                           ...   \n",
       "39639                   -0.011160                     -0.331371   \n",
       "39640                   -0.660623                      0.203796   \n",
       "39641                    0.900083                     -0.660859   \n",
       "39642                    1.541598                     -1.397816   \n",
       "39643                   -0.810958                     -1.304289   \n",
       "\n",
       "        min_positive_polarity   max_positive_polarity  \\\n",
       "0                    0.100000                    0.70   \n",
       "1                    0.033333                    0.70   \n",
       "2                    0.100000                    1.00   \n",
       "3                    0.136364                    0.80   \n",
       "4                    0.033333                    1.00   \n",
       "...                       ...                     ...   \n",
       "39639                0.100000                    0.75   \n",
       "39640                0.136364                    0.70   \n",
       "39641                0.136364                    0.50   \n",
       "39642                0.062500                    0.50   \n",
       "39643                0.100000                    0.50   \n",
       "\n",
       "       rank( avg_negative_polarity)  rank( min_negative_polarity)  \\\n",
       "0                         -0.840613                     -0.309042   \n",
       "1                          1.303623                      1.355812   \n",
       "2                         -1.637609                     -0.868165   \n",
       "3                         -0.984764                     -0.309042   \n",
       "4                          0.327633                      0.032505   \n",
       "...                             ...                           ...   \n",
       "39639                     -0.056493                      0.032505   \n",
       "39640                      0.416663                      0.394831   \n",
       "39641                     -0.892713                     -0.868165   \n",
       "39642                      0.475867                      0.032505   \n",
       "39643                      0.532339                      0.988570   \n",
       "\n",
       "        max_negative_polarity   title_subjectivity   title_sentiment_polarity  \\\n",
       "0                   -0.200000             0.500000                  -0.187500   \n",
       "1                   -0.100000             0.000000                   0.000000   \n",
       "2                   -0.133333             0.000000                   0.000000   \n",
       "3                   -0.166667             0.000000                   0.000000   \n",
       "4                   -0.050000             0.454545                   0.136364   \n",
       "...                       ...                  ...                        ...   \n",
       "39639               -0.125000             0.100000                   0.000000   \n",
       "39640               -0.100000             0.300000                   1.000000   \n",
       "39641               -0.166667             0.454545                   0.136364   \n",
       "39642               -0.012500             0.000000                   0.000000   \n",
       "39643               -0.200000             0.333333                   0.250000   \n",
       "\n",
       "        abs_title_subjectivity   abs_title_sentiment_polarity   shares  \n",
       "0                     0.000000                       0.187500      593  \n",
       "1                     0.500000                       0.000000      711  \n",
       "2                     0.500000                       0.000000     1500  \n",
       "3                     0.500000                       0.000000     1200  \n",
       "4                     0.045455                       0.136364      505  \n",
       "...                        ...                            ...      ...  \n",
       "39639                 0.400000                       0.000000     1800  \n",
       "39640                 0.200000                       1.000000     1900  \n",
       "39641                 0.045455                       0.136364     1900  \n",
       "39642                 0.500000                       0.000000     1100  \n",
       "39643                 0.166667                       0.250000     1300  \n",
       "\n",
       "[39644 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read preprocessed news dataset\n",
    "prep_news_df = pd.read_csv('./prep_news_data.csv')\n",
    "prep_news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Full-Connected Neural Network class\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, dropout: float) -> None:\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 164),\n",
    "            nn.BatchNorm1d(164),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(164, 191),\n",
    "            nn.BatchNorm1d(191),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(191, 224),\n",
    "            nn.BatchNorm1d(224),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(224, 114),\n",
    "            nn.BatchNorm1d(114),\n",
    "            nn.LeakyReLU(),   \n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Linear(114, 164),\n",
    "            nn.BatchNorm1d(164),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Linear(164, 90),\n",
    "            nn.BatchNorm1d(90),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Linear(90, 182),\n",
    "            nn.BatchNorm1d(182),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Linear(182, 208),\n",
    "            nn.BatchNorm1d(208),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Linear(208, 72),\n",
    "            nn.BatchNorm1d(72),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        ) \n",
    "\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Linear(72, 43),\n",
    "            nn.BatchNorm1d(43),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Linear(43, 248),\n",
    "            nn.BatchNorm1d(248),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Linear(248, 76),\n",
    "            nn.BatchNorm1d(76),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Linear(76, output_dim),\n",
    "            # nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    # Define forward loop for NN\n",
    "    def forward(self, x):\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "        x = self.layer9(x)\n",
    "        x = self.layer10(x)\n",
    "        x = self.layer11(x)\n",
    "        x = self.layer12(x)\n",
    "        x = self.layer13(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for calculation RMSE\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    mse = torch.mean((y_true - y_pred) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    return rmse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and evaluating steps\n",
    "def train_and_evaluate_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs, test_data, batch, out_dir):\n",
    "    home_dir = f'./news_output/{out_dir}/weights_graphs_mlp_DataAmount{batch}/barcodes/'\n",
    "    os.makedirs(home_dir)\n",
    "    train_losses = list()\n",
    "    test_losses = list()\n",
    "    rmse_scores = list()\n",
    "    bar_datum = dict()\n",
    "    bar_evaluation = dict()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0.0\n",
    "            all_outputs = list()\n",
    "            all_targets = list()\n",
    "            for inputs, targets in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                test_loss += loss.item()\n",
    "                all_outputs.append(outputs)\n",
    "                all_targets.append(targets)\n",
    "\n",
    "            test_loss /= len(test_loader)\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "            all_outputs = torch.cat(all_outputs, dim=0)\n",
    "            all_targets = torch.cat(all_targets, dim=0)\n",
    "            rmse_value = root_mean_squared_error(all_targets, all_outputs)\n",
    "            rmse_scores.append(rmse_value)\n",
    "        scheduler.step()\n",
    "\n",
    "        # Applying some TDA methods to study the obtained network\n",
    "        model = model.to(torch.device('cpu'))\n",
    "        data = torch.stack([test_data[i][0] for i in range(100)])\n",
    "        layer_list = ['layer1', 'layer2', 'layer3', 'layer4', 'layer5', 'layer6', 'layer7', 'layer8', 'layer9', 'layer10', 'layer11', 'layer12', 'layer13']\n",
    "        barcodes = eXNN.topology.get_nn_barcodes(model, data, layers=layer_list, hom_type=\"standard\", coefs_type=\"2\")\n",
    "        barcodes_data = dict()\n",
    "        barcodes_eval = dict()\n",
    "        epoch_dir = home_dir + f'epoch{epoch+1}/'\n",
    "        os.makedirs(epoch_dir, exist_ok=True)\n",
    "        for i in range(1, 7):\n",
    "            barcode = barcodes[f'layer{i}']\n",
    "            # Save barcodes' info into the JSON\n",
    "            barcodes_data.setdefault(f'layer{i}', barcode)\n",
    "\n",
    "            # Obtain the barcode after epoch and saving it\n",
    "            bplot = eXNN.topology.plot_barcode(barcode)\n",
    "            save_fig_path = epoch_dir + f'layer{i}_barcode.png'\n",
    "            bplot.savefig(save_fig_path)\n",
    "\n",
    "            # Get and save evaluation for barcode into the JSON\n",
    "            bar_eval = eXNN.topology.evaluate_barcode(barcode)\n",
    "            barcodes_eval.setdefault(f'layer{i}', bar_eval)\n",
    "\n",
    "        bar_datum.setdefault(f'epoch{epoch+1}', barcodes_data)\n",
    "        bar_evaluation.setdefault(f'epoch{epoch+1}', barcodes_eval)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, RMSE: {rmse_value:.4f}')\n",
    "\n",
    "    # Save dictionaries with barcodes' data and evaluation as JSON files\n",
    "    with open(f'{home_dir}barcode_data.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(bar_datum, file, indent=4)\n",
    "    \n",
    "    with open(f'{home_dir}barcode_evaluation.json', 'w', encoding='utf-8') as json_eval:\n",
    "        json.dump(bar_evaluation, json_eval, indent=4)\n",
    "\n",
    "    # Get model's weights\n",
    "    model_weights = model.state_dict()\n",
    "\n",
    "    # Loss and MAPE visualisation\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(test_losses, label='Test Loss')\n",
    "    plt.plot(rmse_scores, label='RMSE')\n",
    "    plt.title('Loss and RMSE over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Metric')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return fig, model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for training network on non-full data\n",
    "def batch_fit(batch_df, epochs: int, batch: int, out_dir: str, dropout: float):\n",
    "    # Separate data into features and targets\n",
    "    X = batch_df.iloc[:, :-1].values\n",
    "    y = batch_df.iloc[:, -1].values\n",
    "    y = y.reshape(-1, 1)\n",
    "\n",
    "    # Data normalization\n",
    "    scaler_X = MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "    scaler_y = MinMaxScaler()\n",
    "    y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "    # Splitting data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Convertation data to PyTorch tensors\n",
    "    train_features = torch.tensor(X_train, dtype=torch.float32)\n",
    "    test_features = torch.tensor(X_test, dtype=torch.float32)\n",
    "    train_targets = torch.tensor(y_train, dtype=torch.float32)\n",
    "    test_targets = torch.tensor(y_test, dtype=torch.float32)    \n",
    "\n",
    "    # Creating DataLoader\n",
    "    train_data = TensorDataset(train_features, train_targets)\n",
    "    test_data = TensorDataset(test_features, test_targets)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Model initialization\n",
    "    model = MultiLayerPerceptron(59, 1, dropout)\n",
    "\n",
    "    # Define optimizator and loss function\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00016799883676835427, weight_decay=0.1)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.96)\n",
    "\n",
    "    # Perform training\n",
    "    fig, model_weights = train_and_evaluate_model(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs, test_data, batch, out_dir)\n",
    "\n",
    "    return fig, model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60, Train Loss: 0.0287, Test Loss: 0.0003, RMSE: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60, Train Loss: 0.0009, Test Loss: 0.0003, RMSE: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/60, Train Loss: 0.0002, Test Loss: 0.0003, RMSE: 0.0163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n",
      "/Users/pavel/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:128: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in scalar divide\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m last_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./news_output/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/weights_graphs_mlp_DataAmount\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(prep_news_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Training model and getting it's weights\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m fig, model_weights \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprep_news_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Saving weights and losses\u001b[39;00m\n\u001b[1;32m     26\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model_weights, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mweights_mlp_DataAmount\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(prep_news_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 40\u001b[0m, in \u001b[0;36mbatch_fit\u001b[0;34m(batch_df, epochs, batch, out_dir, dropout)\u001b[0m\n\u001b[1;32m     37\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mExponentialLR(optimizer, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.96\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Perform training\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m fig, model_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fig, model_weights\n",
      "Cell \u001b[0;32mIn[20], line 66\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, scheduler, epochs, test_data, batch, out_dir)\u001b[0m\n\u001b[1;32m     63\u001b[0m     bplot\u001b[38;5;241m.\u001b[39msavefig(save_fig_path)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Get and save evaluation for barcode into the JSON\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     bar_eval \u001b[38;5;241m=\u001b[39m \u001b[43meXNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopology\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_barcode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbarcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     barcodes_eval\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, bar_eval)\n\u001b[1;32m     69\u001b[0m bar_datum\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, barcodes_data)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/eXNN/topology/api.py:88\u001b[0m, in \u001b[0;36mevaluate_barcode\u001b[0;34m(barcode, metric_name)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_barcode\u001b[39m(\n\u001b[1;32m     74\u001b[0m     barcode: Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray], metric_name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     75\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;28mfloat\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    The function evaluates a persistent homologies barcode with a metric.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m            or a dictionary with value of each available metric\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbarcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:33\u001b[0m, in \u001b[0;36mcompute_metric\u001b[0;34m(barcode, metric_name)\u001b[0m\n\u001b[1;32m     31\u001b[0m metrics \u001b[38;5;241m=\u001b[39m _get_available_metrics()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbarcode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics[metric_name](barcode)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:33\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     31\u001b[0m metrics \u001b[38;5;241m=\u001b[39m _get_available_metrics()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {name: \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbarcode\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m (name, fn) \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics[metric_name](barcode)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/eXNN/topology/metrics.py:45\u001b[0m, in \u001b[0;36m_compute_longest_interval_metric\u001b[0;34m(barcode)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_longest_interval_metric\u001b[39m(barcode):\n\u001b[1;32m     44\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m _get_lengths(barcode)\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2810\u001b[0m, in \u001b[0;36mmax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2692\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[1;32m   2693\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2695\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2696\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2697\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2698\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2808\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "# Create a name for output folder\n",
    "out_dir = 'exp_0'\n",
    "\n",
    "# # Create cycle for training network with different amounts of data\n",
    "# for batch in range(5000, len(prep_news_df), 5000):\n",
    "#     base_dir = f'./news_output/{out_dir}/weights_graphs_mlp_DataAmount{batch}/'\n",
    "#     # Getting part of the dataset\n",
    "#     df_batch = prep_news_df.head(batch)\n",
    "\n",
    "#     # Training model and getting it's weights\n",
    "#     fig, model_weights = batch_fit(df_batch, 60, batch, out_dir, 0.25)\n",
    "\n",
    "#     # Saving weights, loss function and RMSE\n",
    "#     torch.save(model_weights, f'{base_dir}weights_mlp_DataAmount{batch}.pth')\n",
    "#     fig.savefig(f'{base_dir}loss_and_rmse_mlp_DataAmount{batch}.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "\n",
    "# Getting part of the dataset\n",
    "df_batch = prep_news_df.head(len(prep_news_df))\n",
    "last_dir = f'./news_output/{out_dir}/weights_graphs_mlp_DataAmount{len(prep_news_df)}/'\n",
    "\n",
    "# Training model and getting it's weights\n",
    "fig, model_weights = batch_fit(df_batch, 60, len(prep_news_df), out_dir, 0.25)\n",
    "\n",
    "# Saving weights and losses\n",
    "torch.save(model_weights, f'{last_dir}weights_mlp_DataAmount{len(prep_news_df)}.pth')\n",
    "fig.savefig(f'{last_dir}loss_and_rmse_mlp_DataAmount{len(prep_news_df)}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
